{
  "user-guide": [
    {
      "id": "/gdi-userportal-frontend/user-guide/about-gdi",
      "url": "/gdi-userportal-frontend/user-guide/about-gdi",
      "title": "About GDI",
      "content": "",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/explore-datasets/browse-by-category",
      "url": "/gdi-userportal-frontend/user-guide/explore-datasets/browse-by-category",
      "title": "browse by category",
      "content": "Browse datasets by category Browse datasets by Themes and Publishers directly from the main menu. While these categories are available as filters in the search page, you can access their dedicated sections from the main navigation menu for quick browsing. :::tip Sign in for better discovery Sign in to view comprehensive information. While you can use this tool without an account, signing in allows you to search and view more details, such as and other metadata, to help you find what you need. ::: To browse datasets by theme or publisher categories: 1. Select either Themes or Publishers from the main navigation menu. 2. Select the theme or publisher name. The Datasets page opens with pre-applied filters based on your selection. In this example, \"University of Oslo\" is selected under Publishers. 3. Explore more using the search, or apply more filters to narrow down results. 4. Found a dataset of interest? Select it to view more details or Request access to the dataset.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/explore-datasets/search-and-filter",
      "url": "/gdi-userportal-frontend/user-guide/explore-datasets/search-and-filter",
      "title": "search and filter",
      "content": "Search and filter datasets Use the search bar and filters to find datasets relevant to your research. Both search and filters are available on all pages where browsing datasets is possible. This includes the Home page and the Datasets page. :::tip Sign in for enhanced search Sign in to get comprehensive search results. While you can search datasets without an account, signing in allows you to filter and view more details in the search results, such as and other metadata. ::: Search datasets On the Home or Datasets page, enter any term or phrase to search across all dataset information, including: - Disease names, research topics, or data types - Specific terms like gene names or scientific keywords - Any other information described in the dataset metadata Filter your results Use the filters on the left side of the search results page to narrow down your results. These filters are based on dataset metadata, and signing in gives you access to additional metadata-based filters. Common filters include: Access Rights, Data Types, Themes, and Publishers. Here's an example of a search result for the word \"cancer\", with filters applied for Access Rights: .",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/explore-datasets/search-by-allele-frequency",
      "url": "/gdi-userportal-frontend/user-guide/explore-datasets/search-by-allele-frequency",
      "title": "search by allele frequency",
      "content": "Search by allele frequency Search for datasets containing specific genomic variants using the allele frequency search tool. Allele frequency refers to how common a specific genetic variant is within a population. This search tool allows you to: - Identify relevant datasets with your specific genomic variant of interest - Compare variant frequencies across different populations and research cohorts - Assess dataset suitability by viewing detailed prevalence data to select the most appropriate datasets for your research :::tip Sign in for enhanced search Sign in to get comprehensive search results. While you can use this tool without an account, signing in allows you to search and view more details, such as and other metadata, to help you find what you need. ::: Search by allele frequency 1. Select Allele Frequency from the main menu. 2. Enter your search criteria: - Variant: The full form of the genomic variant, usually represented in the format . Example: - Ref Genome: Select the reference genome assembly to use for the search. - Cohort: Select the cohort of interest. Cohorts are groups of individuals sharing common characteristics, for example, those with a specific condition such as COVID. - Sex (optional): Filter results by biological sex (Male or Female). - Country of Birth (optional): Filter results by country of birth using 2-letter ISO country codes. 3. Select Search or press Enter. The search results display dataset information in table format. Understanding your results The search results display datasets containing your specified variant in table format. Here's an example of the search result using the allele frequency search tool: - Dataset: Name and source of the dataset. These are Beacon identifiers—the portal uses Beacon technology to retrieve information about whether genomic databases contain specific variants. - Population: Population identifier from the dataset (e.g., \"FR_M\" for French males in GoE format). - Allele Count: Number of times the variant appears in the dataset. - Allele Number: Total number of alleles analysed in the dataset for this position. - Homozygous: Number of individuals with two copies of the variant. - Heterozygous: Number of individuals with one copy of the variant. - Hemizygous: Number of individuals with one copy of the variant on a sex chromosome (relevant for an X or Y chromosome). - Frequency: How common the variant is in that population (as a decimal). - Actions: Add the dataset to your basket to request access later.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/export-metadata",
      "url": "/gdi-userportal-frontend/user-guide/export-metadata",
      "title": "export metadata",
      "content": "Export metadata Download dataset metadata for integration with various tools and systems. The metadata includes detailed information about the dataset such as data types, collection methods, access rights, and other descriptive information that can help you integrate the dataset information into your research workflow. You can export metadata in the following formats: - RDF: Resource Description Framework format for semantic web applications - TTL: Turtle format for human-readable RDF data - JSON-LD: JSON for Linked Data format for web-based applications To export metadata: 1. Browse or search for datasets you want to export metadata from. 2. Select a dataset to view its details. 3. Locate the Export Metadata In section and select your preferred format (RDF, TTL, or JSON-LD). In this example, we select JSON-LD: 4. Select Download to save the metadata file to your device.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/faq",
      "url": "/gdi-userportal-frontend/user-guide/faq",
      "title": "faq",
      "content": "Frequently Asked Questions For additional questions or support, please contact our support team. Do I need an account to access GDI Portal? You do not need an account to access the GDI Portal and browse dataset information. However, you need to sign in to your account to request access to the dataset records. Signing in also enables additional features such as saving searches and receiving notifications. I found a dataset I want to use. What do I do? First, you need to submit an application to access the said data. You might be asked to provide additional information such as your research purpose, institutional affiliation, and ethics approval documentation. The portal will guide you through these requirements when you apply. Once your application is approved, you will receive instructions on how to download the data. How long does it take to get approval to access data? Approval times vary depending on the dataset, the requirements you provide, and the complexity of your request. The portal will connect you with the Data Access Committee who manage the approval process. Can I access data from multiple countries? Yes, the GDI Portal enables cross-border access to genomic data across European countries through its federated network approach.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/add-participants",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/add-participants",
      "title": "add participants",
      "content": "Add participants to your application Add participants to collaborate with team members or colleagues on your dataset access request. You can invite multiple participants to help complete the application, upload required documents, and stay informed about the request status. You can add participants to draft and submitted applications. Participants can: - View the application details and requirements - Submit requirements such as forms and documents - Submit draft applications for review - Receive status updates via email To add participants to your application: 1. Select the folder icon () on your dashboard. 2. Select the Applications tab on your dashboard, and select your draft or submitted application. 3. Select Add Participant on the application details page. 4. Enter the name and email address you want to invite and select Send. Do this for each participant you want to add. :::tip Well done After participants accept your invitation, they can access the application from their dashboard and continue the application process.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/apply-for-access",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/apply-for-access",
      "title": "apply for access",
      "content": "Apply for access to datasets Access datasets you find in the GDI Portal. Depending on the dataset type, you can either submit an application through the portal for GDI datasets, or be redirected to external sources for externally governed datasets. To apply for access to datasets: 1. Browse or search for datasets you want to access. 2. Select Add to basket on each dataset you want to access. You can add datasets directly from the search results: Or you can add the dataset from the dataset details page: :::info External datasets Some datasets may be managed by an external organisation. These datasets have an label and cannot be added to the basket. To request access, select Access External Dataset and follow the link to the external source. ::: 3. When you're ready to check out, select the Basket icon (). The Basket page opens with the list of datasets you selected. 4. Review your list of datasets and select Request now to create an application. The application form opens. 5. Submit the requirements to access the dataset. This can include filling out forms and uploading documents, depending on the dataset. Here's an example of requirements including document uploads: 6. (Optional) Need help with your application? Select Add Participant for collaborators to access your application, submit requirements, and continue your application. 7. Review the Terms & Conditions and select Accept All to agree to the terms. 8. Select Submit to complete your application. You will receive email notifications for status updates and if additional documentation is required. :::tip Continue later If you need more time, you can close or navigate away from the application page. The system automatically saves your progress as draft, and you or your collaborators can continue later. :::",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/continue-an-application",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/continue-an-application",
      "title": "continue an application",
      "content": "Continue an application Continue working on applications that you or other collaborators have started earlier. All incomplete applications are saved as draft. To continue a draft application: 1. Select the folder icon () on your dashboard. 2. Select the APPLICATIONS tab. The page lists applications, indicating their status. In this example, you have one application and one application: 3. Select the draft application you want to complete. 4. Complete the application form by providing all required information or uploading necessary documentation. 5. Review the Terms & Conditions and select Accept All to agree to the terms. 6. Select Submit to submit your completed application. You will receive a confirmation email and be notified of status updates. Or to save and continue later, simply navigate away from the page. The system saves your last completed input.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/download-datasets",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/download-datasets",
      "title": "download datasets",
      "content": "Download datasets Once your application is approved, you'll receive an email with instructions to access the Secure Processing Environment (SPE) where you can securely download and work with your approved datasets. To access and work with your approved datasets: 1. Check your email for instructions and access links to the Secure Processing Environment (SPE). 2. Follow the instructions provided in the email to securely access the SPE. 3. Download and work with your approved datasets within the SPE. :::info Stay compliant All data are protected by governance frameworks and data access policies to ensure ethical and legal use. Remember to use data responsibly and according to the terms and agreements you signed during the application process. ::: View approved datasets in the portal You can also view your approved datasets directly in the GDI Portal to see their metadata and details. To view your approved datasets: 1. Select the folder icon () on your dashboard. 2. Select the Entitlements tab to see the list of your approved datasets. 3. Select the dataset to view its details. This view only displays the metadata of your approved datasets. To download and work with the datasets, use the Secure Processing Environment (SPE) as instructed in your approval email.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/track-application",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/track-application",
      "title": "track application",
      "content": "Track your application After submitting your application, track its progress and check for any status updates or additional requirements from the Data Access Committee. To track your application: 1. Select the folder icon () on your dashboard. 2. Select the APPLICATIONS tab. The page displays all your applications with their current status, sorted by last modified date: In this example, there is one application and one application: 3. Review your application status. Applications can have the following statuses: - DRAFT: Application is incomplete and has not been submitted yet. Continue the application. - SUBMITTED: Application is under review by the Data Access Committee. - RETURNED: Application requires additional information or documents. View the feedback and continue the application. - APPROVED: Application has been approved and you can access the datasets. Download the datasets. - REJECTED: Application has been declined. Select the application to view feedback. To resubmit, create a new application. - CLOSED: Application is closed and no further action is required. Open the application to view details.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/sign-in",
      "url": "/gdi-userportal-frontend/user-guide/sign-in",
      "title": "sign in",
      "content": "Sign in Signing in allows you to access enhanced features and request access to datasets. While you can browse datasets without an account, signing in allows you to: - Submit applications to request access to datasets. - Enhance your search with additional filters and more comprehensive search results. - See more dataset information including and other metadata to help assess if datasets meet your research needs. The GDI Portal uses your existing accounts with other platforms like Google, LinkedIn, and organisations like universities or research institutions, so you don't need to create a separate account. To sign in to the GDI Portal: 1. Open the GDI Portal in your browser: https://portal.dev.gdi.lu/. 2. Select Login at the top right corner of the page. The login page opens. 3. Select LSAAI as your sign-in method. :::info Why LSAAI? GDI Portal requires you to sign in with LSAAI (Login Service for Academic and Administrative Institutions). LSAAI is a secure login system that lets you use your existing accounts like Google, LinkedIn, university, or other institutional accounts. This means you don't need to create a new account specifically for the GDI Portal. ::: 4. Select your account provider: Search for your institution in the search bar, or select from the list of options (LinkedIn, Apple, Google, ORCID, GitHub). 5. Follow the instructions to sign in with your selected account. If it's your first time signing in, you may need to verify your email address. 6. After you sign in, the GDI Portal home page loads and you can start exploring datasets.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/welcome-data-users",
      "url": "/gdi-userportal-frontend/user-guide/welcome-data-users",
      "title": "welcome data users",
      "content": "Welcome to the GDI Data Portal Welcome to the GDI Data Portal user guide! The GDI Data Portal gives you access to Europe's largest network of genomic datasets for your research and analysis needs. As part of the 1+ Million Genomes Initiative, this portal enables federated and secure cross-border access to high-quality genomic data and related phenotypic information across European countries. This guide is for data users—healthcare researchers, policy-makers, and professionals—who want to discover and request access to genomic datasets for research and clinical purposes. Learn more about Genomic Data Infrastructure (GDI) and its founding initiatives. Access genomic datasets in three steps 1. Explore datasets: Browse and search through detailed dataset information—search by any criteria such as keywords, research topics, disease areas, or allele frequency. 2. Request access: Found a dataset you want to use? Submit an application to access it. You may need to provide documentation or requirements for your request, and you can invite collaborators to assist you with your application. 3. Access approved datasets: Once your request is approved, you will receive an email with a link to the Secure Processing Environment (SPE) where you can securely download and work with the datasets. :::info Stay compliant All data are protected by governance frameworks and data access policies to ensure ethical and legal use. Remember to use data responsibly and according to the terms and agreements you signed during the application process. :::",
      "guide": "user-guide"
    }
  ],
  "catalogue-managers-guide": [
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/about-harvesting",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/about-harvesting",
      "title": "about harvesting",
      "content": "About dataset harvesting Dataset harvesting allows you to import and synchronise datasets from external data sources automatically by connecting them to your GDI Data Catalogue. When the source updates, your catalogue synchronises the changes. Use harvesting when you need to: - Collect datasets from partner organisations or multiple European data portals - Stay synchronised with external data repositories - Reduce manual data entry and maintenance effort What gets harvested: - Dataset metadata (titles, descriptions, keywords) - Resource links (URLs to data files) - Contact information and licences - Update timestamps and versioning information Harvesting workflow The diagram below shows how data flows from external sources through the GDI Data Catalogue to the public-facing GDI Data Portal: Supported source types The GDI Data Catalogue can harvest from: - FAIR Data Points: Research data repositories that follow FAIR principles - DCAT-AP endpoints: European data portals using the DCAT-AP standard - CKAN catalogues: Other CKAN instances operated by partner organisations Learn how to add harvest sources → How harvesting works - Initial setup: Connect your data source by configuring a harvest source in the catalogue. You specify the source URL, type, and authentication details. - First harvest: The harvester performs an initial import of all datasets from the source into your catalogue. The initial import starts automatically at the next quarter-hour boundary (:00, :15, :30, or :45). For example, if you set up the source at 10:31, the first harvest starts at 10:45. - Scheduled harvests: After the first harvest completes, the harvester runs automatically on a daily schedule at the same quarter-hour boundary. This ensures consistent, predictable harvest timing for monitoring and troubleshooting. Following the same example above, subsequent harvests would occur daily at 10:45. - Change detection: During each scheduled harvest, the harvester compares the source data with the existing datasets. - New datasets from the source are added to your catalogue - Updated datasets are refreshed with current metadata - Datasets deleted at the source are removed from your catalogue - All changes are logged for review - Publication to Data Portal: Public harvested datasets appear in the GDI Data Portal↗ after import to the catalogue. Private datasets remain visible only to members of your organisation.",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/add-harvest-sources/ckan",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/add-harvest-sources/ckan",
      "title": "ckan",
      "content": "Harvest from CKAN catalogues Synchronise datasets from other CKAN catalogues to enable cross-institutional collaboration and maintain distributed dataset collections. :::tip CKAN-to-CKAN harvesting The GDI Data Catalogue is powered by CKAN. CKAN-to-CKAN harvesting is implemented in the core system, making it straightforward to harvest from other CKAN instances. ::: Configure the CKAN source When adding a harvest source, use these settings for CKAN catalogues: | Field | Description | |-------|-------------| | Source type | Select CKAN from the dropdown | | URL | Enter the CKAN instance API endpoint URL | | Configuration | Leave empty unless specific filters are required | Next steps - Test harvest sources - Monitor harvest sources - Manage harvest sources",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/add-harvest-sources/dcat-ap",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/add-harvest-sources/dcat-ap",
      "title": "dcat ap",
      "content": "Harvest from DCAT-AP endpoints Connect to European data portals using the DCAT-AP standard to import standardised public sector datasets. :::tip What is DCAT-AP? Data Catalog Vocabulary-Application Profile (DCAT-AP) is a European standard for describing public sector data catalogues. Many European national and regional portals use DCAT-AP to expose their metadata. ::: Configure the DCAT-AP source :::info Prerequisites The extension must be added to the CKAN plugins for this harvester to be available. Additionally, ensure the CKAN.ini file contains: - (space-separated list of profiles) - ::: When adding a harvest source, use these settings for DCAT-AP endpoints: | Field | Description | |-------|-------------| | URL | Enter the DCAT-AP endpoint URL. Examples:• • | | Source type | Select Generic DCAT RDF Harvester from the dropdown | | Configuration | Enter: Note: Set to match your file format:• for .ttl files• for .rdf/.xml files | :::tip Troubleshooting MIME types To harvest data sources, the system looks at MIME types: - For turtle format files (.ttl): - For RDF/XML files (.rdf): If you're experiencing harvesting issues, verify the in your configuration matches your file type. ::: Next steps - Test harvest sources - Monitor harvest sources - Manage harvest sources",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/add-harvest-sources/fair-data-points",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/add-harvest-sources/fair-data-points",
      "title": "fair data points",
      "content": "Harvest from FAIR data points Connect to FAIR Data Points to import scientific datasets that follow FAIR principles (Findable, Accessible, Interoperable, Reusable). :::tip What are FAIR Data Points? FAIR Data Points are standardised metadata endpoints for scientific data that ensure data can be easily found and reused by researchers. Learn more about FAIR principles↗. ::: Configure the FAIR data point source :::info Prerequisite The extension must be added to the CKAN plugins for this harvester to be available. ::: When adding a harvest source, use these settings for FAIR data points: | Field | Description | |-------|-------------| | URL | Enter the FAIR Data Point base URL. Example: | | Source type | Select FAIR data point harvester from the dropdown | | Configuration | Enter: | :::tip Known Behaviour If a dataset is moved in FDP from one catalogue to another catalogue (by updating reference on the dataset level), it will be considered a new one because a guid of CKAN harvested resource (unlike FDP itself) includes a catalogue ID. ::: Next steps - Test harvest sources - Monitor harvest sources - Manage harvest sources",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/add-harvest-sources",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/add-harvest-sources",
      "title": "index",
      "content": "Add harvest sources Connect external data sources to automatically import and synchronise datasets into your GDI Data Catalogue. The process is the same for all source types—only the configuration differs. In this guide > Identify your source type > Add a harvest source > Configure source settings Identify your source type The GDI Data Catalogue supports three harvest source types: - FAIR data points: Import from research data repositories following FAIR principles. Example: Health-RI↗ - Generic DCAT RDF: Import from European public sector data portals. Example: OpenData.swiss↗ - CKAN catalogue: Import from partner CKAN instances. Example: Partner institution catalogues, regional data hubs Add a harvest source 1. Go to Harvest Sources and select Add Harvest Source. 2. Fill out the harvest source form based on the source type you are connecting to. | Field | Description | |-------|-------------| | URL | The source endpoint URL. See the URL formats for different sources in the source-specific pages | | Title | A descriptive name for this harvest source | | Name | A unique URL-friendly identifier for this source. This becomes part of the harvest source's URL path.| | Source type | The appropriate harvester for your source. See the source-specific configuration for your source type.| | Update frequency | How often the harvest runs:• Manual: You must click Reharvest each time• Daily: Runs at the end of each day• Weekly: Runs at the end of each week• Biweekly: Runs every two weeks• Monthly: Runs at the end of each month• Always: Runs continuously| | Configuration | Enter the source-specific configurations | | Organisation | The organisation that will own the imported datasets | 3. Select Save to create the harvest source. :::tip Manual harvest Use manual harvest to test new configuration changes, import urgent dataset updates, or verify the harvest after fixing an issue. ::: Configure source settings Select your source type for detailed configuration instructions: - FAIR data points: Research data repositories following FAIR principles - DCAT-AP endpoints: European data portals using DCAT-AP standard - CKAN catalogues: Partner CKAN instances",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/check-your-permissions",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/check-your-permissions",
      "title": "check your permissions",
      "content": "Check your permissions Your permissions in the GDI Data Catalogue depend on two levels of roles: platform-level and organisation-level. In this guide > Platform-level roles > Organisation-level roles Platform-level roles Your platform-level role determines your baseline permissions across the entire GDI Data Catalogue. This role is assigned to you by the Sysadmin and applies to all organisations you belong to. To check: Log in to see your access to management features. You can identify your platform-level role by the features available to you in the top navigation bar. Here's an example screenshot of the navigation bar for a sysadmin with access to all management features: Platform-level permissions | Role | Permissions | Limitations | |------|-------------|-------------| | Visitor (not signed in) | Search and view:• Datasets• Organisations• Groups (dataset groups) | • Cannot access private datasets• Cannot join organisations or manage content• Cannot create any resources | | Registered user | Manage based on organisation-level role:• Organisations• Datasets• Groups (dataset groups) | Depends on organisation-level role | | Sysadmin | Manage all:• Organisations• Datasets• Groups• Harvest sources• Users | None | :::tip Need more access? Contact your Sysadmin to upgrade your platform-level role or to adjust your organisation memberships. ::: Organisation-level roles After verifying your platform-level role, check your permissions within each organisation you belong to. You may have different roles in different organisations. To check: 1. Select your name on the top right corner of the page. 2. Select Organisations, then select the name of an organisation you belong to. 3. On the organisation page, select the Members tab to see your role in that organisation. Organisation-level permissions Your organisation-level role determines what you can do within each specific organisation. | Role | Permissions | Key capabilities | |------|-------------|------------------| | Member | • View private datasets in the organisation• Request elevated permissions | Read-only access to organisation datasets | | Editor | • All member permissions• Create new datasets• Edit any dataset in the organisation• Delete datasets• Set dataset visibility (public/private) | Full dataset management within the organisation | | Admin | • All editor permissions• Invite users to the organisation• Assign and change user roles• Remove users from the organisation• Update organisation settings (title, description, image)• Delete the organisation | Complete control over organisation and its members | :::info Organisation admins Organisation Admins can manage other Admins, including changing their roles or removing them from the organisation. To request more permissions, contact your organisation Admin. ::: :::tip Full documentation For detailed technical information about how permissions work, see the CKAN authorisation documentation↗. CKAN is the system that powers the GDI Catalogue Portal. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/log-in",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/log-in",
      "title": "log in",
      "content": "Login to the GDI Data Catalogue Access the GDI Dataset Catalogue to manage your organisation's genomic datasets. You need an active account with appropriate permissions to perform catalogue management tasks. To log in: 1. Open the Dataset Catalogue at https://catalogue.portal.gdi.lu 2. Select Log in in the top-right corner of the page. 3. Select LSAAI as your sign-in method. 4. Select your account provider: Search for your institution in the search bar, or select from the list of options (LinkedIn, Apple, Google, ORCID, GitHub). 5. Follow the instructions to sign in with your selected account. If it's your first time signing in, you may need to verify your email address. After you sign in, the Catalogue Portal homepage opens and you can start managing datasets.",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually/add-datasets",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually/add-datasets",
      "title": "add datasets",
      "content": "Add datasets Add individual datasets directly in your catalogue when automated harvesting isn't suitable for your use case. :::tip Full documentation This guide covers the common tasks for managing datasets. For a complete guide to all dataset operations, see the CKAN documentation↗. CKAN is the system that powers the GDI Catalogue Portal. ::: To manually add a dataset: 1. Go to Datasets and select Add Dataset. 2. Fill out the dataset form with the metadata of your genomic dataset. For guidance on filling out the form, see the definition of properties in the DCAT-AP Vocabulary↗. :::tip Setting the dataset visibility - Private datasets will be visible to users within your organisation in the Data Catalogue. - Public datasets will be discoverable by all users in the GDI Data Portal↗. ::: 3. Select Next: Add Data to add a data resource. You must add at least one data resource to create your dataset. See: Add data resources for guidance on filling out the data resource form. 4. Select Finish to add your dataset. After your dataset is successfully created, the dataset details page opens.",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually/add-resources",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually/add-resources",
      "title": "add resources",
      "content": "Add data resources A data resource represents the actual data described by your dataset. It can be a file, a link to an external data source, or an API endpoint. Adding data resources makes your dataset actionable and allows users to access the underlying data. In this guide > Add a data resource > Reorder data resources :::tip Full documentation This guide covers the common tasks for managing datasets. For a complete guide to all dataset operations, see the CKAN documentation↗. CKAN is the system that powers the GDI Catalogue Portal. ::: Add a data resource To add a data resource to your dataset: 1. Open the dataset you want to add a data resource to. 2. On the dataset details page, select Manage. 3. On the left panel under Resources, select Add new resource. 4. Fill out the data resource form. For guidance on filling out the form, see the definition of properties in the DCAT-AP Vocabulary. 5. Select Update Dataset to save the data resource. Once the data resource is added, it appears in the list of data resources for the dataset. Repeat the steps to add more data resources as needed. Reorder data resources Reorder data resources to prioritise the most important or frequently accessed files or links. The order of data resources determines their display sequence on the Data Portal and dataset details page. To reorder data resources: 1. On the dataset details page, select Manage. 2. Select the Resources tab. The list of data resources appears. 3. Drag and drop the data resources to reorder them as desired. 4. Select Save order. The data resources are reordered and displayed in the new sequence on the dataset details page and the Data Portal.",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually/delete-datasets",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually/delete-datasets",
      "title": "delete datasets",
      "content": "Delete datasets Permanently remove datasets that are obsolete or no longer needed. Before you proceed, ensure there are no dependencies on the dataset or consider changing visibility from public to private. In this guide > Delete a dataset > What happens when you delete a dataset :::tip Full documentation This guide covers the common tasks for managing datasets. For a complete guide to all dataset operations, see the CKAN documentation↗. CKAN is the system that powers the GDI Catalogue Portal. ::: Delete a dataset To delete a dataset from the catalogue: 1. Go to Datasets from the main menu and open the dataset you want to delete. 2. On the dataset details page, select Manage. 3. Scroll to the bottom panel and select Delete. 4. Select Confirm to permanently delete the dataset. :::danger Permanent action Deleting a dataset cannot be undone. The dataset record and all associated data resources are permanently removed from the catalogue with no recovery option. ::: What happens when you delete a dataset When you delete a dataset, the following occurs: - The dataset metadata and all associated information are permanently deleted - The dataset is removed from the GDI Data Portal↗ - Any users or applications with access permissions lose access to the dataset - Links to the dataset from external sources or documentation will no longer work :::info Data files not affected Deleting a dataset record from the catalogue does not delete the actual data files stored in your organisation's repositories or storage systems. It only removes the metadata record from the GDI catalogue. ::: :::warning Harvested datasets If the dataset you deleted was harvested from an external source, it may be re-created during the next harvest. To permanently remove a harvested dataset remove it from the source system. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually",
      "title": "index",
      "content": "Manage datasets manually Add and manage individual datasets directly in your catalogue when automated harvesting isn't suitable for your use case. Manage datasets manually for: - One-off datasets: Single datasets that don't require ongoing synchronisation - Test datasets: Creating sample data for testing or demonstration purposes - Internal datasets: Organisation-specific data not available from external sources - Special cases: Datasets requiring custom metadata or unique handling :::tip Use harvesting for automation Manual dataset management is for exceptions. For regular updates, bulk imports, or external sources, use automated harvesting to reduce effort and keep your catalogue current. ::: Select an operation to get started: - Add datasets - Create new dataset records with metadata - Add data resources - Add files or links to your datasets - Delete datasets - Permanently remove datasets from your catalogue - Manage dataset groups - Organise datasets into discoverable groups :::tip Complete dataset management For a comprehensive guide to all dataset operations including editing, updating resources, and advanced features, see the CKAN documentation↗. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually/manage-groups",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually/manage-groups",
      "title": "manage groups",
      "content": "Manage dataset groups Organise and categorise related datasets together, making them easier to discover and manage. Groups can contain any combination of harvested or manually created datasets. In this guide > Create a dataset group > Add datasets to a group > Remove datasets from a group > Manage group properties > Delete a dataset group :::tip Full documentation For a complete guide to groups, see the CKAN documentation↗. CKAN is the system that powers the GDI Catalogue Portal. ::: Create a dataset group 1. Go to Groups from the main navigation. 2. Select Add Group. 3. Fill in the group details: - Name: Enter a descriptive name for the group - Description: Explain what types of datasets this group contains - Image URL: (Optional) Add an image to represent the group 4. Select Create Group. Add datasets to a group 1. Navigate to the dataset you want to add to a group. 2. Select Manage → Groups. 3. Select the groups you want to add this dataset to. 4. Select Update Groups to save your changes. :::tip Multiple groups You can add a dataset to multiple groups to improve discoverability across different categorisations. ::: Remove datasets from a group 1. Navigate to the dataset you want to remove from a group. 2. Select Manage → Groups. 3. Deselect the groups you want to remove this dataset from. 4. Select Update Groups to save your changes. Manage group properties 1. Go to Groups from the main navigation. 2. Select the group you want to edit. 3. Select Manage to edit the group details. 4. Update the name, description, or image as needed. 5. Select Update Group to save your changes. Delete a dataset group 1. Go to Groups from the main navigation. 2. Select the group you want to delete. 3. Select Manage → Delete. 4. Confirm the deletion. :::info Datasets are not affected Deleting a group does not delete the datasets within it. The datasets remain in the catalogue and can be added to other groups. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-harvest-sources",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-harvest-sources",
      "title": "manage harvest sources",
      "content": "Manage harvest sources Edit, trigger, and delete harvest sources to maintain accurate synchronisation with external data repositories. In this guide > Edit a harvest source > Trigger a manual harvest > Delete a harvest source Edit a harvest source Update your harvest source configuration when URLs change, credentials expire, or harvest settings need adjustment. 1. Go to Harvest Sources. 2. Select the harvest source you want to edit. 3. Select Admin, and then Edit. 4. Update the configuration, and select Save. 5. (Optionally) Select Reharvest to apply changes immediately. :::tip CONFIGURATION CHANGES Changes take effect immediately for the next scheduled harvest. Any currently running harvest job continues with the old configuration. ::: Trigger a manual harvest Run a harvest immediately without waiting for the scheduled time. 1. Go to Harvest Sources. 2. Select your harvest source. 3. Select Admin, and then Reharvest. 4. Monitor progress in the Jobs tab. Delete a harvest source Permanently remove a harvest source configuration when you no longer need automatic synchronisation. 1. Go to Harvest Sources. 2. Select the harvest source you want to delete. 3. Select Admin, and then Edit. 4. Select Delete at the bottom of the form. 5. Select Delete source or Delete and clear source, and then confirm the deletion. :::info HARVESTED DATASETS REMAIN Deleting a harvest source does not delete the harvested datasets. They remain in your catalogue but will no longer synchronise automatically with the source. ::: What happens after deletion: - The harvest source configuration is permanently removed - Scheduled harvests stop - Harvested datasets remain in your catalogue as regular datasets - You can edit datasets manually without synchronisation conflicts :::info Re-adding the same source Datasets will be considered \"new\" if you configure a harvester source, delete it, and re-add it. ::: :::note Known Deletion Behaviour If deletion fails during the , the dataset becomes permanently hidden in the database and cannot be removed by subsequent harvests. ::: :::tip Editing harvested datasets Manual edits to harvested datasets are overwritten during the next harvest run. For permanent changes, consider requesting the source administrators to update metadata at the original system. Changes will synchronise automatically. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-organisations/create-organisation",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-organisations/create-organisation",
      "title": "create organisation",
      "content": "Create organisation Set up a new organisation to group your institution's datasets and manage team access. Create an organisation when: - Your institution is joining the GDI Data Catalogue for the first time. - You need to separate datasets by department or project team. - You want to control access to datasets within your institution. To create an organisation: 1. Go to Organizations and select Add Organization. 2. Fill out the organization form: - Name: Use your institution's official name for consistency across the GDI ecosystem - URL: Auto-generated from the organization name. Select edit to customise it - Description: Describe your institution and its role in genomic data management - Image URL: Link to an optional logo for your organization 3. Select Create Organization to save your organization. After your organisation is created, the organisation details page opens and you can start adding members and datasets. Next step Manage members to invite your team and assign roles.",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-organisations",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-organisations",
      "title": "index",
      "content": "Manage organisations Control access to your institution's datasets by setting up organisations and managing team permissions. Organisations represent institutions or teams that publish datasets in the GDI Data Catalogue. All datasets must belong to an organisation. Organisations allow you to: - Group datasets by institutional ownership - Control who can view, edit, or manage your datasets - Assign role-based permissions to team members - Maintain institutional branding and identity Select a task to get started: - Create organisation: Set up a new organisation for your institution - Manage members: Add members, assign roles, or remove members :::tip Full documentation For a complete guide to organisations and advanced features, see the CKAN documentation↗. CKAN is the system that powers the GDI Catalogue Portal. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-organisations/manage-members",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-organisations/manage-members",
      "title": "manage members",
      "content": "Manage members Invite team members to your organisation and control their access by assigning roles or removing members. In this guide > Add members > Edit member role > Remove member :::tip Full documentation For a complete guide to organisation management, see the CKAN documentation↗. CKAN is the system that powers the GDI Catalogue Portal. ::: Add members Invite team members to your organisation and assign roles to control their access permissions. 1. Go to Organizations and select your organization from the list. 2. Select Manage and then Members. 3. Select Add Member. 4. The next steps depend on whether the member already has an account in the GDI Data Catalogue: - For existing users: Select their username under Existing User. - For new users: Enter their email address under New User to send them an invitation. Then, come back to this step after they create their account. 5. Enter the member's username and select their role: - Admin: Full control over organization and all datasets - Editor: Can add and edit datasets - Member: Can view private datasets 6. Select Add to save the member. Repeat the steps above to add more team members as needed. Edit member role Change a team member's role to adjust their access permissions. 1. Go to Organizations and select your organization from the list. 2. Select Manage and then Members. 3. Find the member whose role you want to change. 4. Select the Role dropdown next to their name and choose the new role: - Admin: Full control over organization and all datasets - Editor: Can add and edit datasets - Member: Can view private datasets 5. The role change takes effect immediately. :::info Understanding roles See User roles and permissions for detailed information about what each role can do. Role changes are immediate—the member's access is updated as soon as you change their role. ::: Remove member Remove team members who no longer need access to your organisation's datasets. 1. Go to Organizations and select your organization from the list. 2. Select Manage and then Members. 3. Find the member you want to remove. 4. Select the Delete (x) icon next to their name. 5. Confirm the deletion when prompted. :::warning What happens when you remove a member - The member loses access to all private datasets in your organisation - The member can no longer edit or manage datasets in your organisation - The member's user account remains active in the catalogue - The member can still be added to other organisations ::: :::danger Removing organisation admins When removing an organisation admin, ensure at least one other admin remains to manage the organisation. If you remove all admins, you'll need to contact a system administrator to regain access. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/monitor-harvest-sources",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/monitor-harvest-sources",
      "title": "monitor harvest sources",
      "content": "Monitor harvesting Track harvesting health at both system and job levels. In this guide > Monitor background processes > Monitor harvest jobs Monitor background processes When to check: If harvests aren't running as expected. Three background processes must run continuously for harvesting to work: - : Manages the gathering of data sources to be harvested - : Responsible for fetching the data from the sources identified by the gather process - : Responsible for triggering the harvester at the end of each specified time interval To check process status: 1. Access the CKAN container: 2. Check all processes: 3. Verify output: All three processes should show status. If any process is not running correctly, see Manage harvest sources. Monitor harvest jobs When to check: If you want to review harvest history and results. 1. Go to Harvest Sources and select your source. 2. Select the Jobs tab to view: - Harvest history with timestamps - Job status - Number of datasets added, updated, deleted, and not modified - Error messages and logs 3. Select a specific job to view detailed logs and troubleshooting information.",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/test-harvest-sources",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/test-harvest-sources",
      "title": "test harvest sources",
      "content": "Test harvest sources Verify your harvest source configuration is working correctly before relying on automated schedules. To test a harvest source: 1. Access the CKAN container: 2. Run the test command: Where is the last part of the harvest source URL 3. Check for success. If successful, you'll see datasets uploaded in the catalogue. :::tip Manual triggering After you configure the manual harvester, you can trigger it by clicking Reharvest in the job's Admin section. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/welcome",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/welcome",
      "title": "welcome",
      "content": "Welcome to the GDI Data Catalogue Welcome to the GDI Data Catalogue user guide! The GDI Data Catalogue is the central management system for Europe's genomic dataset network. As part of the 1+ Million Genomes Initiative, this catalogue serves as the source for dataset information that users can access through the public-facing GDI Data Portal↗. This guide is for catalogue managers—data stewards, repository administrators, and data managers—who are responsible for publishing, curating, and managing genomic datasets within the GDI ecosystem. Learn more about Genomic Data Infrastructure (GDI) and its founding initiatives. Manage datasets in two ways - Harvest datasets automatically: Set up automated harvesting from external sources like FAIR Data Points, DCAT-AP endpoints, or other CKAN catalogues to synchronise datasets continuously. - Manage datasets manually: Create and update individual datasets through the catalogue interface—add detailed metadata, upload resources, and ensure data quality standards are met. :::info Datasets flow to the Data Portal All datasets you manage in this Data Catalogue are displayed in the public-facing GDI Data Portal↗, making them discoverable to researchers across Europe. Your work ensures high-quality genomic data is available for research and clinical purposes. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/what-is-a-dataset",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/what-is-a-dataset",
      "title": "what is a dataset",
      "content": "What is a dataset? In GDI, a dataset is a structured collection of genomic information pertaining to human health, diseases, and research studies. A dataset can be a single file or a collection of files that provide comprehensive information about a specific research topic, disease area, or study cohort. For example, a genomic data for _COVID-19 Viral Sequences_ can include dataset records describing _patient data_, _virus samples_, and _sequencing results_. When you add a dataset to the GDI Data Catalogue, you provide two types of information that together give a complete picture of the genomic subject: metadata describes the dataset itself, and data resources are the actual genomic data files associated with the dataset. Metadata Metadata (displayed as Additional Info in the portal) are descriptive details about your genomic dataset that provide context and information about the dataset itself. It includes details pertaining to: - Identification: Title, description, keywords, and unique identifiers - Responsibility: Contact points, publisher, creator, and data steward information - Access information: Rights, availability, licensing, and access restrictions - Others: Other key information that allows users to locate and access the data. Data resources Data resources pertain to the actual genomic data files associated with a dataset. In GDI, you can upload the file or provide links to external data resources. GDI supports common genomic data file formats, including: - VCF (Variant Call Format): For storing gene sequence variations - FASTA/FASTQ: For storing raw sequence reads - BAM/CRAM: For storing aligned sequence data - CSV/TSV: For storing tabular data such as phenotypic :::tip Organising datasets Datasets in GDI can be organised in several ways—such as by organisation and groups—to help you manage data effectively, while making it easy for researchers to find relevant datasets. ::: What's next: Add a dataset",
      "guide": "catalogue-managers-guide"
    }
  ],
  "system-admin-guide": [
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/about-gdi",
      "url": "/gdi-userportal-frontend/system-admin-guide/about-gdi",
      "title": "About GDI",
      "content": "",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/configure-auth",
      "url": "/gdi-userportal-frontend/system-admin-guide/configure-auth",
      "title": "configure auth",
      "content": "Set up authentication and authorisation The GDI User Portal uses Keycloak for authentication and authorisation, with integration to LS-AAI (Life Science Authentication and Authorisation Infrastructure) for federated access across European research infrastructures. Authentication architecture Keycloak configuration Keycloak serves as the central authentication provider, managing user sessions, roles, and permissions across all platform components. LS-AAI integration Integration with LS-AAI enables users to authenticate using their existing institutional credentials through the European research federation. User role management Configure role-based access control to ensure appropriate permissions for different user types (data users, catalogue managers, system administrators). Configuration tasks Configure Keycloak Set up Keycloak instance with proper realm configuration, client settings, and security policies. Integrate with LS-AAI Configure LS-AAI as an identity provider in Keycloak, including OpenID Connect settings and attribute mapping. Manage user roles Define and manage user roles and permissions to control access to different platform features and data. Identity providers configuration When configuring identity providers (IdPs), you'll need: - ClientSecret - Provided by the IdP during registration - ClientId - Unique identifier for your application - Token URL - OAuth2 token endpoint - Authorisation URL - OAuth2 authorisation endpoint - Redirect URI - Keycloak callback URL Azure AD integration Configure Azure Active Directory as an identity provider for organisational authentication. LS-AAI integration details - Discovery endpoint: - Required scopes: , , , - Sync mode: Import (not force) - Token storage: Enabled for Beacon Network integration Security considerations Token management Proper configuration of token storage and refresh to enable secure API access across services. Access control Implementation of proper access control policies to protect sensitive data and administrative functions. Audit and monitoring Set up logging and monitoring for authentication events and security incidents. :::info content in progress We are working on this guide. :::",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/configure-ls-aai-in-keycloak/keycloak-setup",
      "url": "/gdi-userportal-frontend/system-admin-guide/configure-ls-aai-in-keycloak/keycloak-setup",
      "title": "keycloak setup",
      "content": "Configure LS-AAI in Keycloak Keycloak can be obtained by running the CKAN deployment script that you can find in the following guide: Azure CLI Script Deployment Guide Configuring Identity Providers (IdPs) When configuring identity providers (IdPs), the following information becomes crucial for OpenID setup: - ClientSecret - ClientId - Token URL - Authorization URL - Redirect URI Both the 'Token URL' and 'Authorization URL' are derived from the IdP. When registering a service, you acquire the clientId and secret. The 'Redirect URI', which remains constant, is provided by Keycloak: Additionally, the corresponding configuration entails: - Scopes: \"openid\", \"profile\", \"email\" , \"elixir_id\" - Method: POST the Clientsecret - Sync method: import For Elixer_id additional mapper is needed Azure AD For Azure integration, I followed the tutorial at https://www.youtube.com/watch?v=LYF-NLHD2uQ. This tutorial comprehensively explains both the service registration and the Azure AD setup within Keycloak. Management of the app registration is done within our Ad: portal.zure.com LSAAI To register Keycloak as service I used https://elixir-europe.org/platforms/compute/aai/service-providers. . Initially, obtaining an account is the first step. 1. Make sure your organisation is recognised as IdP and register if not. 2. Submit a registration for you application as a service. Please note that approval for this step may entail a waiting period. Management of the app registration is done within: https://services.aai.lifescience-ri.eu . Discovery endpoint: https://login.elixir-czech.org/oidc/.well-known/openid-configuration The LSAAI configuration looks like: !LSAAI Configuration Part 1 !LSAAI Configuration Part 2 Note 1: Sync mode must be \"import\" instead of \"force\"\\ Note 2: and must be on, to allow User Portal components to get LS-AAI . That enables Beacon Network integration via Oauth2.\\ The first time you log in you will get a question if you want to be a member of the test environment. Agree and proceed. Fetching LS-AAI Access Token from Keycloak Option 1 In order to fetch access token from LS-AAI - or any IdP - one needs to configure Keycloak accordingly, and later request to Keycloak LS-AAI tokens. 1. Go to ; 2. Enable and ; 3. Delete LS-AAI existing users, to ensure users are initialised correctly in Keycloak; 4. Login with a LS-AAI user; 5. Call Keycloak endpoint: Option 2: Configuring OAuth 2.0 in Postman This guide will help you set up OAuth 2.0 authorization for a request in Postman and obtaining the LSAAI token. Steps to Configure OAuth 2.0 1. Open Postman Application Begin by opening the Postman application on your desktop. 2. Select a Request - Choose any existing request from your collections, or create a new one by clicking on the 'New' button and selecting 'Request'. 3. Authorization Setup - Navigate to the 'Authorization' tab within the selected request. 4. Set Authorization Type - From the 'Type' dropdown menu, select 'OAuth 2.0'. 5. Add Authorization Data to Request Headers - In the 'Add authorization data to' dropdown, select 'Request Headers'. 6. Current Token Configuration - For the 'Current Token' section, choose 'Bearer' as the token type. 7. Configure New Token Follow the steps below to configure a new token: - Token Name: Enter a random name for your token. - Grant Type: Select 'Authorization Code' from the dropdown menu. - Authorize Using Browser: Ensure this box is checked to use your default web browser for the authorization. - Auth URL: Replace and with the appropriate values for your Keycloak server and realm. - Access Token URL: Similar to the Auth URL, fill in the Keycloak server and realm information. - Client ID: Enter 'ckan' or the specific client ID you have been provided. - Client Secret: Enter the client secret you obtained from Keycloak that corresponds to your client ID. - Scope: Input the scopes as . - Client Authentication: Select 'Send as Basic Auth header' from the dropdown menu. 8. Obtain Access Token - Click on the 'Get New Access Token' button to initiate the OAuth 2.0 authorization flow. After completing these steps, you should be able to receive an access token that can be used to authorize your requests within Postman, which is containing also an Elixer Id",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/configure-schemas",
      "url": "/gdi-userportal-frontend/system-admin-guide/configure-schemas",
      "title": "configure schemas",
      "content": "Configure metadata schemas Configure and manage CKAN metadata schemas to define dataset fields, validation rules, and data entry forms. This guide covers schema development, deployment, and maintenance for system administrators. Schema structure and format CKAN schemas can be defined as JSON or YAML files that specify dataset metadata fields and their properties. Example field definition Key field properties Configure field behaviour using these properties: - field_name: CKAN field identifier - label: UI field representation for end users - help_text: Explanatory text appearing under field in UI - choices: For dropdown menus - list of dictionaries with value and label - choices_helper: Form dropdowns dynamically from API - presets: Values like , , for automatic checks - form_snippet: Defines field representation for data input (jinja2 format) - display_snippet: Defines how data is shown in UI - validators: Data validation functions - output_validators: Convert complex data structures from database Schema configuration Single schema setup Configure your primary schema in CKAN configuration: Multiple schema support Configure multiple schemas using a declaration file for different dataset types: Reference the multi-schema file in : Schema deployment Update running CKAN instance To change schema in a running Docker container: Changes to trigger automatic CKAN updates. Schema path format Define schemas using the format: Example: Schema management APIs Use CKAN APIs to manage schemas programmatically: Best practices Schema design - Follow DCAT-AP standards for interoperability - Design for user experience, not just technical requirements - Include comprehensive help text for complex fields - Test schemas with real users before deployment Deployment - Test schema changes in development environment first - Document all schema modifications - Consider migration impact on existing datasets - Backup data before major schema updates For comprehensive schema development, see the CKAN scheming documentation. Next steps After configuring schemas: - Manage user roles and permissions - Control access to schema management - Manage data and services - Configure data workflows - Monitor and maintain the system - Track schema usage and performance",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/deploy-infrastructure",
      "url": "/gdi-userportal-frontend/system-admin-guide/deploy-infrastructure",
      "title": "deploy infrastructure",
      "content": "Deploy infrastructure :::info content in progress We are working on this guide. ::: The GDI User Portal consists of multiple interconnected components that require careful deployment and configuration. This section provides comprehensive guidance for system administrators on setting up production-ready infrastructure. Deployment options Deploy to Azure Complete guide for deploying the GDI User Portal on Microsoft Azure infrastructure, including resource provisioning, networking, and security configuration. Deploy to ELIXIR-LU Specific instructions for deploying to ELIXIR Luxembourg infrastructure, tailored for genomic data infrastructure requirements. Configure Docker containers All components run as Docker containers. Learn about container orchestration, networking, and persistent storage configuration. Manage environments Best practices for managing multiple environments (development, staging, production) and environment-specific configuration. Component installation User Portal Frontend The frontend provides the web interface and integrates with backend services. Built with Next.js for optimal performance and user experience. Installation guide: User Portal Frontend README Dataset Discovery Service (DDS) Backend service that mediates between the frontend and CKAN, providing abstraction and enhanced functionality. Installation guide: Dataset Discovery Service README Access Management Service (AMS) Handles access requests, user permissions, and integration with external systems like REMS. Installation guide: Access Management Service README CKAN Extensions The platform uses several custom CKAN extensions that must be properly integrated: - GDI Userportal Ckanext - Core GDI functionality - Fair Datapoint Ckanext - FAIR principles support - Harvest Ckanext - Data harvesting capabilities For extension integration, see the CKAN Docker repository installation guide.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/fdp/fair-data-point",
      "url": "/gdi-userportal-frontend/system-admin-guide/fdp/fair-data-point",
      "title": "fair data point",
      "content": "FAIR data point setup Fair Data Point (FDP) Installation Guide This guide provides steps to install FDP and configure it with GDI-specific SHACL shapes. For a more comprehensive overview, please refer to the existing FDP documentation on exposing metadata. 1. Installing FDP 1. Follow the installation guide in the documentation linked above to set up FDP in your environment. 2. Ensure that the FDP instance is accessible and that you have administrative rights to configure metadata schemas. 2. Installing GDI-Specific SHACLs To add GDI-specific SHACL validation, perform the following steps: Step 1: Download SHACL Shapes - Access the GDI-specific SHACL shapes from this GDI metadata repository. - Download each SHACL shape file (e.g., and others). Step 2: Upload SHACL Shapes to FDP 1. Login to FDP using an admin account. 2. Navigate to Metadata Schemas (located in the dropdown under your username). 3. For each shape file: - Open the editor and paste the contents of (or other shapes). - Add a description to document the purpose or release information. - Ensure the abstract checkbox is selected when uploading , as most other classes derive from it. - For other shapes, uncheck the abstract checkbox. - Press Save and Release to finalize the shape. - Provide a meaningful description and version number for the release. - Check the public checkbox to make the shape accessible. - Press Release to complete the upload. Repeat these steps for each SHACL shape file. 3. Supported Metadata Fields for Datasets The following metadata fields are currently supported: Dataset | Property Name | Example Data | | ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | contact_point | VCard(hasEmail=[mailto:data-access-committee@xumc.nl], full_name=[Data Access Committee of the x UMC], hasUID=https://ror.org/05wg1m734) | | creator | Agent(name=[Academic Medical Center], identifier=https://ror.org/05wg1m734) | | description | This dataset is part of the GDI MS8 milestone, focused on the distributed analysis of COVID-19 cases (GWAS) and allele frequency lookup for infectious diseases. It contains synthetic data designed to replicate COVID-19-related genetic studies, including risk variants associated with severe disease outcomes. The data is used for federated analysis across multiple nodes to identify genomic associations and variant prevalence. | | number_of_patients | 100 | | issued | 2024-07-01T11:11:11 | | keywords | Covid, Smokers, (free to choose) | | identifier | GDID-[0-9a-f]{8}-[0-9a-f]{4} | | modified | 2024-06-04T13:36:10.246Z | | publisher | Agent(name=[Radboud University Medical Center], identifier=https://ror.org/05wg1m734, mbox=[mailto:test@health-ri.nl]) | | theme | http://publications.europa.eu/resource/authority/data-theme/HEAL | | title | COVID-19 GWAS and Allele Frequency Lookup Dataset for GDI MS 8 | | number_of_participant | 100 | | phenotypes | Age (min and max) | | accessRights | DUO:0000006, DUO:0000017, DUO:0000018 (General research use, Infectious Disease research use, Genomic research on complex diseases) | Distribution | Property Name | Example Data | | --------------- | ------------------------------------------------------------------------- | | title | GWAS and Allele Frequency Lookup Data Distribution for GDI MS8 | | description | VCF file containing COVID-19 case/control data for GDI MS8 demonstration. | | access_url | https://example.com/dataset/GDI-MS8-COVID19.vcf | | media_type | https://www.iana.org/assignments/media-types/application/vcf | | license | https://creativecommons.org/licenses/by-sa/4.0/ | 4. Onboarding Metadata To onboard large datasets more efficiently, you can use a Jupyter notebook to automate this process. Clone the Sempyro repository and run the notebook using: As a reference, an MS8 template/example is available in the notebook for streamlined metadata upload to FDP.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/installation/azure",
      "url": "/gdi-userportal-frontend/system-admin-guide/installation/azure",
      "title": "azure",
      "content": "Azure CLI Script Deployment Guide for a Catalogue with CKAN This guide will walk you through the process of deploying an environment using Azure CLI that includes a CKAN container, Frond end catalogue, SOLR for CKAN, Keycloak for authentication, a managed PostgreSQL server, and Redis Cache. This environment is suitable for development purposes, and further security and performance reviews are necessary for production deployment. Prerequisites - Azure CLI installed: Make sure you have Azure CLI installed on your machine. You can install it via Homebrew with the command . - GitHub Personal Access Token (classic): You'll need a personal access token from GitHub with pack read permissions. - Azure Account with Sufficient Permissions: Ensure you have an Azure account with permissions that, at a minimum, allow you to create a resource group. - PSQL installed: Ensure that PSQL is installed (e.g. ) Initial Setup Before running the script, you'll find several parameters at the beginning of the script that can be customized: - Passwords for the CKAN database, Keycloak database, and the PostgreSQL admin. Change these to secure passwords as desired. Deployment Steps 1. Execute the Script: - Navigate to the deployment project at GenomicDataInfrastructure/gdi-userportal-deployment. - Go to the Azure deployment folder - Run to start the deployment process. 2. Enter Required Information: - The script will prompt you to enter the necessary information. Fill in the details as requested. 3. Script Execution: - After entering the information, the script will automatically execute, setting up the environment and deploying the code. It typically takes about 10 minutes for the entire process to complete and for the services to be up and running. 4. Verification: - Once the script execution is complete, verify that all components are online by accessing the following URLs, replacing with your project name and with your environment name: - SOLR: - CKAN: - Catalog: - Keycloak: 5. Import CKAN Realm into Keycloak: - After verifying that all components are online, the next step is to import the CKAN realm into Keycloak. Log in to Keycloak using the admin account to perform this action. (creditials can be found in the script) Components Included - Azure Web App with CKAN Container: Runs a CKAN container from the main branch of the gdi-userportal-ckan-docker repository. - Azure Web App with Front Catalog: Originates from the main branch of the gdi-userportal-frontend repository. - Azure Web App with SOLR for CKAN: Dedicated SOLR instance for CKAN. - Azure Web App with Keycloak: For authentication and authorization. - Managed PostgreSQL Server: Includes a Keycloak database and a CKAN database. - Managed Redis Cache: For caching purposes to enhance performance. Note This setup is intended for development use. Before moving to a production environment, review and adjust the security and performance settings to meet the necessary requirements.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/installation/components",
      "url": "/gdi-userportal-frontend/system-admin-guide/installation/components",
      "title": "components",
      "content": "Installation guides The user portal consists of multiple components. To install or contribute to a specific component, refer to the respective installation guide linked below. All components run on Docker containers, and their individual setups are documented in their respective repositories. Components User Portal Frontend The User Portal Frontend, built with Next.js, provides a web interface for interacting with key services, including the Dataset Discovery Service (DDS) and the Access Management Service (AMS). It acts as the primary user interface for the GDI project. Installation guide: User Portal Frontend README Dataset Discovery Service (DDS) The Dataset Discovery Service acts as a backend layer mediating requests from the frontend to CKAN’s data catalog APIs. It retrieves, processes, and maps dataset information while abstracting CKAN-specific logic. To use DDS, ensure that the GDI CKAN extension is installed in your CKAN instance. Installation guide: Dataset Discovery Service README Access Management Service (AMS) The Access Management Service ensures secure interactions between the frontend and backend data authorities. It provides APIs for managing user access requests and integrates with external APIs like REMS to enforce policies and track user actions. Installation guide: Access Management Service README CKAN Extensions CKAN is an open-source data management system for publishing, sharing, and discovering datasets. It enables cataloging, searching, and accessing data through a web interface and API. Custom extensions can be developed to extend CKAN’s core functionalities. The User Portal uses several extensions, including one specifically developed for this project. Extensions used include (but are not limited to): - GDI Userportal Ckanext: Adds a DCAT-AP 3 compatible schema with fields such as , , , and . It also provides enhanced parsing for creators in the DCAT profile, adds support for OpenID Connect with PKCE, introduces new fields to , and links CKAN harvest views for admin users. Additionally, it offers endpoints for listing unique values and simplifies integration with CKAN-based datasets for the User Portal. - Fair Datapoint Ckanext: Provides features related to FAIR principles to enhance dataset accessibility and interoperability. - Harvest Ckanext: Supports automated data harvesting and integration with external data sources. In order to contribute on a ckan extension and run it on you local machine, it must be integrated into the docker build that will run as your backend service, connected to your DDS instance. For a detailed guide on how to integrate the extention, read 5. installing new extensions from the CKAN Docker repository",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/installation/elixir-lu",
      "url": "/gdi-userportal-frontend/system-admin-guide/installation/elixir-lu",
      "title": "elixir lu",
      "content": "Current deployment - - User Portal - - IAM - - API Gateway - - Catalogue Deployment Steps 1. Checkout . 2. Copy into the server and update all the secrets. 3. Run . 4. Run . 5. Run . 6. Enter in REMS docker container. 7. Configure the admin user. 8. Configure apikey, for any user and any REST method, but limited to . 9. Configure apikey and robot for any REST method, but limited to . 10. Configure apikey and robot, limited to . 11. Include in the environment variables the newly created apikeys and users. 12. Run . 13. Log into CKAN as sysadmin. 14. Add the harvest sources. 15. Wait for REMS Synchronizer or run it manually. 16. Access Keycloak. 17. Configure LS-AAI IdP. 18. Add mapper, that maps the clain clain into . 19. Create a new OIDC realm for GDI, that accepts redirections to User Portal, CKAN and REMS. 20. Create a new client scope for GDI realm. 21. Add new User Attribute Mapper, that maps the attribute into a claim called and a scope called . 22. Create a new client for User Portal, REMS and CKAN. 23. Add the scope into the newly created client.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/manage-data-services",
      "url": "/gdi-userportal-frontend/system-admin-guide/manage-data-services",
      "title": "manage data services",
      "content": "Manage data and services :::info content in progress We are working on this guide. ::: This section covers the administration of core data management services including CKAN administration, FAIR Data Point deployment, harvester configuration, and database management. Data service components Administer CKAN CKAN serves as the core data catalogue system. Learn about user management, organisation setup, dataset administration, and system maintenance. Set up FAIR Data Points FAIR Data Points provide standardised metadata endpoints that support FAIR principles. Configure FDP instances with GDI-specific SHACL shapes and metadata requirements. Configure harvesters Set up automated data harvesting from external sources including other CKAN instances, FAIR Data Points, and DCAT-AP endpoints. Manage databases Maintain database performance, backups, and integrity across PostgreSQL instances used by CKAN and other services. CKAN administration System configuration - Instance configuration and settings - Extension management and updates - Performance tuning and optimisation - Security configuration and updates User and organisation management - User account administration - Organisation setup and management - Permission and role assignment - API key management Data management - Dataset lifecycle management - Metadata quality assurance - Storage and backup procedures - Search index maintenance FAIR Data Point setup Installation and configuration Deploy FDP instances with GDI-specific requirements and configure metadata schemas using SHACL shapes. Metadata schema configuration Install and configure GDI-specific SHACL shapes for consistent metadata representation across the network. Supported metadata fields Comprehensive coverage of dataset and distribution metadata fields including contact points, creators, themes, and access rights. Harvesting configuration Harvester setup - Configure harvest sources and schedules - Set up authentication for protected endpoints - Monitor harvest job performance - Troubleshoot harvest failures Data source integration - FAIR Data Point harvesting - DCAT-AP endpoint harvesting - Custom API integration - Real-time vs. scheduled synchronisation Database management Performance monitoring - Query performance analysis - Index optimisation - Connection pool management - Resource utilisation tracking Backup and recovery - Automated backup procedures - Point-in-time recovery - Disaster recovery planning - Data integrity verification",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/manage-schemas",
      "url": "/gdi-userportal-frontend/system-admin-guide/manage-schemas",
      "title": "manage schemas",
      "content": "Manage schemas :::info content in progress We are working on this guide. ::: Learn how to configure and manage CKAN dataset schemas for the GDI User Portal. This guide covers schema format, field definitions, and deployment procedures. Schema format and field definitions A CKAN schema can be defined either as JSON or YAML file. The GDI User Portal uses JSON schemas for consistency. Field structure A field in CKAN schema JSON file has the following format: Where: - - CKAN field identifier - - UI field representation - - Text appearing under field in UI next to icon. Square brackets contain DCAT-AP mapping information Field configuration options Documentation on field keys and specifications can be found in the CKAN Scheming documentation. Available field keys include: - - For handling cardinality requirements - - Controls field appearance on multi-stage forms - - For dropdown lists (array of dictionaries with value and label) - - For dynamic dropdowns or API-driven choices - - Built-in field types (, , ) - - Custom field representation (Jinja2-based format) - - Custom data display formatting - - Override representation for DCAT mapping Example with display property: Validation configuration - - Data validation functions. Available functions listed in CKAN validators documentation - - Convert complex data structures from database storage back to objects Important: Default validation includes and . When specifying custom validators, include these explicitly if needed. Changing schemas in running instance Schema configuration Schema is defined in setup scripts by setting: Runtime schema changes In running Docker container, schema is configured in : Configuration changes trigger automatic CKAN updates. Schema path format Schema paths follow format: Example: resolves to extension directory structure under Multi-schema configuration Configuration file approach For better maintainability, create a JSON configuration file under extension schemas directory: Multiple dataset types Support for multiple schema types: Configure in : Schema merging behaviour - Core CKAN: Latest schema with same takes precedence - GDI implementation: Schemas with same type are merged, field order follows schema order in configuration - Field merging: Controlled by parameter - : Latest field definitions take precedence - Fields are never deleted, only added or modified - To remove fields, explicitly undeclare or set to empty API management List available schemas Get specific schema Search configuration Control dataset type visibility in search with:",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/manage-user-roles",
      "url": "/gdi-userportal-frontend/system-admin-guide/manage-user-roles",
      "title": "manage user roles",
      "content": "Manage user roles and permissions Configure and manage user access levels within the CKAN data catalogue system. This guide covers platform-wide and organisation-specific role management for system administrators. CKAN user role hierarchy Understanding CKAN user roles is essential for effective system administration. CKAN operates with two levels of roles: Platform-level roles 1. Visitor - Capabilities: Search and view public datasets - Access level: Anonymous/unauthenticated users 2. Registered User - Capabilities: - Become a member of an organisation (requires admin approval) - Publish, edit, or add datasets based on their role in the organisation - Manage their own profile - Configuration note: Creation of organisations is typically disabled for regular users 3. Sysadmin - Capabilities: - Access and edit any organisations - View and change user details - Permanently delete datasets - Customise the look and feel of the platform - Configure system-wide settings Organisation-level roles 1. Member - Capabilities: View the organisation's private datasets - Use case: Users who need access to restricted organisational data 2. Editor - Capabilities: - All capabilities of a Member - Add new datasets to the organisation - Edit or delete any of the organisation's datasets - Make datasets public or private - Use case: Content contributors and data curators 3. Organisation Admin - Capabilities: - All capabilities of an Editor - Add users to the organisation, and set their role (member, editor, or admin) - Change the role of any user in the organisation, including other admin users - Remove members, editors, or other admins from the organisation - Edit the organisation's details (e.g., title, description, image) - Delete the organisation - Use case: Organisational data stewards and managers User management procedures Configure platform roles Use CKAN's admin interface to manage platform-level user permissions and system access. Set up organisation permissions Configure organisation-specific roles and manage member access to datasets within organisational boundaries. Role assignment best practices - Follow principle of least privilege - Regular audit of user permissions - Document role assignments and changes - Implement approval workflows for sensitive roles For detailed role management procedures, see the CKAN authorisation documentation. Activity monitoring and auditing Monitor user activity and dataset changes to maintain data integrity and track catalogue usage. Enable activity streams CKAN displays a full history of dataset changes in the Activity Stream. For new installations, this is enabled by default, but upgrades may need manual activation. To make activity history public, add this to your file: Note: Since CKAN 2.10, Activity must be activated as a plugin. See the CKAN 2.10 changelog for details. Activity monitoring levels Configure activity tracking at different levels: - Organisation level - Track all changes within an organisation - Dataset level - Monitor specific dataset modifications - Difference view - See detailed changes between versions - User activity - Track individual user actions and access patterns Audit configuration For complete activity configuration options, see CKAN activity settings documentation. Next steps After configuring user roles: - Manage data and services - Set up data management workflows - Monitor and maintain the system - Ongoing system maintenance - Deploy and manage infrastructure - Infrastructure management",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/monitor-maintain",
      "url": "/gdi-userportal-frontend/system-admin-guide/monitor-maintain",
      "title": "monitor maintain",
      "content": "Monitor and maintain the system :::info content in progress We are working on this guide. ::: Ongoing monitoring and maintenance are crucial for ensuring the reliability, security, and performance of your GDI User Portal deployment. This section covers monitoring tools, maintenance procedures, and troubleshooting approaches. Monitoring components Monitor performance Track system performance metrics including response times, resource utilisation, and user activity to ensure optimal platform operation. Audit security Implement comprehensive security monitoring including access logging, intrusion detection, and compliance verification. Back up data Establish reliable backup procedures for all critical data including CKAN databases, configuration files, and user data. Publish new versions Manage platform updates and version deployments with minimal downtime and proper rollback procedures. Performance monitoring",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/platform-overview",
      "url": "/gdi-userportal-frontend/system-admin-guide/platform-overview",
      "title": "platform overview",
      "content": "Platform overview :::info content in progress This section will describe architecture, components, and interactions at a high level. ::: The GDI User Portal consists of multiple interconnected components: - User Portal Frontend - Next.js web interface providing the user experience - Dataset Discovery Service (DDS) - Backend API layer mediating frontend-CKAN communication - Access Management Service (AMS) - Access control and data request management - CKAN - Open-source data catalogue management system with custom extensions - Keycloak - Authentication and authorisation service - Supporting services - PostgreSQL, Elasticsearch/Solr, Redis, Docker containers",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/publishing-new-version/release-process",
      "url": "/gdi-userportal-frontend/system-admin-guide/publishing-new-version/release-process",
      "title": "release process",
      "content": "Publishing new versions > All repositories must follow the same process. > Once all necessary changes are merged to , please follow this process: - Ensure is up to date. - Push a new tag following the versioning and releases described in this page. The tag name follows . Example: - Create a new release branch, to simplify bugfixing and security patches. The branch name follows . Example: - Stage the Commit the : Push the branch to the remote repository - Go to GitHub and create a new release, example: - Click on \"Draft a new release\" CHANGELOG - Select the just created release branch and tag. - Enter a title for the release that includes the version and possibly a short description. - Auto-generate release notes. - Remove unnecessary release notes: ensure that only relevant information for the users is included and matches CHANGELOG.md. - Double-check all entered information. - Click on \"Publish release\" to officially make the release. - Ensure docker images were built and published correctly.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/welcome",
      "url": "/gdi-userportal-frontend/system-admin-guide/welcome",
      "title": "welcome",
      "content": "Welcome, system administrators :::info content in progress We are working on this deployment guide. ::: Welcome to the GDI User Portal System Administration Guide! This comprehensive documentation is designed for system administrators responsible for deploying, configuring, and maintaining the GDI User Portal platform and its associated services. Get started Choose your focus area based on your immediate needs: - New deployment? Start with Deploy and manage infrastructure - Setting up users? Begin with Set up authentication and authorisation - Managing access? Go to Manage user roles and permissions - Configuring data? Check out Manage data and services - System health? Explore Monitor and maintain the system This guide provides the technical knowledge you need to successfully deploy and maintain the GDI User Portal platform for the European genomic data research community.",
      "guide": "system-admin-guide"
    }
  ],
  "developer-guide": [
    {
      "id": "/gdi-userportal-frontend/developer-guide/about-gdi",
      "url": "/gdi-userportal-frontend/developer-guide/about-gdi",
      "title": "About GDI",
      "content": "",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/add-data-resource",
      "url": "/gdi-userportal-frontend/developer-guide/add-data-resource",
      "title": "add data resource",
      "content": "Add data resources In this guide > Add a data resource > Reorder data resources :::tip Full documentation This guide covers the common tasks for managing datasets. For detailed instructions on all dataset operations, see the CKAN Dataset Guide↗. CKAN is the system that powers the GDI Data Catalogue. ::: Add a data resource Add more files or links to your dataset to provide comprehensive genomic information. A data resource represents the actual data described by your dataset. New to adding data resources? Learn about data resources and their significance in datasets. To add a data resource to your dataset: 1. Open the dataset you want to add a data resource to. 2. On the dataset details page, select Manage. 3. On the left panel under Resources, select Add new resource. 4. Fill out the data resource form. For guidance on filling out the form, see the definition of properties in the DCAT-AP Vocabulary. 5. Select Update Dataset to save the data resource. Once the data resource is added, it appears in the list of data resources for the dataset. Repeat the steps to add more data resources as needed. Reorder data resources Reorder data resources to prioritise the most important or frequently accessed files or links. The order of data resources determines their display sequence on the Data Portal and dataset details page. To reorder data resources: 1. On the dataset details page, select Manage. 2. Select the Resources tab. The list of data resources appears. 3. Drag and drop the data resources to reorder them as desired. 4. Select Save order. The data resources are reordered and displayed in the new sequence on the dataset details page and the Data Portal.",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/add-modify-features",
      "url": "/gdi-userportal-frontend/developer-guide/add-modify-features",
      "title": "add modify features",
      "content": "Add and modify features :::info content in progress We are working on this guide. ::: This section covers advanced development topics including metadata field management, extension development, and comprehensive testing strategies for adding new features to the GDI User Portal. Feature development overview Adding new features to the GDI User Portal typically involves: 1. Frontend development - User interface and experience 2. Backend integration - API endpoints and data processing 3. Metadata management - Schema updates and field additions 4. Testing - Comprehensive testing across all layers 5. Documentation - User and developer documentation Metadata field management Manage metadata fields Adding, modifying, or deleting metadata fields requires updates across multiple components of the CKAN ecosystem. Process overview When adding new metadata fields, you must update: 1. CKAN DCAT model - Core schema definition 2. Solr search integration - Search indexing 3. FAIR Data Point - SHACL shapes 4. SeMPyRO - Metadata automation 5. Discovery Service - API mapping CKAN DCAT model updates For DCAT-AP 3 compliant fields: Example schema addition: Solr Search Configuration To make fields searchable: After changes, rebuild the search index: FAIR Data Point integration Add SHACL shapes in FDP: SeMPyRO integration Add property to relevant class: Discovery Service mapping Update OpenAPI definitions and mapping: For complete metadata field procedures, see Metadata field management. Extension development Develop extensions CKAN extensions provide powerful capabilities to enhance catalogue functionality. Extension structure Plugin development Custom Validators Template Customization Testing Strategies Write and Run Tests Comprehensive testing ensures feature reliability and maintainability. Frontend Testing API Integration Testing E2E Testing Extension Testing Performance Considerations Optimization Strategies - Database Indexing - Ensure proper indexes for new fields - Caching - Implement appropriate caching for expensive operations - Lazy Loading - Load heavy components only when needed - Bundle Optimization - Minimize JavaScript bundle size Monitoring",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/add-update-metadata-fields/metadata-fields",
      "url": "/gdi-userportal-frontend/developer-guide/add-update-metadata-fields/metadata-fields",
      "title": "metadata fields",
      "content": "Add and update metadata fields :::info content in progress We are working on this guide. ::: This document outlines the steps required to add, modify, or delete fields across various components of the CKAN ecosystem, including DCAT-AP schema updates, Solr search configuration, SeMPyRO, Discovery Service, and FAIR Data Point (FDP). CKAN DCAT Model When a schema change falls under DCAT-AP 3 or an earlier version of DCAT-AP but is not yet present, follow these steps: 1. Fork and clone the repository: 2. Add the new field to the schema: - Modify the schema file: - Use appropriate field types (e.g., text, repeating subfield, URI). - Follow examples from other fields for consistency. For more information about scheming can be found in the CKAN Scheming documentation 3. Extend the existing mapping depending on the DCAT-AP version: Modify the mapping files located in the directory: 4. Fix the corresponding unit tests: 5. Create a pull request to the CKAN DCAT extension repository. Ensure that you follow the contributing guidelines for CKAN: - Include unit tests for the new fields. - Ensure compatibility across different DCAT-AP versions. 6. Update the following repositories after a new release: Update development and production Dockerfiles in these repositories( order is important): - https://github.com/GenomicDataInfrastructure/gdi-userportal-ckanext-fairdatapoint - https://github.com/GenomicDataInfrastructure/gdi-userportal-ckan-docker Check if ckan locally works with the new added fields by harvesting an example FDP Example of new field An example of a missing mapping in CKAN DCAT can be found here: Multi-valued field creator in CKAN DCAT. > Note: Always take into account the mapping from CKAN → DCAT in addition to DCAT → CKAN. --- Solr Search Integration If you're adding a new field in CKAN and you want it to be searchable via Solr, follow these steps to modify the file. Steps to Add and Configure a Searchable Field 1. Defining the Field Type and Name In the top part of the file, define the type and name of the new field. The type specifies how Solr will handle the data in the field (e.g., as , , , etc.). - Navigate to the section in where other fields are defined. - Add your new field with its corresponding type. Example: Here, custom_field is the name of the field, and it's set as a string type. It is also indexed (which makes it searchable) and stored (so it can be returned in search results). 2. Adding the Field to Search In the lower part of the schema.xml file, you'll need to add this field to the list of fields that are searchable by Solr. This is typically done in a section that defines which fields are indexed for searches. Example: This example maps the custom_field to the text field, which Solr uses for full-text searches. By adding the copyField directive, you're instructing Solr to include the contents of custom_field in the search index 3. When finished. Release a new version and update When finished. Release a new version and update GitHub - GenomicDataInfrastructure/gdi-userportal-ckan-docker: Scripts and images to run CKAN using Docker Compose in the development and production dockerfile Notes Indexing vs Storing: - indexed=\"true\": The field can be used in searches. - stored=\"true\": The field can be retrieved in search results. Testing the Configuration: After making these changes, you should restart your Solr instance and reindex your CKAN data to ensure that the new field is indexed and searchable with the command: SeMPyRO Prerequisites Fields are easy to add to SeMPyRO. You’ll need to know a few things: - The predicate of the field - Cardinality (single or multiple-valued) - Range or datatype Adding a Field Once that’s identified, go to the relevant class and add a property as follows. Here’s an example of the property of : At Line 1, we see , which is the name of the property. Its range is an , which is a helper for any URL. Other examples of this are or sometimes even classes like or . It is multi-valued because it's in a . If the maximum cardinality is one, it should not be in a . At Line 2, indicates the field is optional and by default undefined. Leave this line out for mandatory fields. At Line 3, we have a human-readable description of the field. At Line 4, we define the predicate. In this case, it's . Some common namespaces, like and , are imported by default. A full URI can also be defined, for example with . At Line 5, we define the RDF type. There are many possible values here, such as , , or . It's recommended to take a look at other properties to understand what is necessary here. Once this is done, the JSON and YAML schemas need to be re-generated. For the class, this can be done by running the following command: FAIR Data Point For the technical point of view, updating the appropriate SHACL shapes allows for adding of fields. Steps to Add a Field in FDP: 1. In the FDP, log in as an admin user and go to the Metadata schemas option. 2. Select the resource to update (e.g. Catalog). 3. In the Form Definition textarea, add a new entry in the list of values. For example: 4. Click Save if this is a draft and needs further work, or Save and release if the work is done. 5. Add a description and select a version number. 6. Click Release. Discovery Service The Dataset Discovery service requires two parts to be updated: the OpenAPI definitions and the mapping. OpenAPI Definition Two definitions need to be updated, both located in the folder: - ckan.yaml: This file contains the API returned by CKAN. Based on this YAML, Java classes are automatically generated corresponding to the API definition. For adding a field to a Dataset, the primary change will likely be in the CkanPackage definition. See the examples there on how to add a property. - discovery.yaml: This file defines what the Discovery service should return. You can make this definition whatever you want it to be—it does not have to correspond one-to-one with CKAN. To add a property here, modify the RetrievedDataset definition. Again, see the examples in the file. Mapping Once you have changed the definitions, follow these steps: 1. Run the following command:",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/develop-ckan-extensions",
      "url": "/gdi-userportal-frontend/developer-guide/develop-ckan-extensions",
      "title": "develop ckan extensions",
      "content": "Develop CKAN extensions Learn how to develop and test custom CKAN extensions for the GDI User Portal. This guide covers local development setup, extension structure, and testing procedures. Local development setup To develop and test CKAN extensions locally, you need to set up a proper development environment: 1. Set up virtual environment Note: Keep the virtual environment activated during the entire installation process. 2. Install CKAN as a package 3. Troubleshoot common dependency issues psycopg2 building issues If installation of fails: 1. Edit the requirements file at 2. Change to 3. Reinstall dependencies and CKAN separately: PyYAML compatibility issues For CKAN v2.9.10, if you encounter this error: Downgrade PyYAML in requirements.txt from or to . 4. Install required extensions Extensions can be installed from local repositories or directly from GitHub. Install from local repository Example on macOS: Install from GitHub Install extension dependencies Example for ckanext-harvest: 5. Configure database Set up PostgreSQL database and specify database connection strings in both and . Testing CKAN extensions Testing strategy depends on extension functionality. CKAN provides helper functions for generating dummy data and cleaning databases. Testing setup 1. Install pytest-ckan: Should be in extension's 2. Configure test.ini: Point to CKAN's test configuration 3. Configure test-core.ini: Set correct database connection Recommendation: Use separate test database instance for extensions requiring database writes. Running tests Basic test execution Test with coverage PyCharm configuration Set environment variable: Testing best practices - Review CKAN testing documentation for detailed guidance - Use CKAN helper functions for data generation and cleanup - Write tests for all extension interfaces and validators - Test schema changes with various data scenarios - Include integration tests for API endpoints Extension development workflow For detailed extension development procedures, see: - Add and modify features - Complete feature development guide - Work with backend services - Integration patterns - CKAN extensions documentation - Official guide Next steps After setting up your development environment: - Add and modify features - Build complete features - Work with backend services - Integrate with GDI services - Get started - Review overall development setup",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/develop-frontend",
      "url": "/gdi-userportal-frontend/developer-guide/develop-frontend",
      "title": "develop frontend",
      "content": "Develop frontend features :::info content in progress We are working on this guide. ::: The GDI User Portal frontend is built with Next.js 13+ using the App Router, TypeScript, and Tailwind CSS. This section covers frontend development including theming, component development, and API integration. Frontend architecture Technology stack - Next.js 13+ with App Router for server-side rendering and routing - TypeScript for type safety and better developer experience - Tailwind CSS for utility-first styling and responsive design - React Hook Form for form handling and validation - SWR for data fetching and caching - Radix UI for accessible component primitives Component organisation Theme customisation and styling Customise themes and styling The GDI User Portal offers extensive customisation options through configuration files and CSS variables. Configuration-based theming Modify for site-wide customisation: CSS customisation Use to define colour schemes: Custom fonts 1. Add font files to 2. Define font faces in 3. Update Tailwind configuration for font usage Visual assets Replace default assets in : - - Header logo - - Footer logo - - Browser icon - - Homepage background For detailed theming documentation, see Frontend Customisation. Component development Build components Follow established patterns for creating new React components: Component guidelines - Use TypeScript for all components - Implement proper accessibility (ARIA labels, keyboard navigation) - Follow established naming conventions - Include comprehensive prop types - Write unit tests for component logic State management - Use React's built-in state management for local state - Implement custom hooks for complex state logic - Use SWR for server state management - Context providers for global application state API integration Integrate with APIs The frontend integrates with multiple backend services using consistent patterns. Data Fetching with SWR API Route Handlers Service integration patterns Dataset Discovery Service integration - Search and filter datasets - Retrieve dataset metadata - Handle pagination and sorting Access Management Service integration - Submit access requests - Track application status - Manage user permissions Authentication integration - Handle login/logout flows - Manage user sessions - Secure API communication Testing Frontend testing strategy Testing best practices - Test user interactions, not implementation details - Use semantic queries for element selection - Mock external API calls - Test accessibility compliance - Implement visual regression testing Development tools Code quality - ESLint for code linting - Prettier for code formatting - TypeScript for type checking - Husky for Git hooks Development workflow Performance optimisation Next.js optimisation - Use Next.js Image component for optimised images - Implement proper code splitting - Utilise server-side rendering where appropriate - Optimise bundle size with dynamic imports Accessibility - Follow WCAG guidelines - Test with screen readers - Ensure keyboard navigation - Implement proper ARIA attributes",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/get-started",
      "url": "/gdi-userportal-frontend/developer-guide/get-started",
      "title": "get started",
      "content": "Get started :::info content in progress We are working on this guide. ::: This guide helps you set up a complete development environment for the GDI User Portal platform, including all necessary tools and dependencies. Prerequisites Before you begin, ensure you have the following installed: - Node.js (version 18 or higher) - npm or yarn package manager - Git for version control - Docker and Docker Compose for containerised services - Java 11+ (for backend services) - PostgreSQL (for local database development) Development environment setup 1. Clone the repository 2. Install dependencies 3. Environment configuration Copy the example environment file and configure for local development: Edit with your local configuration settings: 4. Start development services Use Docker Compose to start the required backend services: This starts: - CKAN instance with GDI extensions - PostgreSQL database - Keycloak authentication server - Dataset Discovery Service - Access Management Service 5. Start the development server The application will be available at . Project structure Understanding the codebase organisation: Local development workflow 1. Feature development - Create feature branches from - Use descriptive commit messages - Follow the established coding conventions - Write tests for new functionality 2. Testing Run the test suite before committing: 3. Code quality Maintain code quality with automated tools: Backend services integration Dataset Discovery Service The DDS provides abstraction over CKAN APIs. For local development: - Repository: gdi-userportal-dataset-discovery-service - Local URL: Access Management Service The AMS handles access requests and user permissions: - Repository: gdi-userportal-access-management-service - Local URL:",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/theming/customise-frontend",
      "url": "/gdi-userportal-frontend/developer-guide/theming/customise-frontend",
      "title": "customise frontend",
      "content": "Frontend customisation :::info content in progress We are working on this guide. ::: The GDI User Portal offers extensive customisation options through configuration files and public assets. This guide will help you understand how to customise various aspects of the portal. Configuration options The following configuration options can be set in the file: | Variable Name | Explanation | Example Value | | ---------------------------------- | ----------------------------------------------- | --------------------------------------------------------- | | NEXT_PUBLIC_SITE_TITLE | Main title of the website | \"GDI - User Portal\" | | NEXT_PUBLIC_SITE_DESCRIPTION | Brief description of the site | \"Genomic Data Infrastructure User Portal\" | | NEXT_PUBLIC_HOMEPAGE_TITLE | Main heading on the homepage | \"WELCOME TO GDI\" | | NEXT_PUBLIC_HOMEPAGE_SUBTITLE | Subheading text on the homepage | \"The Genomic Data Infrastructure (GDI) project...\" | | NEXT_PUBLIC_HOMEPAGE_ABOUT_CONTENT | Detailed content for the about section | \"The Genomic Data Infrastructure (GDI) homepage...\" | | NEXT_PUBLIC_BANNER_LINK | Navigation link for the banner | \"/howto\" | | NEXT_PUBLIC_FOOTER_TEXT | Text displayed in the footer | \"GDI project receives funding from the European Union...\" | | NEXT_PUBLIC_LINKEDIN_URL | LinkedIn social media link | \"https://www.linkedin.com/company/gdi-euproject/\" | | NEXT_PUBLIC_TWITTER_URL | Twitter/X social media link | \"https://twitter.com/GDI_EUproject\" | | NEXT_PUBLIC_GITHUB_URL | GitHub repository link | \"https://github.com/GenomicDataInfrastructure\" | | NEXT_PUBLIC_WEBSITE_URL | Main project website link | \"https://gdi.onemilliongenomes.eu/\" | | NEXT_PUBLIC_EMAIL | Contact email address | \"gdi-coordination@elixir-europe.org\" | | NEXT_PUBLIC_SHOW_BASKET_AND_LOGIN | Feature flag for basket and login functionality | \"true\" | Public assets customisation The portal's appearance can be customised through various files in the directory: Core configuration files 1. : Contains main site configuration including: - Site title and description - Homepage content and titles - Social media links - Contact information - Footer text - Feature flags 2. : Defines the colour scheme including: - Primary and secondary colours - Info and warning colours - Hover states - Surface colours - Dark mode support Visual assets 1. Logos: - : Main logo displayed in the header - : Logo displayed in the footer - : Browser tab icon 2. Images: - : Background image for the about section Typography 1. : Custom font definitions and typography settings 2. directory: Contains custom font files Content files 1. : About page content 2. : How-to guide content 3. : Legal information and terms Customisation best practices 1. Colours: - Use the file to maintain consistent branding - Consider both light and dark mode colour schemes - Ensure sufficient contrast for accessibility 2. Typography: - Add custom fonts to the directory - Define font faces in - Maintain consistent font usage throughout the application 3. Content: - Keep content in markdown files for easy maintenance - Update for site-wide text changes - Maintain proper licensing information in files 4. Images: - Use SVG format for logos when possible - Optimise image sizes for web performance - Include appropriate alt text in implementation 5. Environment variables: - Use different values for development, staging, and production - Keep sensitive values secure - Document any new variables added to the system",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/welcome",
      "url": "/gdi-userportal-frontend/developer-guide/welcome",
      "title": "welcome",
      "content": "Welcome, developers :::info content in progress We are working on this developer guide. ::: Welcome to the GDI User Portal Developer Guide! This comprehensive documentation will help you contribute to the Genomic Data Infrastructure (GDI) User Portal platform, whether you're developing new features, fixing bugs, or extending functionality. Development overview The GDI User Portal is built with modern web technologies and follows best practices for scalability, security, and maintainability: - Frontend: Next.js with TypeScript - Backend Services: Java/Spring Boot microservices - Data Catalogue: CKAN with custom extensions - Authentication: Keycloak with LS-AAI integration - Containerisation: Docker and Docker Compose Getting started Choose your development focus: - New to the project? Start with Get started - Frontend development? Go to Develop frontend features - Backend integration? Check out Work with backend services - CKAN extensions? Explore Develop CKAN extensions - Feature development? See Add and modify features Contributing Before contributing, review our coding standards and follow the established Git workflow. Ensure comprehensive testing coverage and update documentation for new features. GitHub Repository: GenomicDataInfrastructure/gdi-userportal-frontend",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/work-with-backend",
      "url": "/gdi-userportal-frontend/developer-guide/work-with-backend",
      "title": "work with backend",
      "content": "Work with backend services The GDI User Portal integrates with multiple backend services to provide comprehensive genomic data infrastructure functionality. This section covers integration patterns, API communication, and service orchestration. Backend architecture Service overview The platform consists of several interconnected services: - Dataset Discovery Service (DDS) - Data catalogue API abstraction - Access Management Service (AMS) - Access control and requests - CKAN - Core data catalogue system - Keycloak - Authentication and authorisation - PostgreSQL - Data persistence - Solr - Search and indexing Service communication Services communicate using: - REST APIs with JSON payloads - OAuth2/OpenID Connect for authentication - Service-to-service authentication tokens - Event-driven patterns for asynchronous operations Dataset Discovery Service integration Integrate Dataset Discovery Service The DDS provides a clean API layer over CKAN, abstracting complex CKAN operations and providing enhanced functionality. API Endpoints Dataset Search and Retrieval React Integration Access Management Service integration Connect Access Management Service The AMS handles all aspects of data access requests, user permissions, and compliance tracking. Access Request Flow AMS Client Implementation Authentication flow implementation Implement authentication flows Integration with Keycloak and LS-AAI requires careful handling of OAuth2 flows and token management. NextAuth Configuration Token management Error handling and resilience Service error handling Implement robust error handling for service communication: Retry logic Service monitoring and logging Health checks Implement service health monitoring: Testing backend integration Integration testing Mocking services Next steps After mastering backend integration: - Add and modify features - Build complete features - Develop frontend features - Enhance user interfaces - Get started - Review development setup",
      "guide": "developer-guide"
    }
  ],
  "all": [
    {
      "id": "/gdi-userportal-frontend/user-guide/about-gdi",
      "url": "/gdi-userportal-frontend/user-guide/about-gdi",
      "title": "About GDI",
      "content": "",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/explore-datasets/browse-by-category",
      "url": "/gdi-userportal-frontend/user-guide/explore-datasets/browse-by-category",
      "title": "browse by category",
      "content": "Browse datasets by category Browse datasets by Themes and Publishers directly from the main menu. While these categories are available as filters in the search page, you can access their dedicated sections from the main navigation menu for quick browsing. :::tip Sign in for better discovery Sign in to view comprehensive information. While you can use this tool without an account, signing in allows you to search and view more details, such as and other metadata, to help you find what you need. ::: To browse datasets by theme or publisher categories: 1. Select either Themes or Publishers from the main navigation menu. 2. Select the theme or publisher name. The Datasets page opens with pre-applied filters based on your selection. In this example, \"University of Oslo\" is selected under Publishers. 3. Explore more using the search, or apply more filters to narrow down results. 4. Found a dataset of interest? Select it to view more details or Request access to the dataset.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/explore-datasets/search-and-filter",
      "url": "/gdi-userportal-frontend/user-guide/explore-datasets/search-and-filter",
      "title": "search and filter",
      "content": "Search and filter datasets Use the search bar and filters to find datasets relevant to your research. Both search and filters are available on all pages where browsing datasets is possible. This includes the Home page and the Datasets page. :::tip Sign in for enhanced search Sign in to get comprehensive search results. While you can search datasets without an account, signing in allows you to filter and view more details in the search results, such as and other metadata. ::: Search datasets On the Home or Datasets page, enter any term or phrase to search across all dataset information, including: - Disease names, research topics, or data types - Specific terms like gene names or scientific keywords - Any other information described in the dataset metadata Filter your results Use the filters on the left side of the search results page to narrow down your results. These filters are based on dataset metadata, and signing in gives you access to additional metadata-based filters. Common filters include: Access Rights, Data Types, Themes, and Publishers. Here's an example of a search result for the word \"cancer\", with filters applied for Access Rights: .",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/explore-datasets/search-by-allele-frequency",
      "url": "/gdi-userportal-frontend/user-guide/explore-datasets/search-by-allele-frequency",
      "title": "search by allele frequency",
      "content": "Search by allele frequency Search for datasets containing specific genomic variants using the allele frequency search tool. Allele frequency refers to how common a specific genetic variant is within a population. This search tool allows you to: - Identify relevant datasets with your specific genomic variant of interest - Compare variant frequencies across different populations and research cohorts - Assess dataset suitability by viewing detailed prevalence data to select the most appropriate datasets for your research :::tip Sign in for enhanced search Sign in to get comprehensive search results. While you can use this tool without an account, signing in allows you to search and view more details, such as and other metadata, to help you find what you need. ::: Search by allele frequency 1. Select Allele Frequency from the main menu. 2. Enter your search criteria: - Variant: The full form of the genomic variant, usually represented in the format . Example: - Ref Genome: Select the reference genome assembly to use for the search. - Cohort: Select the cohort of interest. Cohorts are groups of individuals sharing common characteristics, for example, those with a specific condition such as COVID. - Sex (optional): Filter results by biological sex (Male or Female). - Country of Birth (optional): Filter results by country of birth using 2-letter ISO country codes. 3. Select Search or press Enter. The search results display dataset information in table format. Understanding your results The search results display datasets containing your specified variant in table format. Here's an example of the search result using the allele frequency search tool: - Dataset: Name and source of the dataset. These are Beacon identifiers—the portal uses Beacon technology to retrieve information about whether genomic databases contain specific variants. - Population: Population identifier from the dataset (e.g., \"FR_M\" for French males in GoE format). - Allele Count: Number of times the variant appears in the dataset. - Allele Number: Total number of alleles analysed in the dataset for this position. - Homozygous: Number of individuals with two copies of the variant. - Heterozygous: Number of individuals with one copy of the variant. - Hemizygous: Number of individuals with one copy of the variant on a sex chromosome (relevant for an X or Y chromosome). - Frequency: How common the variant is in that population (as a decimal). - Actions: Add the dataset to your basket to request access later.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/export-metadata",
      "url": "/gdi-userportal-frontend/user-guide/export-metadata",
      "title": "export metadata",
      "content": "Export metadata Download dataset metadata for integration with various tools and systems. The metadata includes detailed information about the dataset such as data types, collection methods, access rights, and other descriptive information that can help you integrate the dataset information into your research workflow. You can export metadata in the following formats: - RDF: Resource Description Framework format for semantic web applications - TTL: Turtle format for human-readable RDF data - JSON-LD: JSON for Linked Data format for web-based applications To export metadata: 1. Browse or search for datasets you want to export metadata from. 2. Select a dataset to view its details. 3. Locate the Export Metadata In section and select your preferred format (RDF, TTL, or JSON-LD). In this example, we select JSON-LD: 4. Select Download to save the metadata file to your device.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/faq",
      "url": "/gdi-userportal-frontend/user-guide/faq",
      "title": "faq",
      "content": "Frequently Asked Questions For additional questions or support, please contact our support team. Do I need an account to access GDI Portal? You do not need an account to access the GDI Portal and browse dataset information. However, you need to sign in to your account to request access to the dataset records. Signing in also enables additional features such as saving searches and receiving notifications. I found a dataset I want to use. What do I do? First, you need to submit an application to access the said data. You might be asked to provide additional information such as your research purpose, institutional affiliation, and ethics approval documentation. The portal will guide you through these requirements when you apply. Once your application is approved, you will receive instructions on how to download the data. How long does it take to get approval to access data? Approval times vary depending on the dataset, the requirements you provide, and the complexity of your request. The portal will connect you with the Data Access Committee who manage the approval process. Can I access data from multiple countries? Yes, the GDI Portal enables cross-border access to genomic data across European countries through its federated network approach.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/add-participants",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/add-participants",
      "title": "add participants",
      "content": "Add participants to your application Add participants to collaborate with team members or colleagues on your dataset access request. You can invite multiple participants to help complete the application, upload required documents, and stay informed about the request status. You can add participants to draft and submitted applications. Participants can: - View the application details and requirements - Submit requirements such as forms and documents - Submit draft applications for review - Receive status updates via email To add participants to your application: 1. Select the folder icon () on your dashboard. 2. Select the Applications tab on your dashboard, and select your draft or submitted application. 3. Select Add Participant on the application details page. 4. Enter the name and email address you want to invite and select Send. Do this for each participant you want to add. :::tip Well done After participants accept your invitation, they can access the application from their dashboard and continue the application process.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/apply-for-access",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/apply-for-access",
      "title": "apply for access",
      "content": "Apply for access to datasets Access datasets you find in the GDI Portal. Depending on the dataset type, you can either submit an application through the portal for GDI datasets, or be redirected to external sources for externally governed datasets. To apply for access to datasets: 1. Browse or search for datasets you want to access. 2. Select Add to basket on each dataset you want to access. You can add datasets directly from the search results: Or you can add the dataset from the dataset details page: :::info External datasets Some datasets may be managed by an external organisation. These datasets have an label and cannot be added to the basket. To request access, select Access External Dataset and follow the link to the external source. ::: 3. When you're ready to check out, select the Basket icon (). The Basket page opens with the list of datasets you selected. 4. Review your list of datasets and select Request now to create an application. The application form opens. 5. Submit the requirements to access the dataset. This can include filling out forms and uploading documents, depending on the dataset. Here's an example of requirements including document uploads: 6. (Optional) Need help with your application? Select Add Participant for collaborators to access your application, submit requirements, and continue your application. 7. Review the Terms & Conditions and select Accept All to agree to the terms. 8. Select Submit to complete your application. You will receive email notifications for status updates and if additional documentation is required. :::tip Continue later If you need more time, you can close or navigate away from the application page. The system automatically saves your progress as draft, and you or your collaborators can continue later. :::",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/continue-an-application",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/continue-an-application",
      "title": "continue an application",
      "content": "Continue an application Continue working on applications that you or other collaborators have started earlier. All incomplete applications are saved as draft. To continue a draft application: 1. Select the folder icon () on your dashboard. 2. Select the APPLICATIONS tab. The page lists applications, indicating their status. In this example, you have one application and one application: 3. Select the draft application you want to complete. 4. Complete the application form by providing all required information or uploading necessary documentation. 5. Review the Terms & Conditions and select Accept All to agree to the terms. 6. Select Submit to submit your completed application. You will receive a confirmation email and be notified of status updates. Or to save and continue later, simply navigate away from the page. The system saves your last completed input.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/download-datasets",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/download-datasets",
      "title": "download datasets",
      "content": "Download datasets Once your application is approved, you'll receive an email with instructions to access the Secure Processing Environment (SPE) where you can securely download and work with your approved datasets. To access and work with your approved datasets: 1. Check your email for instructions and access links to the Secure Processing Environment (SPE). 2. Follow the instructions provided in the email to securely access the SPE. 3. Download and work with your approved datasets within the SPE. :::info Stay compliant All data are protected by governance frameworks and data access policies to ensure ethical and legal use. Remember to use data responsibly and according to the terms and agreements you signed during the application process. ::: View approved datasets in the portal You can also view your approved datasets directly in the GDI Portal to see their metadata and details. To view your approved datasets: 1. Select the folder icon () on your dashboard. 2. Select the Entitlements tab to see the list of your approved datasets. 3. Select the dataset to view its details. This view only displays the metadata of your approved datasets. To download and work with the datasets, use the Secure Processing Environment (SPE) as instructed in your approval email.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/track-application",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/track-application",
      "title": "track application",
      "content": "Track your application After submitting your application, track its progress and check for any status updates or additional requirements from the Data Access Committee. To track your application: 1. Select the folder icon () on your dashboard. 2. Select the APPLICATIONS tab. The page displays all your applications with their current status, sorted by last modified date: In this example, there is one application and one application: 3. Review your application status. Applications can have the following statuses: - DRAFT: Application is incomplete and has not been submitted yet. Continue the application. - SUBMITTED: Application is under review by the Data Access Committee. - RETURNED: Application requires additional information or documents. View the feedback and continue the application. - APPROVED: Application has been approved and you can access the datasets. Download the datasets. - REJECTED: Application has been declined. Select the application to view feedback. To resubmit, create a new application. - CLOSED: Application is closed and no further action is required. Open the application to view details.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/sign-in",
      "url": "/gdi-userportal-frontend/user-guide/sign-in",
      "title": "sign in",
      "content": "Sign in Signing in allows you to access enhanced features and request access to datasets. While you can browse datasets without an account, signing in allows you to: - Submit applications to request access to datasets. - Enhance your search with additional filters and more comprehensive search results. - See more dataset information including and other metadata to help assess if datasets meet your research needs. The GDI Portal uses your existing accounts with other platforms like Google, LinkedIn, and organisations like universities or research institutions, so you don't need to create a separate account. To sign in to the GDI Portal: 1. Open the GDI Portal in your browser: https://portal.dev.gdi.lu/. 2. Select Login at the top right corner of the page. The login page opens. 3. Select LSAAI as your sign-in method. :::info Why LSAAI? GDI Portal requires you to sign in with LSAAI (Login Service for Academic and Administrative Institutions). LSAAI is a secure login system that lets you use your existing accounts like Google, LinkedIn, university, or other institutional accounts. This means you don't need to create a new account specifically for the GDI Portal. ::: 4. Select your account provider: Search for your institution in the search bar, or select from the list of options (LinkedIn, Apple, Google, ORCID, GitHub). 5. Follow the instructions to sign in with your selected account. If it's your first time signing in, you may need to verify your email address. 6. After you sign in, the GDI Portal home page loads and you can start exploring datasets.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/welcome-data-users",
      "url": "/gdi-userportal-frontend/user-guide/welcome-data-users",
      "title": "welcome data users",
      "content": "Welcome to the GDI Data Portal Welcome to the GDI Data Portal user guide! The GDI Data Portal gives you access to Europe's largest network of genomic datasets for your research and analysis needs. As part of the 1+ Million Genomes Initiative, this portal enables federated and secure cross-border access to high-quality genomic data and related phenotypic information across European countries. This guide is for data users—healthcare researchers, policy-makers, and professionals—who want to discover and request access to genomic datasets for research and clinical purposes. Learn more about Genomic Data Infrastructure (GDI) and its founding initiatives. Access genomic datasets in three steps 1. Explore datasets: Browse and search through detailed dataset information—search by any criteria such as keywords, research topics, disease areas, or allele frequency. 2. Request access: Found a dataset you want to use? Submit an application to access it. You may need to provide documentation or requirements for your request, and you can invite collaborators to assist you with your application. 3. Access approved datasets: Once your request is approved, you will receive an email with a link to the Secure Processing Environment (SPE) where you can securely download and work with the datasets. :::info Stay compliant All data are protected by governance frameworks and data access policies to ensure ethical and legal use. Remember to use data responsibly and according to the terms and agreements you signed during the application process. :::",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/about-harvesting",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/about-harvesting",
      "title": "about harvesting",
      "content": "About dataset harvesting Dataset harvesting allows you to import and synchronise datasets from external data sources automatically by connecting them to your GDI Data Catalogue. When the source updates, your catalogue synchronises the changes. Use harvesting when you need to: - Collect datasets from partner organisations or multiple European data portals - Stay synchronised with external data repositories - Reduce manual data entry and maintenance effort What gets harvested: - Dataset metadata (titles, descriptions, keywords) - Resource links (URLs to data files) - Contact information and licences - Update timestamps and versioning information Harvesting workflow The diagram below shows how data flows from external sources through the GDI Data Catalogue to the public-facing GDI Data Portal: Supported source types The GDI Data Catalogue can harvest from: - FAIR Data Points: Research data repositories that follow FAIR principles - DCAT-AP endpoints: European data portals using the DCAT-AP standard - CKAN catalogues: Other CKAN instances operated by partner organisations Learn how to add harvest sources → How harvesting works - Initial setup: Connect your data source by configuring a harvest source in the catalogue. You specify the source URL, type, and authentication details. - First harvest: The harvester performs an initial import of all datasets from the source into your catalogue. The initial import starts automatically at the next quarter-hour boundary (:00, :15, :30, or :45). For example, if you set up the source at 10:31, the first harvest starts at 10:45. - Scheduled harvests: After the first harvest completes, the harvester runs automatically on a daily schedule at the same quarter-hour boundary. This ensures consistent, predictable harvest timing for monitoring and troubleshooting. Following the same example above, subsequent harvests would occur daily at 10:45. - Change detection: During each scheduled harvest, the harvester compares the source data with the existing datasets. - New datasets from the source are added to your catalogue - Updated datasets are refreshed with current metadata - Datasets deleted at the source are removed from your catalogue - All changes are logged for review - Publication to Data Portal: Public harvested datasets appear in the GDI Data Portal↗ after import to the catalogue. Private datasets remain visible only to members of your organisation.",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/add-harvest-sources/ckan",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/add-harvest-sources/ckan",
      "title": "ckan",
      "content": "Harvest from CKAN catalogues Synchronise datasets from other CKAN catalogues to enable cross-institutional collaboration and maintain distributed dataset collections. :::tip CKAN-to-CKAN harvesting The GDI Data Catalogue is powered by CKAN. CKAN-to-CKAN harvesting is implemented in the core system, making it straightforward to harvest from other CKAN instances. ::: Configure the CKAN source When adding a harvest source, use these settings for CKAN catalogues: | Field | Description | |-------|-------------| | Source type | Select CKAN from the dropdown | | URL | Enter the CKAN instance API endpoint URL | | Configuration | Leave empty unless specific filters are required | Next steps - Test harvest sources - Monitor harvest sources - Manage harvest sources",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/add-harvest-sources/dcat-ap",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/add-harvest-sources/dcat-ap",
      "title": "dcat ap",
      "content": "Harvest from DCAT-AP endpoints Connect to European data portals using the DCAT-AP standard to import standardised public sector datasets. :::tip What is DCAT-AP? Data Catalog Vocabulary-Application Profile (DCAT-AP) is a European standard for describing public sector data catalogues. Many European national and regional portals use DCAT-AP to expose their metadata. ::: Configure the DCAT-AP source :::info Prerequisites The extension must be added to the CKAN plugins for this harvester to be available. Additionally, ensure the CKAN.ini file contains: - (space-separated list of profiles) - ::: When adding a harvest source, use these settings for DCAT-AP endpoints: | Field | Description | |-------|-------------| | URL | Enter the DCAT-AP endpoint URL. Examples:• • | | Source type | Select Generic DCAT RDF Harvester from the dropdown | | Configuration | Enter: Note: Set to match your file format:• for .ttl files• for .rdf/.xml files | :::tip Troubleshooting MIME types To harvest data sources, the system looks at MIME types: - For turtle format files (.ttl): - For RDF/XML files (.rdf): If you're experiencing harvesting issues, verify the in your configuration matches your file type. ::: Next steps - Test harvest sources - Monitor harvest sources - Manage harvest sources",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/add-harvest-sources/fair-data-points",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/add-harvest-sources/fair-data-points",
      "title": "fair data points",
      "content": "Harvest from FAIR data points Connect to FAIR Data Points to import scientific datasets that follow FAIR principles (Findable, Accessible, Interoperable, Reusable). :::tip What are FAIR Data Points? FAIR Data Points are standardised metadata endpoints for scientific data that ensure data can be easily found and reused by researchers. Learn more about FAIR principles↗. ::: Configure the FAIR data point source :::info Prerequisite The extension must be added to the CKAN plugins for this harvester to be available. ::: When adding a harvest source, use these settings for FAIR data points: | Field | Description | |-------|-------------| | URL | Enter the FAIR Data Point base URL. Example: | | Source type | Select FAIR data point harvester from the dropdown | | Configuration | Enter: | :::tip Known Behaviour If a dataset is moved in FDP from one catalogue to another catalogue (by updating reference on the dataset level), it will be considered a new one because a guid of CKAN harvested resource (unlike FDP itself) includes a catalogue ID. ::: Next steps - Test harvest sources - Monitor harvest sources - Manage harvest sources",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/add-harvest-sources",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/add-harvest-sources",
      "title": "index",
      "content": "Add harvest sources Connect external data sources to automatically import and synchronise datasets into your GDI Data Catalogue. The process is the same for all source types—only the configuration differs. In this guide > Identify your source type > Add a harvest source > Configure source settings Identify your source type The GDI Data Catalogue supports three harvest source types: - FAIR data points: Import from research data repositories following FAIR principles. Example: Health-RI↗ - Generic DCAT RDF: Import from European public sector data portals. Example: OpenData.swiss↗ - CKAN catalogue: Import from partner CKAN instances. Example: Partner institution catalogues, regional data hubs Add a harvest source 1. Go to Harvest Sources and select Add Harvest Source. 2. Fill out the harvest source form based on the source type you are connecting to. | Field | Description | |-------|-------------| | URL | The source endpoint URL. See the URL formats for different sources in the source-specific pages | | Title | A descriptive name for this harvest source | | Name | A unique URL-friendly identifier for this source. This becomes part of the harvest source's URL path.| | Source type | The appropriate harvester for your source. See the source-specific configuration for your source type.| | Update frequency | How often the harvest runs:• Manual: You must click Reharvest each time• Daily: Runs at the end of each day• Weekly: Runs at the end of each week• Biweekly: Runs every two weeks• Monthly: Runs at the end of each month• Always: Runs continuously| | Configuration | Enter the source-specific configurations | | Organisation | The organisation that will own the imported datasets | 3. Select Save to create the harvest source. :::tip Manual harvest Use manual harvest to test new configuration changes, import urgent dataset updates, or verify the harvest after fixing an issue. ::: Configure source settings Select your source type for detailed configuration instructions: - FAIR data points: Research data repositories following FAIR principles - DCAT-AP endpoints: European data portals using DCAT-AP standard - CKAN catalogues: Partner CKAN instances",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/check-your-permissions",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/check-your-permissions",
      "title": "check your permissions",
      "content": "Check your permissions Your permissions in the GDI Data Catalogue depend on two levels of roles: platform-level and organisation-level. In this guide > Platform-level roles > Organisation-level roles Platform-level roles Your platform-level role determines your baseline permissions across the entire GDI Data Catalogue. This role is assigned to you by the Sysadmin and applies to all organisations you belong to. To check: Log in to see your access to management features. You can identify your platform-level role by the features available to you in the top navigation bar. Here's an example screenshot of the navigation bar for a sysadmin with access to all management features: Platform-level permissions | Role | Permissions | Limitations | |------|-------------|-------------| | Visitor (not signed in) | Search and view:• Datasets• Organisations• Groups (dataset groups) | • Cannot access private datasets• Cannot join organisations or manage content• Cannot create any resources | | Registered user | Manage based on organisation-level role:• Organisations• Datasets• Groups (dataset groups) | Depends on organisation-level role | | Sysadmin | Manage all:• Organisations• Datasets• Groups• Harvest sources• Users | None | :::tip Need more access? Contact your Sysadmin to upgrade your platform-level role or to adjust your organisation memberships. ::: Organisation-level roles After verifying your platform-level role, check your permissions within each organisation you belong to. You may have different roles in different organisations. To check: 1. Select your name on the top right corner of the page. 2. Select Organisations, then select the name of an organisation you belong to. 3. On the organisation page, select the Members tab to see your role in that organisation. Organisation-level permissions Your organisation-level role determines what you can do within each specific organisation. | Role | Permissions | Key capabilities | |------|-------------|------------------| | Member | • View private datasets in the organisation• Request elevated permissions | Read-only access to organisation datasets | | Editor | • All member permissions• Create new datasets• Edit any dataset in the organisation• Delete datasets• Set dataset visibility (public/private) | Full dataset management within the organisation | | Admin | • All editor permissions• Invite users to the organisation• Assign and change user roles• Remove users from the organisation• Update organisation settings (title, description, image)• Delete the organisation | Complete control over organisation and its members | :::info Organisation admins Organisation Admins can manage other Admins, including changing their roles or removing them from the organisation. To request more permissions, contact your organisation Admin. ::: :::tip Full documentation For detailed technical information about how permissions work, see the CKAN authorisation documentation↗. CKAN is the system that powers the GDI Catalogue Portal. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/log-in",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/log-in",
      "title": "log in",
      "content": "Login to the GDI Data Catalogue Access the GDI Dataset Catalogue to manage your organisation's genomic datasets. You need an active account with appropriate permissions to perform catalogue management tasks. To log in: 1. Open the Dataset Catalogue at https://catalogue.portal.gdi.lu 2. Select Log in in the top-right corner of the page. 3. Select LSAAI as your sign-in method. 4. Select your account provider: Search for your institution in the search bar, or select from the list of options (LinkedIn, Apple, Google, ORCID, GitHub). 5. Follow the instructions to sign in with your selected account. If it's your first time signing in, you may need to verify your email address. After you sign in, the Catalogue Portal homepage opens and you can start managing datasets.",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually/add-datasets",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually/add-datasets",
      "title": "add datasets",
      "content": "Add datasets Add individual datasets directly in your catalogue when automated harvesting isn't suitable for your use case. :::tip Full documentation This guide covers the common tasks for managing datasets. For a complete guide to all dataset operations, see the CKAN documentation↗. CKAN is the system that powers the GDI Catalogue Portal. ::: To manually add a dataset: 1. Go to Datasets and select Add Dataset. 2. Fill out the dataset form with the metadata of your genomic dataset. For guidance on filling out the form, see the definition of properties in the DCAT-AP Vocabulary↗. :::tip Setting the dataset visibility - Private datasets will be visible to users within your organisation in the Data Catalogue. - Public datasets will be discoverable by all users in the GDI Data Portal↗. ::: 3. Select Next: Add Data to add a data resource. You must add at least one data resource to create your dataset. See: Add data resources for guidance on filling out the data resource form. 4. Select Finish to add your dataset. After your dataset is successfully created, the dataset details page opens.",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually/add-resources",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually/add-resources",
      "title": "add resources",
      "content": "Add data resources A data resource represents the actual data described by your dataset. It can be a file, a link to an external data source, or an API endpoint. Adding data resources makes your dataset actionable and allows users to access the underlying data. In this guide > Add a data resource > Reorder data resources :::tip Full documentation This guide covers the common tasks for managing datasets. For a complete guide to all dataset operations, see the CKAN documentation↗. CKAN is the system that powers the GDI Catalogue Portal. ::: Add a data resource To add a data resource to your dataset: 1. Open the dataset you want to add a data resource to. 2. On the dataset details page, select Manage. 3. On the left panel under Resources, select Add new resource. 4. Fill out the data resource form. For guidance on filling out the form, see the definition of properties in the DCAT-AP Vocabulary. 5. Select Update Dataset to save the data resource. Once the data resource is added, it appears in the list of data resources for the dataset. Repeat the steps to add more data resources as needed. Reorder data resources Reorder data resources to prioritise the most important or frequently accessed files or links. The order of data resources determines their display sequence on the Data Portal and dataset details page. To reorder data resources: 1. On the dataset details page, select Manage. 2. Select the Resources tab. The list of data resources appears. 3. Drag and drop the data resources to reorder them as desired. 4. Select Save order. The data resources are reordered and displayed in the new sequence on the dataset details page and the Data Portal.",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually/delete-datasets",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually/delete-datasets",
      "title": "delete datasets",
      "content": "Delete datasets Permanently remove datasets that are obsolete or no longer needed. Before you proceed, ensure there are no dependencies on the dataset or consider changing visibility from public to private. In this guide > Delete a dataset > What happens when you delete a dataset :::tip Full documentation This guide covers the common tasks for managing datasets. For a complete guide to all dataset operations, see the CKAN documentation↗. CKAN is the system that powers the GDI Catalogue Portal. ::: Delete a dataset To delete a dataset from the catalogue: 1. Go to Datasets from the main menu and open the dataset you want to delete. 2. On the dataset details page, select Manage. 3. Scroll to the bottom panel and select Delete. 4. Select Confirm to permanently delete the dataset. :::danger Permanent action Deleting a dataset cannot be undone. The dataset record and all associated data resources are permanently removed from the catalogue with no recovery option. ::: What happens when you delete a dataset When you delete a dataset, the following occurs: - The dataset metadata and all associated information are permanently deleted - The dataset is removed from the GDI Data Portal↗ - Any users or applications with access permissions lose access to the dataset - Links to the dataset from external sources or documentation will no longer work :::info Data files not affected Deleting a dataset record from the catalogue does not delete the actual data files stored in your organisation's repositories or storage systems. It only removes the metadata record from the GDI catalogue. ::: :::warning Harvested datasets If the dataset you deleted was harvested from an external source, it may be re-created during the next harvest. To permanently remove a harvested dataset remove it from the source system. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually",
      "title": "index",
      "content": "Manage datasets manually Add and manage individual datasets directly in your catalogue when automated harvesting isn't suitable for your use case. Manage datasets manually for: - One-off datasets: Single datasets that don't require ongoing synchronisation - Test datasets: Creating sample data for testing or demonstration purposes - Internal datasets: Organisation-specific data not available from external sources - Special cases: Datasets requiring custom metadata or unique handling :::tip Use harvesting for automation Manual dataset management is for exceptions. For regular updates, bulk imports, or external sources, use automated harvesting to reduce effort and keep your catalogue current. ::: Select an operation to get started: - Add datasets - Create new dataset records with metadata - Add data resources - Add files or links to your datasets - Delete datasets - Permanently remove datasets from your catalogue - Manage dataset groups - Organise datasets into discoverable groups :::tip Complete dataset management For a comprehensive guide to all dataset operations including editing, updating resources, and advanced features, see the CKAN documentation↗. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually/manage-groups",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets-manually/manage-groups",
      "title": "manage groups",
      "content": "Manage dataset groups Organise and categorise related datasets together, making them easier to discover and manage. Groups can contain any combination of harvested or manually created datasets. In this guide > Create a dataset group > Add datasets to a group > Remove datasets from a group > Manage group properties > Delete a dataset group :::tip Full documentation For a complete guide to groups, see the CKAN documentation↗. CKAN is the system that powers the GDI Catalogue Portal. ::: Create a dataset group 1. Go to Groups from the main navigation. 2. Select Add Group. 3. Fill in the group details: - Name: Enter a descriptive name for the group - Description: Explain what types of datasets this group contains - Image URL: (Optional) Add an image to represent the group 4. Select Create Group. Add datasets to a group 1. Navigate to the dataset you want to add to a group. 2. Select Manage → Groups. 3. Select the groups you want to add this dataset to. 4. Select Update Groups to save your changes. :::tip Multiple groups You can add a dataset to multiple groups to improve discoverability across different categorisations. ::: Remove datasets from a group 1. Navigate to the dataset you want to remove from a group. 2. Select Manage → Groups. 3. Deselect the groups you want to remove this dataset from. 4. Select Update Groups to save your changes. Manage group properties 1. Go to Groups from the main navigation. 2. Select the group you want to edit. 3. Select Manage to edit the group details. 4. Update the name, description, or image as needed. 5. Select Update Group to save your changes. Delete a dataset group 1. Go to Groups from the main navigation. 2. Select the group you want to delete. 3. Select Manage → Delete. 4. Confirm the deletion. :::info Datasets are not affected Deleting a group does not delete the datasets within it. The datasets remain in the catalogue and can be added to other groups. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-harvest-sources",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-harvest-sources",
      "title": "manage harvest sources",
      "content": "Manage harvest sources Edit, trigger, and delete harvest sources to maintain accurate synchronisation with external data repositories. In this guide > Edit a harvest source > Trigger a manual harvest > Delete a harvest source Edit a harvest source Update your harvest source configuration when URLs change, credentials expire, or harvest settings need adjustment. 1. Go to Harvest Sources. 2. Select the harvest source you want to edit. 3. Select Admin, and then Edit. 4. Update the configuration, and select Save. 5. (Optionally) Select Reharvest to apply changes immediately. :::tip CONFIGURATION CHANGES Changes take effect immediately for the next scheduled harvest. Any currently running harvest job continues with the old configuration. ::: Trigger a manual harvest Run a harvest immediately without waiting for the scheduled time. 1. Go to Harvest Sources. 2. Select your harvest source. 3. Select Admin, and then Reharvest. 4. Monitor progress in the Jobs tab. Delete a harvest source Permanently remove a harvest source configuration when you no longer need automatic synchronisation. 1. Go to Harvest Sources. 2. Select the harvest source you want to delete. 3. Select Admin, and then Edit. 4. Select Delete at the bottom of the form. 5. Select Delete source or Delete and clear source, and then confirm the deletion. :::info HARVESTED DATASETS REMAIN Deleting a harvest source does not delete the harvested datasets. They remain in your catalogue but will no longer synchronise automatically with the source. ::: What happens after deletion: - The harvest source configuration is permanently removed - Scheduled harvests stop - Harvested datasets remain in your catalogue as regular datasets - You can edit datasets manually without synchronisation conflicts :::info Re-adding the same source Datasets will be considered \"new\" if you configure a harvester source, delete it, and re-add it. ::: :::note Known Deletion Behaviour If deletion fails during the , the dataset becomes permanently hidden in the database and cannot be removed by subsequent harvests. ::: :::tip Editing harvested datasets Manual edits to harvested datasets are overwritten during the next harvest run. For permanent changes, consider requesting the source administrators to update metadata at the original system. Changes will synchronise automatically. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-organisations/create-organisation",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-organisations/create-organisation",
      "title": "create organisation",
      "content": "Create organisation Set up a new organisation to group your institution's datasets and manage team access. Create an organisation when: - Your institution is joining the GDI Data Catalogue for the first time. - You need to separate datasets by department or project team. - You want to control access to datasets within your institution. To create an organisation: 1. Go to Organizations and select Add Organization. 2. Fill out the organization form: - Name: Use your institution's official name for consistency across the GDI ecosystem - URL: Auto-generated from the organization name. Select edit to customise it - Description: Describe your institution and its role in genomic data management - Image URL: Link to an optional logo for your organization 3. Select Create Organization to save your organization. After your organisation is created, the organisation details page opens and you can start adding members and datasets. Next step Manage members to invite your team and assign roles.",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-organisations",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-organisations",
      "title": "index",
      "content": "Manage organisations Control access to your institution's datasets by setting up organisations and managing team permissions. Organisations represent institutions or teams that publish datasets in the GDI Data Catalogue. All datasets must belong to an organisation. Organisations allow you to: - Group datasets by institutional ownership - Control who can view, edit, or manage your datasets - Assign role-based permissions to team members - Maintain institutional branding and identity Select a task to get started: - Create organisation: Set up a new organisation for your institution - Manage members: Add members, assign roles, or remove members :::tip Full documentation For a complete guide to organisations and advanced features, see the CKAN documentation↗. CKAN is the system that powers the GDI Catalogue Portal. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-organisations/manage-members",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-organisations/manage-members",
      "title": "manage members",
      "content": "Manage members Invite team members to your organisation and control their access by assigning roles or removing members. In this guide > Add members > Edit member role > Remove member :::tip Full documentation For a complete guide to organisation management, see the CKAN documentation↗. CKAN is the system that powers the GDI Catalogue Portal. ::: Add members Invite team members to your organisation and assign roles to control their access permissions. 1. Go to Organizations and select your organization from the list. 2. Select Manage and then Members. 3. Select Add Member. 4. The next steps depend on whether the member already has an account in the GDI Data Catalogue: - For existing users: Select their username under Existing User. - For new users: Enter their email address under New User to send them an invitation. Then, come back to this step after they create their account. 5. Enter the member's username and select their role: - Admin: Full control over organization and all datasets - Editor: Can add and edit datasets - Member: Can view private datasets 6. Select Add to save the member. Repeat the steps above to add more team members as needed. Edit member role Change a team member's role to adjust their access permissions. 1. Go to Organizations and select your organization from the list. 2. Select Manage and then Members. 3. Find the member whose role you want to change. 4. Select the Role dropdown next to their name and choose the new role: - Admin: Full control over organization and all datasets - Editor: Can add and edit datasets - Member: Can view private datasets 5. The role change takes effect immediately. :::info Understanding roles See User roles and permissions for detailed information about what each role can do. Role changes are immediate—the member's access is updated as soon as you change their role. ::: Remove member Remove team members who no longer need access to your organisation's datasets. 1. Go to Organizations and select your organization from the list. 2. Select Manage and then Members. 3. Find the member you want to remove. 4. Select the Delete (x) icon next to their name. 5. Confirm the deletion when prompted. :::warning What happens when you remove a member - The member loses access to all private datasets in your organisation - The member can no longer edit or manage datasets in your organisation - The member's user account remains active in the catalogue - The member can still be added to other organisations ::: :::danger Removing organisation admins When removing an organisation admin, ensure at least one other admin remains to manage the organisation. If you remove all admins, you'll need to contact a system administrator to regain access. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/monitor-harvest-sources",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/monitor-harvest-sources",
      "title": "monitor harvest sources",
      "content": "Monitor harvesting Track harvesting health at both system and job levels. In this guide > Monitor background processes > Monitor harvest jobs Monitor background processes When to check: If harvests aren't running as expected. Three background processes must run continuously for harvesting to work: - : Manages the gathering of data sources to be harvested - : Responsible for fetching the data from the sources identified by the gather process - : Responsible for triggering the harvester at the end of each specified time interval To check process status: 1. Access the CKAN container: 2. Check all processes: 3. Verify output: All three processes should show status. If any process is not running correctly, see Manage harvest sources. Monitor harvest jobs When to check: If you want to review harvest history and results. 1. Go to Harvest Sources and select your source. 2. Select the Jobs tab to view: - Harvest history with timestamps - Job status - Number of datasets added, updated, deleted, and not modified - Error messages and logs 3. Select a specific job to view detailed logs and troubleshooting information.",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/test-harvest-sources",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/test-harvest-sources",
      "title": "test harvest sources",
      "content": "Test harvest sources Verify your harvest source configuration is working correctly before relying on automated schedules. To test a harvest source: 1. Access the CKAN container: 2. Run the test command: Where is the last part of the harvest source URL 3. Check for success. If successful, you'll see datasets uploaded in the catalogue. :::tip Manual triggering After you configure the manual harvester, you can trigger it by clicking Reharvest in the job's Admin section. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/welcome",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/welcome",
      "title": "welcome",
      "content": "Welcome to the GDI Data Catalogue Welcome to the GDI Data Catalogue user guide! The GDI Data Catalogue is the central management system for Europe's genomic dataset network. As part of the 1+ Million Genomes Initiative, this catalogue serves as the source for dataset information that users can access through the public-facing GDI Data Portal↗. This guide is for catalogue managers—data stewards, repository administrators, and data managers—who are responsible for publishing, curating, and managing genomic datasets within the GDI ecosystem. Learn more about Genomic Data Infrastructure (GDI) and its founding initiatives. Manage datasets in two ways - Harvest datasets automatically: Set up automated harvesting from external sources like FAIR Data Points, DCAT-AP endpoints, or other CKAN catalogues to synchronise datasets continuously. - Manage datasets manually: Create and update individual datasets through the catalogue interface—add detailed metadata, upload resources, and ensure data quality standards are met. :::info Datasets flow to the Data Portal All datasets you manage in this Data Catalogue are displayed in the public-facing GDI Data Portal↗, making them discoverable to researchers across Europe. Your work ensures high-quality genomic data is available for research and clinical purposes. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/what-is-a-dataset",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/what-is-a-dataset",
      "title": "what is a dataset",
      "content": "What is a dataset? In GDI, a dataset is a structured collection of genomic information pertaining to human health, diseases, and research studies. A dataset can be a single file or a collection of files that provide comprehensive information about a specific research topic, disease area, or study cohort. For example, a genomic data for _COVID-19 Viral Sequences_ can include dataset records describing _patient data_, _virus samples_, and _sequencing results_. When you add a dataset to the GDI Data Catalogue, you provide two types of information that together give a complete picture of the genomic subject: metadata describes the dataset itself, and data resources are the actual genomic data files associated with the dataset. Metadata Metadata (displayed as Additional Info in the portal) are descriptive details about your genomic dataset that provide context and information about the dataset itself. It includes details pertaining to: - Identification: Title, description, keywords, and unique identifiers - Responsibility: Contact points, publisher, creator, and data steward information - Access information: Rights, availability, licensing, and access restrictions - Others: Other key information that allows users to locate and access the data. Data resources Data resources pertain to the actual genomic data files associated with a dataset. In GDI, you can upload the file or provide links to external data resources. GDI supports common genomic data file formats, including: - VCF (Variant Call Format): For storing gene sequence variations - FASTA/FASTQ: For storing raw sequence reads - BAM/CRAM: For storing aligned sequence data - CSV/TSV: For storing tabular data such as phenotypic :::tip Organising datasets Datasets in GDI can be organised in several ways—such as by organisation and groups—to help you manage data effectively, while making it easy for researchers to find relevant datasets. ::: What's next: Add a dataset",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/about-gdi",
      "url": "/gdi-userportal-frontend/system-admin-guide/about-gdi",
      "title": "About GDI",
      "content": "",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/configure-auth",
      "url": "/gdi-userportal-frontend/system-admin-guide/configure-auth",
      "title": "configure auth",
      "content": "Set up authentication and authorisation The GDI User Portal uses Keycloak for authentication and authorisation, with integration to LS-AAI (Life Science Authentication and Authorisation Infrastructure) for federated access across European research infrastructures. Authentication architecture Keycloak configuration Keycloak serves as the central authentication provider, managing user sessions, roles, and permissions across all platform components. LS-AAI integration Integration with LS-AAI enables users to authenticate using their existing institutional credentials through the European research federation. User role management Configure role-based access control to ensure appropriate permissions for different user types (data users, catalogue managers, system administrators). Configuration tasks Configure Keycloak Set up Keycloak instance with proper realm configuration, client settings, and security policies. Integrate with LS-AAI Configure LS-AAI as an identity provider in Keycloak, including OpenID Connect settings and attribute mapping. Manage user roles Define and manage user roles and permissions to control access to different platform features and data. Identity providers configuration When configuring identity providers (IdPs), you'll need: - ClientSecret - Provided by the IdP during registration - ClientId - Unique identifier for your application - Token URL - OAuth2 token endpoint - Authorisation URL - OAuth2 authorisation endpoint - Redirect URI - Keycloak callback URL Azure AD integration Configure Azure Active Directory as an identity provider for organisational authentication. LS-AAI integration details - Discovery endpoint: - Required scopes: , , , - Sync mode: Import (not force) - Token storage: Enabled for Beacon Network integration Security considerations Token management Proper configuration of token storage and refresh to enable secure API access across services. Access control Implementation of proper access control policies to protect sensitive data and administrative functions. Audit and monitoring Set up logging and monitoring for authentication events and security incidents. :::info content in progress We are working on this guide. :::",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/configure-ls-aai-in-keycloak/keycloak-setup",
      "url": "/gdi-userportal-frontend/system-admin-guide/configure-ls-aai-in-keycloak/keycloak-setup",
      "title": "keycloak setup",
      "content": "Configure LS-AAI in Keycloak Keycloak can be obtained by running the CKAN deployment script that you can find in the following guide: Azure CLI Script Deployment Guide Configuring Identity Providers (IdPs) When configuring identity providers (IdPs), the following information becomes crucial for OpenID setup: - ClientSecret - ClientId - Token URL - Authorization URL - Redirect URI Both the 'Token URL' and 'Authorization URL' are derived from the IdP. When registering a service, you acquire the clientId and secret. The 'Redirect URI', which remains constant, is provided by Keycloak: Additionally, the corresponding configuration entails: - Scopes: \"openid\", \"profile\", \"email\" , \"elixir_id\" - Method: POST the Clientsecret - Sync method: import For Elixer_id additional mapper is needed Azure AD For Azure integration, I followed the tutorial at https://www.youtube.com/watch?v=LYF-NLHD2uQ. This tutorial comprehensively explains both the service registration and the Azure AD setup within Keycloak. Management of the app registration is done within our Ad: portal.zure.com LSAAI To register Keycloak as service I used https://elixir-europe.org/platforms/compute/aai/service-providers. . Initially, obtaining an account is the first step. 1. Make sure your organisation is recognised as IdP and register if not. 2. Submit a registration for you application as a service. Please note that approval for this step may entail a waiting period. Management of the app registration is done within: https://services.aai.lifescience-ri.eu . Discovery endpoint: https://login.elixir-czech.org/oidc/.well-known/openid-configuration The LSAAI configuration looks like: !LSAAI Configuration Part 1 !LSAAI Configuration Part 2 Note 1: Sync mode must be \"import\" instead of \"force\"\\ Note 2: and must be on, to allow User Portal components to get LS-AAI . That enables Beacon Network integration via Oauth2.\\ The first time you log in you will get a question if you want to be a member of the test environment. Agree and proceed. Fetching LS-AAI Access Token from Keycloak Option 1 In order to fetch access token from LS-AAI - or any IdP - one needs to configure Keycloak accordingly, and later request to Keycloak LS-AAI tokens. 1. Go to ; 2. Enable and ; 3. Delete LS-AAI existing users, to ensure users are initialised correctly in Keycloak; 4. Login with a LS-AAI user; 5. Call Keycloak endpoint: Option 2: Configuring OAuth 2.0 in Postman This guide will help you set up OAuth 2.0 authorization for a request in Postman and obtaining the LSAAI token. Steps to Configure OAuth 2.0 1. Open Postman Application Begin by opening the Postman application on your desktop. 2. Select a Request - Choose any existing request from your collections, or create a new one by clicking on the 'New' button and selecting 'Request'. 3. Authorization Setup - Navigate to the 'Authorization' tab within the selected request. 4. Set Authorization Type - From the 'Type' dropdown menu, select 'OAuth 2.0'. 5. Add Authorization Data to Request Headers - In the 'Add authorization data to' dropdown, select 'Request Headers'. 6. Current Token Configuration - For the 'Current Token' section, choose 'Bearer' as the token type. 7. Configure New Token Follow the steps below to configure a new token: - Token Name: Enter a random name for your token. - Grant Type: Select 'Authorization Code' from the dropdown menu. - Authorize Using Browser: Ensure this box is checked to use your default web browser for the authorization. - Auth URL: Replace and with the appropriate values for your Keycloak server and realm. - Access Token URL: Similar to the Auth URL, fill in the Keycloak server and realm information. - Client ID: Enter 'ckan' or the specific client ID you have been provided. - Client Secret: Enter the client secret you obtained from Keycloak that corresponds to your client ID. - Scope: Input the scopes as . - Client Authentication: Select 'Send as Basic Auth header' from the dropdown menu. 8. Obtain Access Token - Click on the 'Get New Access Token' button to initiate the OAuth 2.0 authorization flow. After completing these steps, you should be able to receive an access token that can be used to authorize your requests within Postman, which is containing also an Elixer Id",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/configure-schemas",
      "url": "/gdi-userportal-frontend/system-admin-guide/configure-schemas",
      "title": "configure schemas",
      "content": "Configure metadata schemas Configure and manage CKAN metadata schemas to define dataset fields, validation rules, and data entry forms. This guide covers schema development, deployment, and maintenance for system administrators. Schema structure and format CKAN schemas can be defined as JSON or YAML files that specify dataset metadata fields and their properties. Example field definition Key field properties Configure field behaviour using these properties: - field_name: CKAN field identifier - label: UI field representation for end users - help_text: Explanatory text appearing under field in UI - choices: For dropdown menus - list of dictionaries with value and label - choices_helper: Form dropdowns dynamically from API - presets: Values like , , for automatic checks - form_snippet: Defines field representation for data input (jinja2 format) - display_snippet: Defines how data is shown in UI - validators: Data validation functions - output_validators: Convert complex data structures from database Schema configuration Single schema setup Configure your primary schema in CKAN configuration: Multiple schema support Configure multiple schemas using a declaration file for different dataset types: Reference the multi-schema file in : Schema deployment Update running CKAN instance To change schema in a running Docker container: Changes to trigger automatic CKAN updates. Schema path format Define schemas using the format: Example: Schema management APIs Use CKAN APIs to manage schemas programmatically: Best practices Schema design - Follow DCAT-AP standards for interoperability - Design for user experience, not just technical requirements - Include comprehensive help text for complex fields - Test schemas with real users before deployment Deployment - Test schema changes in development environment first - Document all schema modifications - Consider migration impact on existing datasets - Backup data before major schema updates For comprehensive schema development, see the CKAN scheming documentation. Next steps After configuring schemas: - Manage user roles and permissions - Control access to schema management - Manage data and services - Configure data workflows - Monitor and maintain the system - Track schema usage and performance",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/deploy-infrastructure",
      "url": "/gdi-userportal-frontend/system-admin-guide/deploy-infrastructure",
      "title": "deploy infrastructure",
      "content": "Deploy infrastructure :::info content in progress We are working on this guide. ::: The GDI User Portal consists of multiple interconnected components that require careful deployment and configuration. This section provides comprehensive guidance for system administrators on setting up production-ready infrastructure. Deployment options Deploy to Azure Complete guide for deploying the GDI User Portal on Microsoft Azure infrastructure, including resource provisioning, networking, and security configuration. Deploy to ELIXIR-LU Specific instructions for deploying to ELIXIR Luxembourg infrastructure, tailored for genomic data infrastructure requirements. Configure Docker containers All components run as Docker containers. Learn about container orchestration, networking, and persistent storage configuration. Manage environments Best practices for managing multiple environments (development, staging, production) and environment-specific configuration. Component installation User Portal Frontend The frontend provides the web interface and integrates with backend services. Built with Next.js for optimal performance and user experience. Installation guide: User Portal Frontend README Dataset Discovery Service (DDS) Backend service that mediates between the frontend and CKAN, providing abstraction and enhanced functionality. Installation guide: Dataset Discovery Service README Access Management Service (AMS) Handles access requests, user permissions, and integration with external systems like REMS. Installation guide: Access Management Service README CKAN Extensions The platform uses several custom CKAN extensions that must be properly integrated: - GDI Userportal Ckanext - Core GDI functionality - Fair Datapoint Ckanext - FAIR principles support - Harvest Ckanext - Data harvesting capabilities For extension integration, see the CKAN Docker repository installation guide.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/fdp/fair-data-point",
      "url": "/gdi-userportal-frontend/system-admin-guide/fdp/fair-data-point",
      "title": "fair data point",
      "content": "FAIR data point setup Fair Data Point (FDP) Installation Guide This guide provides steps to install FDP and configure it with GDI-specific SHACL shapes. For a more comprehensive overview, please refer to the existing FDP documentation on exposing metadata. 1. Installing FDP 1. Follow the installation guide in the documentation linked above to set up FDP in your environment. 2. Ensure that the FDP instance is accessible and that you have administrative rights to configure metadata schemas. 2. Installing GDI-Specific SHACLs To add GDI-specific SHACL validation, perform the following steps: Step 1: Download SHACL Shapes - Access the GDI-specific SHACL shapes from this GDI metadata repository. - Download each SHACL shape file (e.g., and others). Step 2: Upload SHACL Shapes to FDP 1. Login to FDP using an admin account. 2. Navigate to Metadata Schemas (located in the dropdown under your username). 3. For each shape file: - Open the editor and paste the contents of (or other shapes). - Add a description to document the purpose or release information. - Ensure the abstract checkbox is selected when uploading , as most other classes derive from it. - For other shapes, uncheck the abstract checkbox. - Press Save and Release to finalize the shape. - Provide a meaningful description and version number for the release. - Check the public checkbox to make the shape accessible. - Press Release to complete the upload. Repeat these steps for each SHACL shape file. 3. Supported Metadata Fields for Datasets The following metadata fields are currently supported: Dataset | Property Name | Example Data | | ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | contact_point | VCard(hasEmail=[mailto:data-access-committee@xumc.nl], full_name=[Data Access Committee of the x UMC], hasUID=https://ror.org/05wg1m734) | | creator | Agent(name=[Academic Medical Center], identifier=https://ror.org/05wg1m734) | | description | This dataset is part of the GDI MS8 milestone, focused on the distributed analysis of COVID-19 cases (GWAS) and allele frequency lookup for infectious diseases. It contains synthetic data designed to replicate COVID-19-related genetic studies, including risk variants associated with severe disease outcomes. The data is used for federated analysis across multiple nodes to identify genomic associations and variant prevalence. | | number_of_patients | 100 | | issued | 2024-07-01T11:11:11 | | keywords | Covid, Smokers, (free to choose) | | identifier | GDID-[0-9a-f]{8}-[0-9a-f]{4} | | modified | 2024-06-04T13:36:10.246Z | | publisher | Agent(name=[Radboud University Medical Center], identifier=https://ror.org/05wg1m734, mbox=[mailto:test@health-ri.nl]) | | theme | http://publications.europa.eu/resource/authority/data-theme/HEAL | | title | COVID-19 GWAS and Allele Frequency Lookup Dataset for GDI MS 8 | | number_of_participant | 100 | | phenotypes | Age (min and max) | | accessRights | DUO:0000006, DUO:0000017, DUO:0000018 (General research use, Infectious Disease research use, Genomic research on complex diseases) | Distribution | Property Name | Example Data | | --------------- | ------------------------------------------------------------------------- | | title | GWAS and Allele Frequency Lookup Data Distribution for GDI MS8 | | description | VCF file containing COVID-19 case/control data for GDI MS8 demonstration. | | access_url | https://example.com/dataset/GDI-MS8-COVID19.vcf | | media_type | https://www.iana.org/assignments/media-types/application/vcf | | license | https://creativecommons.org/licenses/by-sa/4.0/ | 4. Onboarding Metadata To onboard large datasets more efficiently, you can use a Jupyter notebook to automate this process. Clone the Sempyro repository and run the notebook using: As a reference, an MS8 template/example is available in the notebook for streamlined metadata upload to FDP.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/installation/azure",
      "url": "/gdi-userportal-frontend/system-admin-guide/installation/azure",
      "title": "azure",
      "content": "Azure CLI Script Deployment Guide for a Catalogue with CKAN This guide will walk you through the process of deploying an environment using Azure CLI that includes a CKAN container, Frond end catalogue, SOLR for CKAN, Keycloak for authentication, a managed PostgreSQL server, and Redis Cache. This environment is suitable for development purposes, and further security and performance reviews are necessary for production deployment. Prerequisites - Azure CLI installed: Make sure you have Azure CLI installed on your machine. You can install it via Homebrew with the command . - GitHub Personal Access Token (classic): You'll need a personal access token from GitHub with pack read permissions. - Azure Account with Sufficient Permissions: Ensure you have an Azure account with permissions that, at a minimum, allow you to create a resource group. - PSQL installed: Ensure that PSQL is installed (e.g. ) Initial Setup Before running the script, you'll find several parameters at the beginning of the script that can be customized: - Passwords for the CKAN database, Keycloak database, and the PostgreSQL admin. Change these to secure passwords as desired. Deployment Steps 1. Execute the Script: - Navigate to the deployment project at GenomicDataInfrastructure/gdi-userportal-deployment. - Go to the Azure deployment folder - Run to start the deployment process. 2. Enter Required Information: - The script will prompt you to enter the necessary information. Fill in the details as requested. 3. Script Execution: - After entering the information, the script will automatically execute, setting up the environment and deploying the code. It typically takes about 10 minutes for the entire process to complete and for the services to be up and running. 4. Verification: - Once the script execution is complete, verify that all components are online by accessing the following URLs, replacing with your project name and with your environment name: - SOLR: - CKAN: - Catalog: - Keycloak: 5. Import CKAN Realm into Keycloak: - After verifying that all components are online, the next step is to import the CKAN realm into Keycloak. Log in to Keycloak using the admin account to perform this action. (creditials can be found in the script) Components Included - Azure Web App with CKAN Container: Runs a CKAN container from the main branch of the gdi-userportal-ckan-docker repository. - Azure Web App with Front Catalog: Originates from the main branch of the gdi-userportal-frontend repository. - Azure Web App with SOLR for CKAN: Dedicated SOLR instance for CKAN. - Azure Web App with Keycloak: For authentication and authorization. - Managed PostgreSQL Server: Includes a Keycloak database and a CKAN database. - Managed Redis Cache: For caching purposes to enhance performance. Note This setup is intended for development use. Before moving to a production environment, review and adjust the security and performance settings to meet the necessary requirements.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/installation/components",
      "url": "/gdi-userportal-frontend/system-admin-guide/installation/components",
      "title": "components",
      "content": "Installation guides The user portal consists of multiple components. To install or contribute to a specific component, refer to the respective installation guide linked below. All components run on Docker containers, and their individual setups are documented in their respective repositories. Components User Portal Frontend The User Portal Frontend, built with Next.js, provides a web interface for interacting with key services, including the Dataset Discovery Service (DDS) and the Access Management Service (AMS). It acts as the primary user interface for the GDI project. Installation guide: User Portal Frontend README Dataset Discovery Service (DDS) The Dataset Discovery Service acts as a backend layer mediating requests from the frontend to CKAN’s data catalog APIs. It retrieves, processes, and maps dataset information while abstracting CKAN-specific logic. To use DDS, ensure that the GDI CKAN extension is installed in your CKAN instance. Installation guide: Dataset Discovery Service README Access Management Service (AMS) The Access Management Service ensures secure interactions between the frontend and backend data authorities. It provides APIs for managing user access requests and integrates with external APIs like REMS to enforce policies and track user actions. Installation guide: Access Management Service README CKAN Extensions CKAN is an open-source data management system for publishing, sharing, and discovering datasets. It enables cataloging, searching, and accessing data through a web interface and API. Custom extensions can be developed to extend CKAN’s core functionalities. The User Portal uses several extensions, including one specifically developed for this project. Extensions used include (but are not limited to): - GDI Userportal Ckanext: Adds a DCAT-AP 3 compatible schema with fields such as , , , and . It also provides enhanced parsing for creators in the DCAT profile, adds support for OpenID Connect with PKCE, introduces new fields to , and links CKAN harvest views for admin users. Additionally, it offers endpoints for listing unique values and simplifies integration with CKAN-based datasets for the User Portal. - Fair Datapoint Ckanext: Provides features related to FAIR principles to enhance dataset accessibility and interoperability. - Harvest Ckanext: Supports automated data harvesting and integration with external data sources. In order to contribute on a ckan extension and run it on you local machine, it must be integrated into the docker build that will run as your backend service, connected to your DDS instance. For a detailed guide on how to integrate the extention, read 5. installing new extensions from the CKAN Docker repository",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/installation/elixir-lu",
      "url": "/gdi-userportal-frontend/system-admin-guide/installation/elixir-lu",
      "title": "elixir lu",
      "content": "Current deployment - - User Portal - - IAM - - API Gateway - - Catalogue Deployment Steps 1. Checkout . 2. Copy into the server and update all the secrets. 3. Run . 4. Run . 5. Run . 6. Enter in REMS docker container. 7. Configure the admin user. 8. Configure apikey, for any user and any REST method, but limited to . 9. Configure apikey and robot for any REST method, but limited to . 10. Configure apikey and robot, limited to . 11. Include in the environment variables the newly created apikeys and users. 12. Run . 13. Log into CKAN as sysadmin. 14. Add the harvest sources. 15. Wait for REMS Synchronizer or run it manually. 16. Access Keycloak. 17. Configure LS-AAI IdP. 18. Add mapper, that maps the clain clain into . 19. Create a new OIDC realm for GDI, that accepts redirections to User Portal, CKAN and REMS. 20. Create a new client scope for GDI realm. 21. Add new User Attribute Mapper, that maps the attribute into a claim called and a scope called . 22. Create a new client for User Portal, REMS and CKAN. 23. Add the scope into the newly created client.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/manage-data-services",
      "url": "/gdi-userportal-frontend/system-admin-guide/manage-data-services",
      "title": "manage data services",
      "content": "Manage data and services :::info content in progress We are working on this guide. ::: This section covers the administration of core data management services including CKAN administration, FAIR Data Point deployment, harvester configuration, and database management. Data service components Administer CKAN CKAN serves as the core data catalogue system. Learn about user management, organisation setup, dataset administration, and system maintenance. Set up FAIR Data Points FAIR Data Points provide standardised metadata endpoints that support FAIR principles. Configure FDP instances with GDI-specific SHACL shapes and metadata requirements. Configure harvesters Set up automated data harvesting from external sources including other CKAN instances, FAIR Data Points, and DCAT-AP endpoints. Manage databases Maintain database performance, backups, and integrity across PostgreSQL instances used by CKAN and other services. CKAN administration System configuration - Instance configuration and settings - Extension management and updates - Performance tuning and optimisation - Security configuration and updates User and organisation management - User account administration - Organisation setup and management - Permission and role assignment - API key management Data management - Dataset lifecycle management - Metadata quality assurance - Storage and backup procedures - Search index maintenance FAIR Data Point setup Installation and configuration Deploy FDP instances with GDI-specific requirements and configure metadata schemas using SHACL shapes. Metadata schema configuration Install and configure GDI-specific SHACL shapes for consistent metadata representation across the network. Supported metadata fields Comprehensive coverage of dataset and distribution metadata fields including contact points, creators, themes, and access rights. Harvesting configuration Harvester setup - Configure harvest sources and schedules - Set up authentication for protected endpoints - Monitor harvest job performance - Troubleshoot harvest failures Data source integration - FAIR Data Point harvesting - DCAT-AP endpoint harvesting - Custom API integration - Real-time vs. scheduled synchronisation Database management Performance monitoring - Query performance analysis - Index optimisation - Connection pool management - Resource utilisation tracking Backup and recovery - Automated backup procedures - Point-in-time recovery - Disaster recovery planning - Data integrity verification",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/manage-schemas",
      "url": "/gdi-userportal-frontend/system-admin-guide/manage-schemas",
      "title": "manage schemas",
      "content": "Manage schemas :::info content in progress We are working on this guide. ::: Learn how to configure and manage CKAN dataset schemas for the GDI User Portal. This guide covers schema format, field definitions, and deployment procedures. Schema format and field definitions A CKAN schema can be defined either as JSON or YAML file. The GDI User Portal uses JSON schemas for consistency. Field structure A field in CKAN schema JSON file has the following format: Where: - - CKAN field identifier - - UI field representation - - Text appearing under field in UI next to icon. Square brackets contain DCAT-AP mapping information Field configuration options Documentation on field keys and specifications can be found in the CKAN Scheming documentation. Available field keys include: - - For handling cardinality requirements - - Controls field appearance on multi-stage forms - - For dropdown lists (array of dictionaries with value and label) - - For dynamic dropdowns or API-driven choices - - Built-in field types (, , ) - - Custom field representation (Jinja2-based format) - - Custom data display formatting - - Override representation for DCAT mapping Example with display property: Validation configuration - - Data validation functions. Available functions listed in CKAN validators documentation - - Convert complex data structures from database storage back to objects Important: Default validation includes and . When specifying custom validators, include these explicitly if needed. Changing schemas in running instance Schema configuration Schema is defined in setup scripts by setting: Runtime schema changes In running Docker container, schema is configured in : Configuration changes trigger automatic CKAN updates. Schema path format Schema paths follow format: Example: resolves to extension directory structure under Multi-schema configuration Configuration file approach For better maintainability, create a JSON configuration file under extension schemas directory: Multiple dataset types Support for multiple schema types: Configure in : Schema merging behaviour - Core CKAN: Latest schema with same takes precedence - GDI implementation: Schemas with same type are merged, field order follows schema order in configuration - Field merging: Controlled by parameter - : Latest field definitions take precedence - Fields are never deleted, only added or modified - To remove fields, explicitly undeclare or set to empty API management List available schemas Get specific schema Search configuration Control dataset type visibility in search with:",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/manage-user-roles",
      "url": "/gdi-userportal-frontend/system-admin-guide/manage-user-roles",
      "title": "manage user roles",
      "content": "Manage user roles and permissions Configure and manage user access levels within the CKAN data catalogue system. This guide covers platform-wide and organisation-specific role management for system administrators. CKAN user role hierarchy Understanding CKAN user roles is essential for effective system administration. CKAN operates with two levels of roles: Platform-level roles 1. Visitor - Capabilities: Search and view public datasets - Access level: Anonymous/unauthenticated users 2. Registered User - Capabilities: - Become a member of an organisation (requires admin approval) - Publish, edit, or add datasets based on their role in the organisation - Manage their own profile - Configuration note: Creation of organisations is typically disabled for regular users 3. Sysadmin - Capabilities: - Access and edit any organisations - View and change user details - Permanently delete datasets - Customise the look and feel of the platform - Configure system-wide settings Organisation-level roles 1. Member - Capabilities: View the organisation's private datasets - Use case: Users who need access to restricted organisational data 2. Editor - Capabilities: - All capabilities of a Member - Add new datasets to the organisation - Edit or delete any of the organisation's datasets - Make datasets public or private - Use case: Content contributors and data curators 3. Organisation Admin - Capabilities: - All capabilities of an Editor - Add users to the organisation, and set their role (member, editor, or admin) - Change the role of any user in the organisation, including other admin users - Remove members, editors, or other admins from the organisation - Edit the organisation's details (e.g., title, description, image) - Delete the organisation - Use case: Organisational data stewards and managers User management procedures Configure platform roles Use CKAN's admin interface to manage platform-level user permissions and system access. Set up organisation permissions Configure organisation-specific roles and manage member access to datasets within organisational boundaries. Role assignment best practices - Follow principle of least privilege - Regular audit of user permissions - Document role assignments and changes - Implement approval workflows for sensitive roles For detailed role management procedures, see the CKAN authorisation documentation. Activity monitoring and auditing Monitor user activity and dataset changes to maintain data integrity and track catalogue usage. Enable activity streams CKAN displays a full history of dataset changes in the Activity Stream. For new installations, this is enabled by default, but upgrades may need manual activation. To make activity history public, add this to your file: Note: Since CKAN 2.10, Activity must be activated as a plugin. See the CKAN 2.10 changelog for details. Activity monitoring levels Configure activity tracking at different levels: - Organisation level - Track all changes within an organisation - Dataset level - Monitor specific dataset modifications - Difference view - See detailed changes between versions - User activity - Track individual user actions and access patterns Audit configuration For complete activity configuration options, see CKAN activity settings documentation. Next steps After configuring user roles: - Manage data and services - Set up data management workflows - Monitor and maintain the system - Ongoing system maintenance - Deploy and manage infrastructure - Infrastructure management",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/monitor-maintain",
      "url": "/gdi-userportal-frontend/system-admin-guide/monitor-maintain",
      "title": "monitor maintain",
      "content": "Monitor and maintain the system :::info content in progress We are working on this guide. ::: Ongoing monitoring and maintenance are crucial for ensuring the reliability, security, and performance of your GDI User Portal deployment. This section covers monitoring tools, maintenance procedures, and troubleshooting approaches. Monitoring components Monitor performance Track system performance metrics including response times, resource utilisation, and user activity to ensure optimal platform operation. Audit security Implement comprehensive security monitoring including access logging, intrusion detection, and compliance verification. Back up data Establish reliable backup procedures for all critical data including CKAN databases, configuration files, and user data. Publish new versions Manage platform updates and version deployments with minimal downtime and proper rollback procedures. Performance monitoring",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/platform-overview",
      "url": "/gdi-userportal-frontend/system-admin-guide/platform-overview",
      "title": "platform overview",
      "content": "Platform overview :::info content in progress This section will describe architecture, components, and interactions at a high level. ::: The GDI User Portal consists of multiple interconnected components: - User Portal Frontend - Next.js web interface providing the user experience - Dataset Discovery Service (DDS) - Backend API layer mediating frontend-CKAN communication - Access Management Service (AMS) - Access control and data request management - CKAN - Open-source data catalogue management system with custom extensions - Keycloak - Authentication and authorisation service - Supporting services - PostgreSQL, Elasticsearch/Solr, Redis, Docker containers",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/publishing-new-version/release-process",
      "url": "/gdi-userportal-frontend/system-admin-guide/publishing-new-version/release-process",
      "title": "release process",
      "content": "Publishing new versions > All repositories must follow the same process. > Once all necessary changes are merged to , please follow this process: - Ensure is up to date. - Push a new tag following the versioning and releases described in this page. The tag name follows . Example: - Create a new release branch, to simplify bugfixing and security patches. The branch name follows . Example: - Stage the Commit the : Push the branch to the remote repository - Go to GitHub and create a new release, example: - Click on \"Draft a new release\" CHANGELOG - Select the just created release branch and tag. - Enter a title for the release that includes the version and possibly a short description. - Auto-generate release notes. - Remove unnecessary release notes: ensure that only relevant information for the users is included and matches CHANGELOG.md. - Double-check all entered information. - Click on \"Publish release\" to officially make the release. - Ensure docker images were built and published correctly.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/welcome",
      "url": "/gdi-userportal-frontend/system-admin-guide/welcome",
      "title": "welcome",
      "content": "Welcome, system administrators :::info content in progress We are working on this deployment guide. ::: Welcome to the GDI User Portal System Administration Guide! This comprehensive documentation is designed for system administrators responsible for deploying, configuring, and maintaining the GDI User Portal platform and its associated services. Get started Choose your focus area based on your immediate needs: - New deployment? Start with Deploy and manage infrastructure - Setting up users? Begin with Set up authentication and authorisation - Managing access? Go to Manage user roles and permissions - Configuring data? Check out Manage data and services - System health? Explore Monitor and maintain the system This guide provides the technical knowledge you need to successfully deploy and maintain the GDI User Portal platform for the European genomic data research community.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/about-gdi",
      "url": "/gdi-userportal-frontend/developer-guide/about-gdi",
      "title": "About GDI",
      "content": "",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/add-data-resource",
      "url": "/gdi-userportal-frontend/developer-guide/add-data-resource",
      "title": "add data resource",
      "content": "Add data resources In this guide > Add a data resource > Reorder data resources :::tip Full documentation This guide covers the common tasks for managing datasets. For detailed instructions on all dataset operations, see the CKAN Dataset Guide↗. CKAN is the system that powers the GDI Data Catalogue. ::: Add a data resource Add more files or links to your dataset to provide comprehensive genomic information. A data resource represents the actual data described by your dataset. New to adding data resources? Learn about data resources and their significance in datasets. To add a data resource to your dataset: 1. Open the dataset you want to add a data resource to. 2. On the dataset details page, select Manage. 3. On the left panel under Resources, select Add new resource. 4. Fill out the data resource form. For guidance on filling out the form, see the definition of properties in the DCAT-AP Vocabulary. 5. Select Update Dataset to save the data resource. Once the data resource is added, it appears in the list of data resources for the dataset. Repeat the steps to add more data resources as needed. Reorder data resources Reorder data resources to prioritise the most important or frequently accessed files or links. The order of data resources determines their display sequence on the Data Portal and dataset details page. To reorder data resources: 1. On the dataset details page, select Manage. 2. Select the Resources tab. The list of data resources appears. 3. Drag and drop the data resources to reorder them as desired. 4. Select Save order. The data resources are reordered and displayed in the new sequence on the dataset details page and the Data Portal.",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/add-modify-features",
      "url": "/gdi-userportal-frontend/developer-guide/add-modify-features",
      "title": "add modify features",
      "content": "Add and modify features :::info content in progress We are working on this guide. ::: This section covers advanced development topics including metadata field management, extension development, and comprehensive testing strategies for adding new features to the GDI User Portal. Feature development overview Adding new features to the GDI User Portal typically involves: 1. Frontend development - User interface and experience 2. Backend integration - API endpoints and data processing 3. Metadata management - Schema updates and field additions 4. Testing - Comprehensive testing across all layers 5. Documentation - User and developer documentation Metadata field management Manage metadata fields Adding, modifying, or deleting metadata fields requires updates across multiple components of the CKAN ecosystem. Process overview When adding new metadata fields, you must update: 1. CKAN DCAT model - Core schema definition 2. Solr search integration - Search indexing 3. FAIR Data Point - SHACL shapes 4. SeMPyRO - Metadata automation 5. Discovery Service - API mapping CKAN DCAT model updates For DCAT-AP 3 compliant fields: Example schema addition: Solr Search Configuration To make fields searchable: After changes, rebuild the search index: FAIR Data Point integration Add SHACL shapes in FDP: SeMPyRO integration Add property to relevant class: Discovery Service mapping Update OpenAPI definitions and mapping: For complete metadata field procedures, see Metadata field management. Extension development Develop extensions CKAN extensions provide powerful capabilities to enhance catalogue functionality. Extension structure Plugin development Custom Validators Template Customization Testing Strategies Write and Run Tests Comprehensive testing ensures feature reliability and maintainability. Frontend Testing API Integration Testing E2E Testing Extension Testing Performance Considerations Optimization Strategies - Database Indexing - Ensure proper indexes for new fields - Caching - Implement appropriate caching for expensive operations - Lazy Loading - Load heavy components only when needed - Bundle Optimization - Minimize JavaScript bundle size Monitoring",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/add-update-metadata-fields/metadata-fields",
      "url": "/gdi-userportal-frontend/developer-guide/add-update-metadata-fields/metadata-fields",
      "title": "metadata fields",
      "content": "Add and update metadata fields :::info content in progress We are working on this guide. ::: This document outlines the steps required to add, modify, or delete fields across various components of the CKAN ecosystem, including DCAT-AP schema updates, Solr search configuration, SeMPyRO, Discovery Service, and FAIR Data Point (FDP). CKAN DCAT Model When a schema change falls under DCAT-AP 3 or an earlier version of DCAT-AP but is not yet present, follow these steps: 1. Fork and clone the repository: 2. Add the new field to the schema: - Modify the schema file: - Use appropriate field types (e.g., text, repeating subfield, URI). - Follow examples from other fields for consistency. For more information about scheming can be found in the CKAN Scheming documentation 3. Extend the existing mapping depending on the DCAT-AP version: Modify the mapping files located in the directory: 4. Fix the corresponding unit tests: 5. Create a pull request to the CKAN DCAT extension repository. Ensure that you follow the contributing guidelines for CKAN: - Include unit tests for the new fields. - Ensure compatibility across different DCAT-AP versions. 6. Update the following repositories after a new release: Update development and production Dockerfiles in these repositories( order is important): - https://github.com/GenomicDataInfrastructure/gdi-userportal-ckanext-fairdatapoint - https://github.com/GenomicDataInfrastructure/gdi-userportal-ckan-docker Check if ckan locally works with the new added fields by harvesting an example FDP Example of new field An example of a missing mapping in CKAN DCAT can be found here: Multi-valued field creator in CKAN DCAT. > Note: Always take into account the mapping from CKAN → DCAT in addition to DCAT → CKAN. --- Solr Search Integration If you're adding a new field in CKAN and you want it to be searchable via Solr, follow these steps to modify the file. Steps to Add and Configure a Searchable Field 1. Defining the Field Type and Name In the top part of the file, define the type and name of the new field. The type specifies how Solr will handle the data in the field (e.g., as , , , etc.). - Navigate to the section in where other fields are defined. - Add your new field with its corresponding type. Example: Here, custom_field is the name of the field, and it's set as a string type. It is also indexed (which makes it searchable) and stored (so it can be returned in search results). 2. Adding the Field to Search In the lower part of the schema.xml file, you'll need to add this field to the list of fields that are searchable by Solr. This is typically done in a section that defines which fields are indexed for searches. Example: This example maps the custom_field to the text field, which Solr uses for full-text searches. By adding the copyField directive, you're instructing Solr to include the contents of custom_field in the search index 3. When finished. Release a new version and update When finished. Release a new version and update GitHub - GenomicDataInfrastructure/gdi-userportal-ckan-docker: Scripts and images to run CKAN using Docker Compose in the development and production dockerfile Notes Indexing vs Storing: - indexed=\"true\": The field can be used in searches. - stored=\"true\": The field can be retrieved in search results. Testing the Configuration: After making these changes, you should restart your Solr instance and reindex your CKAN data to ensure that the new field is indexed and searchable with the command: SeMPyRO Prerequisites Fields are easy to add to SeMPyRO. You’ll need to know a few things: - The predicate of the field - Cardinality (single or multiple-valued) - Range or datatype Adding a Field Once that’s identified, go to the relevant class and add a property as follows. Here’s an example of the property of : At Line 1, we see , which is the name of the property. Its range is an , which is a helper for any URL. Other examples of this are or sometimes even classes like or . It is multi-valued because it's in a . If the maximum cardinality is one, it should not be in a . At Line 2, indicates the field is optional and by default undefined. Leave this line out for mandatory fields. At Line 3, we have a human-readable description of the field. At Line 4, we define the predicate. In this case, it's . Some common namespaces, like and , are imported by default. A full URI can also be defined, for example with . At Line 5, we define the RDF type. There are many possible values here, such as , , or . It's recommended to take a look at other properties to understand what is necessary here. Once this is done, the JSON and YAML schemas need to be re-generated. For the class, this can be done by running the following command: FAIR Data Point For the technical point of view, updating the appropriate SHACL shapes allows for adding of fields. Steps to Add a Field in FDP: 1. In the FDP, log in as an admin user and go to the Metadata schemas option. 2. Select the resource to update (e.g. Catalog). 3. In the Form Definition textarea, add a new entry in the list of values. For example: 4. Click Save if this is a draft and needs further work, or Save and release if the work is done. 5. Add a description and select a version number. 6. Click Release. Discovery Service The Dataset Discovery service requires two parts to be updated: the OpenAPI definitions and the mapping. OpenAPI Definition Two definitions need to be updated, both located in the folder: - ckan.yaml: This file contains the API returned by CKAN. Based on this YAML, Java classes are automatically generated corresponding to the API definition. For adding a field to a Dataset, the primary change will likely be in the CkanPackage definition. See the examples there on how to add a property. - discovery.yaml: This file defines what the Discovery service should return. You can make this definition whatever you want it to be—it does not have to correspond one-to-one with CKAN. To add a property here, modify the RetrievedDataset definition. Again, see the examples in the file. Mapping Once you have changed the definitions, follow these steps: 1. Run the following command:",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/develop-ckan-extensions",
      "url": "/gdi-userportal-frontend/developer-guide/develop-ckan-extensions",
      "title": "develop ckan extensions",
      "content": "Develop CKAN extensions Learn how to develop and test custom CKAN extensions for the GDI User Portal. This guide covers local development setup, extension structure, and testing procedures. Local development setup To develop and test CKAN extensions locally, you need to set up a proper development environment: 1. Set up virtual environment Note: Keep the virtual environment activated during the entire installation process. 2. Install CKAN as a package 3. Troubleshoot common dependency issues psycopg2 building issues If installation of fails: 1. Edit the requirements file at 2. Change to 3. Reinstall dependencies and CKAN separately: PyYAML compatibility issues For CKAN v2.9.10, if you encounter this error: Downgrade PyYAML in requirements.txt from or to . 4. Install required extensions Extensions can be installed from local repositories or directly from GitHub. Install from local repository Example on macOS: Install from GitHub Install extension dependencies Example for ckanext-harvest: 5. Configure database Set up PostgreSQL database and specify database connection strings in both and . Testing CKAN extensions Testing strategy depends on extension functionality. CKAN provides helper functions for generating dummy data and cleaning databases. Testing setup 1. Install pytest-ckan: Should be in extension's 2. Configure test.ini: Point to CKAN's test configuration 3. Configure test-core.ini: Set correct database connection Recommendation: Use separate test database instance for extensions requiring database writes. Running tests Basic test execution Test with coverage PyCharm configuration Set environment variable: Testing best practices - Review CKAN testing documentation for detailed guidance - Use CKAN helper functions for data generation and cleanup - Write tests for all extension interfaces and validators - Test schema changes with various data scenarios - Include integration tests for API endpoints Extension development workflow For detailed extension development procedures, see: - Add and modify features - Complete feature development guide - Work with backend services - Integration patterns - CKAN extensions documentation - Official guide Next steps After setting up your development environment: - Add and modify features - Build complete features - Work with backend services - Integrate with GDI services - Get started - Review overall development setup",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/develop-frontend",
      "url": "/gdi-userportal-frontend/developer-guide/develop-frontend",
      "title": "develop frontend",
      "content": "Develop frontend features :::info content in progress We are working on this guide. ::: The GDI User Portal frontend is built with Next.js 13+ using the App Router, TypeScript, and Tailwind CSS. This section covers frontend development including theming, component development, and API integration. Frontend architecture Technology stack - Next.js 13+ with App Router for server-side rendering and routing - TypeScript for type safety and better developer experience - Tailwind CSS for utility-first styling and responsive design - React Hook Form for form handling and validation - SWR for data fetching and caching - Radix UI for accessible component primitives Component organisation Theme customisation and styling Customise themes and styling The GDI User Portal offers extensive customisation options through configuration files and CSS variables. Configuration-based theming Modify for site-wide customisation: CSS customisation Use to define colour schemes: Custom fonts 1. Add font files to 2. Define font faces in 3. Update Tailwind configuration for font usage Visual assets Replace default assets in : - - Header logo - - Footer logo - - Browser icon - - Homepage background For detailed theming documentation, see Frontend Customisation. Component development Build components Follow established patterns for creating new React components: Component guidelines - Use TypeScript for all components - Implement proper accessibility (ARIA labels, keyboard navigation) - Follow established naming conventions - Include comprehensive prop types - Write unit tests for component logic State management - Use React's built-in state management for local state - Implement custom hooks for complex state logic - Use SWR for server state management - Context providers for global application state API integration Integrate with APIs The frontend integrates with multiple backend services using consistent patterns. Data Fetching with SWR API Route Handlers Service integration patterns Dataset Discovery Service integration - Search and filter datasets - Retrieve dataset metadata - Handle pagination and sorting Access Management Service integration - Submit access requests - Track application status - Manage user permissions Authentication integration - Handle login/logout flows - Manage user sessions - Secure API communication Testing Frontend testing strategy Testing best practices - Test user interactions, not implementation details - Use semantic queries for element selection - Mock external API calls - Test accessibility compliance - Implement visual regression testing Development tools Code quality - ESLint for code linting - Prettier for code formatting - TypeScript for type checking - Husky for Git hooks Development workflow Performance optimisation Next.js optimisation - Use Next.js Image component for optimised images - Implement proper code splitting - Utilise server-side rendering where appropriate - Optimise bundle size with dynamic imports Accessibility - Follow WCAG guidelines - Test with screen readers - Ensure keyboard navigation - Implement proper ARIA attributes",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/get-started",
      "url": "/gdi-userportal-frontend/developer-guide/get-started",
      "title": "get started",
      "content": "Get started :::info content in progress We are working on this guide. ::: This guide helps you set up a complete development environment for the GDI User Portal platform, including all necessary tools and dependencies. Prerequisites Before you begin, ensure you have the following installed: - Node.js (version 18 or higher) - npm or yarn package manager - Git for version control - Docker and Docker Compose for containerised services - Java 11+ (for backend services) - PostgreSQL (for local database development) Development environment setup 1. Clone the repository 2. Install dependencies 3. Environment configuration Copy the example environment file and configure for local development: Edit with your local configuration settings: 4. Start development services Use Docker Compose to start the required backend services: This starts: - CKAN instance with GDI extensions - PostgreSQL database - Keycloak authentication server - Dataset Discovery Service - Access Management Service 5. Start the development server The application will be available at . Project structure Understanding the codebase organisation: Local development workflow 1. Feature development - Create feature branches from - Use descriptive commit messages - Follow the established coding conventions - Write tests for new functionality 2. Testing Run the test suite before committing: 3. Code quality Maintain code quality with automated tools: Backend services integration Dataset Discovery Service The DDS provides abstraction over CKAN APIs. For local development: - Repository: gdi-userportal-dataset-discovery-service - Local URL: Access Management Service The AMS handles access requests and user permissions: - Repository: gdi-userportal-access-management-service - Local URL:",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/theming/customise-frontend",
      "url": "/gdi-userportal-frontend/developer-guide/theming/customise-frontend",
      "title": "customise frontend",
      "content": "Frontend customisation :::info content in progress We are working on this guide. ::: The GDI User Portal offers extensive customisation options through configuration files and public assets. This guide will help you understand how to customise various aspects of the portal. Configuration options The following configuration options can be set in the file: | Variable Name | Explanation | Example Value | | ---------------------------------- | ----------------------------------------------- | --------------------------------------------------------- | | NEXT_PUBLIC_SITE_TITLE | Main title of the website | \"GDI - User Portal\" | | NEXT_PUBLIC_SITE_DESCRIPTION | Brief description of the site | \"Genomic Data Infrastructure User Portal\" | | NEXT_PUBLIC_HOMEPAGE_TITLE | Main heading on the homepage | \"WELCOME TO GDI\" | | NEXT_PUBLIC_HOMEPAGE_SUBTITLE | Subheading text on the homepage | \"The Genomic Data Infrastructure (GDI) project...\" | | NEXT_PUBLIC_HOMEPAGE_ABOUT_CONTENT | Detailed content for the about section | \"The Genomic Data Infrastructure (GDI) homepage...\" | | NEXT_PUBLIC_BANNER_LINK | Navigation link for the banner | \"/howto\" | | NEXT_PUBLIC_FOOTER_TEXT | Text displayed in the footer | \"GDI project receives funding from the European Union...\" | | NEXT_PUBLIC_LINKEDIN_URL | LinkedIn social media link | \"https://www.linkedin.com/company/gdi-euproject/\" | | NEXT_PUBLIC_TWITTER_URL | Twitter/X social media link | \"https://twitter.com/GDI_EUproject\" | | NEXT_PUBLIC_GITHUB_URL | GitHub repository link | \"https://github.com/GenomicDataInfrastructure\" | | NEXT_PUBLIC_WEBSITE_URL | Main project website link | \"https://gdi.onemilliongenomes.eu/\" | | NEXT_PUBLIC_EMAIL | Contact email address | \"gdi-coordination@elixir-europe.org\" | | NEXT_PUBLIC_SHOW_BASKET_AND_LOGIN | Feature flag for basket and login functionality | \"true\" | Public assets customisation The portal's appearance can be customised through various files in the directory: Core configuration files 1. : Contains main site configuration including: - Site title and description - Homepage content and titles - Social media links - Contact information - Footer text - Feature flags 2. : Defines the colour scheme including: - Primary and secondary colours - Info and warning colours - Hover states - Surface colours - Dark mode support Visual assets 1. Logos: - : Main logo displayed in the header - : Logo displayed in the footer - : Browser tab icon 2. Images: - : Background image for the about section Typography 1. : Custom font definitions and typography settings 2. directory: Contains custom font files Content files 1. : About page content 2. : How-to guide content 3. : Legal information and terms Customisation best practices 1. Colours: - Use the file to maintain consistent branding - Consider both light and dark mode colour schemes - Ensure sufficient contrast for accessibility 2. Typography: - Add custom fonts to the directory - Define font faces in - Maintain consistent font usage throughout the application 3. Content: - Keep content in markdown files for easy maintenance - Update for site-wide text changes - Maintain proper licensing information in files 4. Images: - Use SVG format for logos when possible - Optimise image sizes for web performance - Include appropriate alt text in implementation 5. Environment variables: - Use different values for development, staging, and production - Keep sensitive values secure - Document any new variables added to the system",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/welcome",
      "url": "/gdi-userportal-frontend/developer-guide/welcome",
      "title": "welcome",
      "content": "Welcome, developers :::info content in progress We are working on this developer guide. ::: Welcome to the GDI User Portal Developer Guide! This comprehensive documentation will help you contribute to the Genomic Data Infrastructure (GDI) User Portal platform, whether you're developing new features, fixing bugs, or extending functionality. Development overview The GDI User Portal is built with modern web technologies and follows best practices for scalability, security, and maintainability: - Frontend: Next.js with TypeScript - Backend Services: Java/Spring Boot microservices - Data Catalogue: CKAN with custom extensions - Authentication: Keycloak with LS-AAI integration - Containerisation: Docker and Docker Compose Getting started Choose your development focus: - New to the project? Start with Get started - Frontend development? Go to Develop frontend features - Backend integration? Check out Work with backend services - CKAN extensions? Explore Develop CKAN extensions - Feature development? See Add and modify features Contributing Before contributing, review our coding standards and follow the established Git workflow. Ensure comprehensive testing coverage and update documentation for new features. GitHub Repository: GenomicDataInfrastructure/gdi-userportal-frontend",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/work-with-backend",
      "url": "/gdi-userportal-frontend/developer-guide/work-with-backend",
      "title": "work with backend",
      "content": "Work with backend services The GDI User Portal integrates with multiple backend services to provide comprehensive genomic data infrastructure functionality. This section covers integration patterns, API communication, and service orchestration. Backend architecture Service overview The platform consists of several interconnected services: - Dataset Discovery Service (DDS) - Data catalogue API abstraction - Access Management Service (AMS) - Access control and requests - CKAN - Core data catalogue system - Keycloak - Authentication and authorisation - PostgreSQL - Data persistence - Solr - Search and indexing Service communication Services communicate using: - REST APIs with JSON payloads - OAuth2/OpenID Connect for authentication - Service-to-service authentication tokens - Event-driven patterns for asynchronous operations Dataset Discovery Service integration Integrate Dataset Discovery Service The DDS provides a clean API layer over CKAN, abstracting complex CKAN operations and providing enhanced functionality. API Endpoints Dataset Search and Retrieval React Integration Access Management Service integration Connect Access Management Service The AMS handles all aspects of data access requests, user permissions, and compliance tracking. Access Request Flow AMS Client Implementation Authentication flow implementation Implement authentication flows Integration with Keycloak and LS-AAI requires careful handling of OAuth2 flows and token management. NextAuth Configuration Token management Error handling and resilience Service error handling Implement robust error handling for service communication: Retry logic Service monitoring and logging Health checks Implement service health monitoring: Testing backend integration Integration testing Mocking services Next steps After mastering backend integration: - Add and modify features - Build complete features - Develop frontend features - Enhance user interfaces - Get started - Review development setup",
      "guide": "developer-guide"
    }
  ]
}