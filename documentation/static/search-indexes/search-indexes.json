{
  "user-guide": [
    {
      "id": "/gdi-userportal-frontend/user-guide/_get-started/sign-in",
      "url": "/gdi-userportal-frontend/user-guide/_get-started/sign-in",
      "title": "sign in",
      "content": "Sign in Sign in to GDI User Portal with your organisation credentials—no need to create a separate account. GDI User Portal uses your organisation’s Identity and Access Management (IAM) system to facilitate your access and permissions within the platform. For questions regarding your organisation account, please contact your Inventory Coordinator or IT support team. To sign in to GDI User Portal: 1. Obtain the link to GDI User Portal from your Inventory Coordinator. 2. Open GDI User Portal in your web browser. 3. Select your sign-in method and sign in with your organisation credentials. 4. After you sign in, the GDI User Portal home page loads and you can _explore the dashboard_ :::info Unauthorised Access? If you're signing in for the first time or if there are no roles assigned to your account, you may get an \"Unauthorized Access\" error. Contact your Inventory Coordinator and request that they assign the necessary roles to your account, and then try again. ::: Sign in Sign in to GDI User Portal with your organisation credentials—no need to create a separate account. GDI User Portal uses your organisation's Identity and Access Management (IAM) system to facilitate your access and permissions within the platform. For questions regarding your organisation account, please contact your IT support team. To sign in to GDI User Portal: 1. Obtain the link to GDI User Portal from your IT support team. 2. Open GDI User Portal in your web browser. 3. Select your sign-in method and sign in with your organisation credentials. 4. After you sign in, the GDI User Portal home page loads and you can explore the dashboard",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/about-gdi",
      "url": "/gdi-userportal-frontend/user-guide/about-gdi",
      "title": "About GDI",
      "content": "",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/explore-datasets/browse-by-category",
      "url": "/gdi-userportal-frontend/user-guide/explore-datasets/browse-by-category",
      "title": "browse by category",
      "content": "Browse datasets by category Browse datasets by Themes and Publishers directly from the main menu. While these categories are available as filters in the search page, you can access their dedicated sections from the main navigation menu for quick browsing. :::tip Sign in for better discovery Sign in to view comprehensive information. While you can use this tool without an account, signing in allows you to search and view more details, such as and other metadata, to help you find what you need. ::: Here's a quick demo of browsing datasets by publishers: To browse datasets by theme or publisher categories: 1. Select either Themes or Publishers from the main navigation menu. 2. Select a category to view all datasets within that theme or publisher. After you select a theme or publisher, the Datasets page opens with pre-applied filters based on your selection. In this example, we selected the theme: Health, and is pre-applied as a filter with its resulting datasets. 3. Explore more using the search, or apply more filters to narrow down results. 4. Found a dataset of interest? Select it to view more details or Request access to the dataset.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/explore-datasets/search-and-filter",
      "url": "/gdi-userportal-frontend/user-guide/explore-datasets/search-and-filter",
      "title": "search and filter",
      "content": "Search and filter datasets Use the search bar and filters to find datasets relevant to your research. Both search and filters are available on all pages where browsing datasets is possible. This includes the Home page and the Datasets page. :::tip Sign in for enhanced search Sign in to get comprehensive search results. While you can search datasets without an account, signing in allows you to filter and view more details in the search results, such as and other metadata. ::: Search datasets On the Home or Datasets page, enter any term or phrase to search across all dataset information, including: - Disease names, research topics, or data types - Specific terms like gene names or scientific keywords - Any other information described in the dataset metadata Filter your results Use the filters on the left side of the search results page to narrow down your results. These filters are based on dataset metadata, and signing in gives you access to additional metadata-based filters. Common filters include: Access Rights, Data Types, Themes, and Publishers. Here's an example of a search result for the word \"cancer\", with filters applied for Access Rights: and Themes: and .",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/explore-datasets/search-by-allele-frequency",
      "url": "/gdi-userportal-frontend/user-guide/explore-datasets/search-by-allele-frequency",
      "title": "search by allele frequency",
      "content": "Search by allele frequency Search for datasets containing specific genomic variants using the allele frequency search tool. Allele frequency refers to how common a specific genetic variant is within a population. This search tool allows you to: - Identify relevant datasets with your specific genomic variant of interest - Compare variant frequencies across different populations and research cohorts - Assess dataset suitability by viewing detailed prevalence data to select the most appropriate datasets for your research :::tip Sign in for enhanced search Sign in to get comprehensive search results. While you can use this tool without an account, signing in allows you to search and view more details, such as and other metadata, to help you find what you need. ::: Search by allele frequency 1. Select Allele Frequency from the main menu. 2. Enter your search criteria: - Variant: The full form of the genomic variant, usually represented in the format . Example: - Ref Genome: Select the reference genome assembly to use for the search. - Cohort: Select the cohort of interest. Cohorts are groups of individuals sharing common characteristics, for example, those with a specific condition such as COVID. - Sex (optional): Filter results by biological sex (Male or Female). - Country of Birth (optional): Filter results by country of birth using 2-letter ISO country codes. 3. Select Search or press Enter. The search results display dataset information in table format. Understanding your results The search results display datasets containing your specified variant in table format. Here's an example of the search result using the allele frequency search tool: - Dataset: Name and source of the dataset. These are Beacon identifiers—the portal uses Beacon technology to retrieve information about whether genomic databases contain specific variants. - Population: Population identifier from the dataset (e.g., \"FR_M\" for French males in GoE format). - Allele Count: Number of times the variant appears in the dataset. - Allele Number: Total number of alleles analysed in the dataset for this position. - Homozygous: Number of individuals with two copies of the variant. - Heterozygous: Number of individuals with one copy of the variant. - Hemizygous: Number of individuals with one copy of the variant on a sex chromosome (relevant for an X or Y chromosome). - Frequency: How common the variant is in that population (as a decimal). - Actions: Add the dataset to your basket to request access later.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/export-metadata",
      "url": "/gdi-userportal-frontend/user-guide/export-metadata",
      "title": "export metadata",
      "content": "Export metadata Download dataset metadata for integration with various tools and systems. The metadata includes detailed information about the dataset such as data types, collection methods, access rights, and other descriptive information that can help you integrate the dataset information into your research workflow. You can export metadata in the following formats: - RDF: Resource Description Framework format for semantic web applications - TTL: Turtle format for human-readable RDF data - JSON-LD: JSON for Linked Data format for web-based applications To export metadata: 1. Browse or search for datasets you want to export metadata from. 2. Select a dataset to view its details. 3. Locate the Export Metadata In section and select your preferred format (RDF, TTL, or JSON-LD). In this example, we select JSON-LD: 4. Select Download to save the metadata file to your device.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/faq",
      "url": "/gdi-userportal-frontend/user-guide/faq",
      "title": "faq",
      "content": "Frequently Asked Questions For additional questions or support, please contact our support team. Do I need an account to access GDI Portal? You do not need an account to access the GDI Portal and browse dataset information. However, you need to sign in to your account to request access to the dataset records. Signing in also enables additional features such as saving searches and receiving notifications. I found a dataset I want to use. What do I do? First, you need to submit an application to access the said data. You might be asked to provide additional information such as your research purpose, institutional affiliation, and ethics approval documentation. The portal will guide you through these requirements when you apply. Once your application is approved, you will receive instructions on how to download the data. How long does it take to get approval to access data? Approval times vary depending on the dataset, the requirements you provide, and the complexity of your request. The portal will connect you with the Data Access Committee who manage the approval process. Can I access data from multiple countries? Yes, the GDI Portal enables cross-border access to genomic data across European countries through its federated network approach.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/add-participants",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/add-participants",
      "title": "add participants",
      "content": "Add participants to your application Add participants to collaborate with team members or colleagues on your dataset access request. You can invite multiple participants to help complete the application, upload required documents, and stay informed about the request status. You can add participants to draft and submitted applications. Participants can: - View the application details and requirements - Submit requirements such as forms and documents - Submit draft applications for review - Receive status updates via email To add participants to your application: 1. Select the folder icon () on your dashboard. 2. Select the Applications tab on your dashboard, and select your draft or submitted application. 3. Select Add Participant on the application details page. 4. Enter the name and email address you want to invite and select Send. Do this for each participant you want to add. :::tip Well done After participants accept your invitation, they can access the application from their dashboard and continue the application process.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/apply-for-access",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/apply-for-access",
      "title": "apply for access",
      "content": "Apply for access to datasets Found datasets you want to use? Submit an application to access and use the datasets. The Data Access Committee will review your application to ensure compliance with data use policies and ethical standards. To apply for access to datasets: 1. Browse or search for datasets you want to access. 2. Select Add to basket on each dataset you want to include in your application. You can do this from the search results or when you view the dataset details. This example shows adding a dataset to the basket from the search results: 3. After you add datasets to your basket, select the Basket icon (). The Basket page opens with the list of datasets you selected. 4. Review your list of datasets. To remove a dataset, select Remove from basket. 5. Select Request now to create an application. The application form opens. 6. Submit the requirements to access the dataset. This can include filling out forms and uploading documents, depending on the dataset. Here's an example of requirements including document uploads: 7. (Optional) Need help with your application? Select Add Participant for collaborators to access your application, submit requirements, and continue your application. 8. Review the Terms & Conditions and select Accept All to agree to the terms. 9. Select Submit to complete your application. You will receive email notifications for status updates and if additional documentation is required. :::tip Continue later If you need more time, you can close or navigate away from the application page. The system automatically saves your progress as draft, and you or your collaborators can continue later. :::",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/continue-an-application",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/continue-an-application",
      "title": "continue an application",
      "content": "Continue an application Continue working on applications that you or other collaborators have started earlier. All incomplete applications are saved as draft. To continue a draft application: 1. Select the folder icon () on your dashboard. 2. Select the APPLICATIONS tab. The page lists applications, indicating their status. In this example, you have one application and one application: 3. Select the draft application you want to complete. 4. Complete the application form by providing all required information or uploading necessary documentation. 5. Review the Terms & Conditions and select Accept All to agree to the terms. 6. Select Submit to submit your completed application. You will receive a confirmation email and be notified of status updates. Or to save and continue later, simply navigate away from the page. The system saves your last completed input.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/download-datasets",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/download-datasets",
      "title": "download datasets",
      "content": "Download datasets Once your application is approved, you'll receive an email with instructions to access the Secure Processing Environment (SPE) where you can securely download and work with your approved datasets. To access and work with your approved datasets: 1. Check your email for instructions and access links to the Secure Processing Environment (SPE). 2. Follow the instructions provided in the email to securely access the SPE. 3. Download and work with your approved datasets within the SPE. :::info Stay compliant All data are protected by governance frameworks and data access policies to ensure ethical and legal use. Remember to use data responsibly and according to the terms and agreements you signed during the application process. ::: View approved datasets in the portal You can also view your approved datasets directly in the GDI Portal to see their metadata and details. To view your approved datasets: 1. Select the folder icon () on your dashboard. 2. Select the Entitlements tab to see the list of your approved datasets. 3. Select the dataset to view its details. This view only displays the metadata of your approved datasets. To download and work with the datasets, use the Secure Processing Environment (SPE) as instructed in your approval email.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/track-application",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/track-application",
      "title": "track application",
      "content": "Track your application After submitting your application, track its progress and check for any status updates or additional requirements from the Data Access Committee. To track your application: 1. Select the folder icon () on your dashboard. 2. Select the APPLICATIONS tab. The page displays all your applications with their current status, sorted by last modified date: In this example, there is one application and one application: 3. Review your application status. Applications can have the following statuses: - DRAFT: Application is incomplete and has not been submitted yet. Continue the application. - SUBMITTED: Application is under review by the Data Access Committee. - RETURNED: Application requires additional information or documents. View the feedback and continue the application. - APPROVED: Application has been approved and you can access the datasets. Download the datasets. - REJECTED: Application has been declined. Select the application to view feedback. To resubmit, create a new application. - CLOSED: Application is closed and no further action is required. Open the application to view details.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/sign-in",
      "url": "/gdi-userportal-frontend/user-guide/sign-in",
      "title": "sign in",
      "content": "Sign in Sign in to get full access to available datasets and request access. Why sign in? Signing in allows you to access enhanced features and request access to datasets. While you can browse datasets without an account, signing in allows you to: - Submit applications to request access to datasets. - Enhance your search with additional filters and more comprehensive search results. - See more dataset information including and other metadata to help assess if datasets meet your research needs. Sign in The GDI Portal uses your existing accounts with other platforms like Google, LinkedIn, and organisations like universities or research institutions, so you don't need to create a separate account. To sign in to the GDI Portal: 1. Open the GDI Portal in your browser: https://portal.dev.gdi.lu/. 2. Select Login at the top right corner of the page. The login page opens. 3. Select LSAAI as your sign-in method. :::info Why LSAAI? GDI Portal requires you to sign in with LSAAI (Login Service for Academic and Administrative Institutions). LSAAI is a secure login system that lets you use your existing accounts like Google, LinkedIn, university, or other institutional accounts. This means you don't need to create a new account specifically for the GDI Portal. ::: 4. Select your account provider: Search for your institution in the search bar, or select from the list of options (LinkedIn, Apple, Google, ORCID, GitHub). 5. Follow the instructions to sign in with your selected account. If it's your first time signing in, you may need to verify your email address. 6. After you sign in, the GDI Portal home page loads and you can start exploring datasets.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/welcome-data-users",
      "url": "/gdi-userportal-frontend/user-guide/welcome-data-users",
      "title": "welcome data users",
      "content": "Welcome to the GDI Data Portal Welcome to the GDI Data Portal user guide! The GDI Data Portal gives you access to Europe's largest network of genomic datasets for your research and analysis needs. As part of the 1+ Million Genomes Initiative, this portal enables federated and secure cross-border access to high-quality genomic data and related phenotypic information across European countries. This guide is for data users—healthcare researchers, policy-makers, and professionals—who want to discover and request access to genomic datasets for research and clinical purposes. Learn more about Genomic Data Infrastructure (GDI) and its founding initiatives. How it works Access genomic datasets in three steps: 1. Explore datasets: Browse and search through detailed dataset information—search by any criteria such as keywords, research topics, disease areas, or allele frequency. Explore datasets. 2. Request access: Found a dataset you want to use? Submit an application to access it. You may need to provide documentation or requirements for your request, and you can invite collaborators to assist you with your application. Request access. 3. Access approved datasets: Once your request is approved, you will receive an email with a link to the Secure Processing Environment (SPE) where you can securely download and work with the datasets. :::info Stay compliant All data are protected by governance frameworks and data access policies to ensure ethical and legal use. Remember to use data responsibly and according to the terms and agreements you signed during the application process. :::",
      "guide": "user-guide"
    }
  ],
  "catalogue-managers-guide": [
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/ensure-quality",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/ensure-quality",
      "title": "ensure quality",
      "content": "Ensure data quality Maintaining high-quality data in your catalogue is essential for user trust and effective data discovery. This section covers validation, monitoring, and auditing processes to ensure your catalogue maintains quality standards. :::info content in progress We are working on this data quality guide. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/harvest-data",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/harvest-data",
      "title": "harvest data",
      "content": "Set up harvest sources :::info content in progress We are working on this guide. ::: Data harvesting is a crucial process for automatically collecting and integrating datasets from various sources into your CKAN catalogue. This section covers setting up harvesters, managing different data source types, and troubleshooting common issues. Overview The GDI User Portal supports harvesting from multiple data source types: - FAIR Data Points - DCAT-AP endpoints - Other CKAN instances - Custom API endpoints Harvesting tasks Set up harvesters Learn how to configure and deploy harvesters for different data sources, including authentication and scheduling options. Harvest from FAIR Data Points Specific guidance for harvesting metadata from FAIR Data Point implementations, including configuration requirements and best practices. Harvest DCAT-AP data Instructions for setting up DCAT-AP harvesters to collect standardised metadata from European data portals and catalogues. Troubleshoot harvest issues Common problems and solutions for harvesting operations, including network issues, authentication failures, and data mapping problems.",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets",
      "title": "manage datasets",
      "content": "Manage datasets :::info content in progress We are working on this dataset management guide. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-organisations",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-organisations",
      "title": "manage organisations",
      "content": "Manage organisations :::info content in progress We are working on this dataset management guide. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/welcome",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/welcome",
      "title": "welcome",
      "content": "Welcome, catalogue managers :::info content in progress We are working on this catalogue manager guide. ::: Welcome to the GDI Dataset Catalogue Portal Guide! This comprehensive documentation is designed for business users responsible for managing and curating data catalogues within the GDI ecosystem. Your role in the GDI ecosystem As a catalogue manager, you're a business user who plays a crucial role in ensuring high-quality, discoverable genomic datasets are available to the European research community. Your day-to-day responsibilities include: - Publishing datasets - Adding new research data to the catalogue - Managing organisations - Overseeing your institution's data presence - Ensuring quality - Maintaining high standards for data descriptions - Team collaboration - Working with colleagues on data publishing - Supporting users - Helping researchers find relevant datasets Available guides This documentation covers everything you need to manage datasets effectively: - Manage datasets - Learn to publish and update datasets - Manage organisations - Oversee your institution's data presence - Ensure data quality - Maintain high-quality data descriptions - Work with advanced features - Explore enhanced portal capabilities Getting started Choose your starting point based on your immediate needs: - New to the portal? Start with Manage datasets - Setting up your team? Begin with Manage organisations - Focus on quality? Go to Ensure data quality - Exploring features? Check out Work with advanced features Your work in managing datasets helps ensure that Europe's genomic data infrastructure serves the research community effectively.",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/work-with-extensions",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/work-with-extensions",
      "title": "work with extensions",
      "content": "Work with advanced features Learn how to optimise your dataset publishing to take advantage of the portal's advanced capabilities. This guide helps you understand how your data publishing choices enhance user experience and dataset discoverability. :::info content in progress We are working on this advanced features guide. :::",
      "guide": "catalogue-managers-guide"
    }
  ],
  "system-admin-guide": [
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/about-gdi",
      "url": "/gdi-userportal-frontend/system-admin-guide/about-gdi",
      "title": "About GDI",
      "content": "",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/configure-auth",
      "url": "/gdi-userportal-frontend/system-admin-guide/configure-auth",
      "title": "configure auth",
      "content": "Set up authentication and authorisation The GDI User Portal uses Keycloak for authentication and authorisation, with integration to LS-AAI (Life Science Authentication and Authorisation Infrastructure) for federated access across European research infrastructures. Authentication architecture Keycloak configuration Keycloak serves as the central authentication provider, managing user sessions, roles, and permissions across all platform components. LS-AAI integration Integration with LS-AAI enables users to authenticate using their existing institutional credentials through the European research federation. User role management Configure role-based access control to ensure appropriate permissions for different user types (data users, catalogue managers, system administrators). Configuration tasks Configure Keycloak Set up Keycloak instance with proper realm configuration, client settings, and security policies. Integrate with LS-AAI Configure LS-AAI as an identity provider in Keycloak, including OpenID Connect settings and attribute mapping. Manage user roles Define and manage user roles and permissions to control access to different platform features and data. Identity providers configuration When configuring identity providers (IdPs), you'll need: - ClientSecret - Provided by the IdP during registration - ClientId - Unique identifier for your application - Token URL - OAuth2 token endpoint - Authorisation URL - OAuth2 authorisation endpoint - Redirect URI - Keycloak callback URL Azure AD integration Configure Azure Active Directory as an identity provider for organisational authentication. LS-AAI integration details - Discovery endpoint: - Required scopes: , , , - Sync mode: Import (not force) - Token storage: Enabled for Beacon Network integration Security considerations Token management Proper configuration of token storage and refresh to enable secure API access across services. Access control Implementation of proper access control policies to protect sensitive data and administrative functions. Audit and monitoring Set up logging and monitoring for authentication events and security incidents. :::info content in progress We are working on this guide. :::",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/configure-ls-aai-in-keycloak/keycloak-setup",
      "url": "/gdi-userportal-frontend/system-admin-guide/configure-ls-aai-in-keycloak/keycloak-setup",
      "title": "keycloak setup",
      "content": "Configure LS-AAI in Keycloak Keycloak can be obtained by running the CKAN deployment script that you can find in the following guide: Azure CLI Script Deployment Guide Configuring Identity Providers (IdPs) When configuring identity providers (IdPs), the following information becomes crucial for OpenID setup: - ClientSecret - ClientId - Token URL - Authorization URL - Redirect URI Both the 'Token URL' and 'Authorization URL' are derived from the IdP. When registering a service, you acquire the clientId and secret. The 'Redirect URI', which remains constant, is provided by Keycloak: Additionally, the corresponding configuration entails: - Scopes: \"openid\", \"profile\", \"email\" , \"elixir_id\" - Method: POST the Clientsecret - Sync method: import For Elixer_id additional mapper is needed Azure AD For Azure integration, I followed the tutorial at https://www.youtube.com/watch?v=LYF-NLHD2uQ. This tutorial comprehensively explains both the service registration and the Azure AD setup within Keycloak. Management of the app registration is done within our Ad: portal.zure.com LSAAI To register Keycloak as service I used https://elixir-europe.org/platforms/compute/aai/service-providers. . Initially, obtaining an account is the first step. 1. Make sure your organisation is recognised as IdP and register if not. 2. Submit a registration for you application as a service. Please note that approval for this step may entail a waiting period. Management of the app registration is done within: https://services.aai.lifescience-ri.eu . Discovery endpoint: https://login.elixir-czech.org/oidc/.well-known/openid-configuration The LSAAI configuration looks like: !LSAAI Configuration Part 1 !LSAAI Configuration Part 2 Note 1: Sync mode must be \"import\" instead of \"force\"\\ Note 2: and must be on, to allow User Portal components to get LS-AAI . That enables Beacon Network integration via Oauth2.\\ The first time you log in you will get a question if you want to be a member of the test environment. Agree and proceed. Fetching LS-AAI Access Token from Keycloak Option 1 In order to fetch access token from LS-AAI - or any IdP - one needs to configure Keycloak accordingly, and later request to Keycloak LS-AAI tokens. 1. Go to ; 2. Enable and ; 3. Delete LS-AAI existing users, to ensure users are initialised correctly in Keycloak; 4. Login with a LS-AAI user; 5. Call Keycloak endpoint: Option 2: Configuring OAuth 2.0 in Postman This guide will help you set up OAuth 2.0 authorization for a request in Postman and obtaining the LSAAI token. Steps to Configure OAuth 2.0 1. Open Postman Application Begin by opening the Postman application on your desktop. 2. Select a Request - Choose any existing request from your collections, or create a new one by clicking on the 'New' button and selecting 'Request'. 3. Authorization Setup - Navigate to the 'Authorization' tab within the selected request. 4. Set Authorization Type - From the 'Type' dropdown menu, select 'OAuth 2.0'. 5. Add Authorization Data to Request Headers - In the 'Add authorization data to' dropdown, select 'Request Headers'. 6. Current Token Configuration - For the 'Current Token' section, choose 'Bearer' as the token type. 7. Configure New Token Follow the steps below to configure a new token: - Token Name: Enter a random name for your token. - Grant Type: Select 'Authorization Code' from the dropdown menu. - Authorize Using Browser: Ensure this box is checked to use your default web browser for the authorization. - Auth URL: Replace and with the appropriate values for your Keycloak server and realm. - Access Token URL: Similar to the Auth URL, fill in the Keycloak server and realm information. - Client ID: Enter 'ckan' or the specific client ID you have been provided. - Client Secret: Enter the client secret you obtained from Keycloak that corresponds to your client ID. - Scope: Input the scopes as . - Client Authentication: Select 'Send as Basic Auth header' from the dropdown menu. 8. Obtain Access Token - Click on the 'Get New Access Token' button to initiate the OAuth 2.0 authorization flow. After completing these steps, you should be able to receive an access token that can be used to authorize your requests within Postman, which is containing also an Elixer Id",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/configure-schemas",
      "url": "/gdi-userportal-frontend/system-admin-guide/configure-schemas",
      "title": "configure schemas",
      "content": "Configure metadata schemas Configure and manage CKAN metadata schemas to define dataset fields, validation rules, and data entry forms. This guide covers schema development, deployment, and maintenance for system administrators. Schema structure and format CKAN schemas can be defined as JSON or YAML files that specify dataset metadata fields and their properties. Example field definition Key field properties Configure field behaviour using these properties: - field_name: CKAN field identifier - label: UI field representation for end users - help_text: Explanatory text appearing under field in UI - choices: For dropdown menus - list of dictionaries with value and label - choices_helper: Form dropdowns dynamically from API - presets: Values like , , for automatic checks - form_snippet: Defines field representation for data input (jinja2 format) - display_snippet: Defines how data is shown in UI - validators: Data validation functions - output_validators: Convert complex data structures from database Schema configuration Single schema setup Configure your primary schema in CKAN configuration: Multiple schema support Configure multiple schemas using a declaration file for different dataset types: Reference the multi-schema file in : Schema deployment Update running CKAN instance To change schema in a running Docker container: Changes to trigger automatic CKAN updates. Schema path format Define schemas using the format: Example: Schema management APIs Use CKAN APIs to manage schemas programmatically: Best practices Schema design - Follow DCAT-AP standards for interoperability - Design for user experience, not just technical requirements - Include comprehensive help text for complex fields - Test schemas with real users before deployment Deployment - Test schema changes in development environment first - Document all schema modifications - Consider migration impact on existing datasets - Backup data before major schema updates For comprehensive schema development, see the CKAN scheming documentation. Next steps After configuring schemas: - Manage user roles and permissions - Control access to schema management - Manage data and services - Configure data workflows - Monitor and maintain the system - Track schema usage and performance",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/deploy-infrastructure",
      "url": "/gdi-userportal-frontend/system-admin-guide/deploy-infrastructure",
      "title": "deploy infrastructure",
      "content": "Deploy infrastructure :::info content in progress We are working on this guide. ::: The GDI User Portal consists of multiple interconnected components that require careful deployment and configuration. This section provides comprehensive guidance for system administrators on setting up production-ready infrastructure. Deployment options Deploy to Azure Complete guide for deploying the GDI User Portal on Microsoft Azure infrastructure, including resource provisioning, networking, and security configuration. Deploy to ELIXIR-LU Specific instructions for deploying to ELIXIR Luxembourg infrastructure, tailored for genomic data infrastructure requirements. Configure Docker containers All components run as Docker containers. Learn about container orchestration, networking, and persistent storage configuration. Manage environments Best practices for managing multiple environments (development, staging, production) and environment-specific configuration. Component installation User Portal Frontend The frontend provides the web interface and integrates with backend services. Built with Next.js for optimal performance and user experience. Installation guide: User Portal Frontend README Dataset Discovery Service (DDS) Backend service that mediates between the frontend and CKAN, providing abstraction and enhanced functionality. Installation guide: Dataset Discovery Service README Access Management Service (AMS) Handles access requests, user permissions, and integration with external systems like REMS. Installation guide: Access Management Service README CKAN Extensions The platform uses several custom CKAN extensions that must be properly integrated: - GDI Userportal Ckanext - Core GDI functionality - Fair Datapoint Ckanext - FAIR principles support - Harvest Ckanext - Data harvesting capabilities For extension integration, see the CKAN Docker repository installation guide.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/fdp/fair-data-point",
      "url": "/gdi-userportal-frontend/system-admin-guide/fdp/fair-data-point",
      "title": "fair data point",
      "content": "FAIR data point setup Fair Data Point (FDP) Installation Guide This guide provides steps to install FDP and configure it with GDI-specific SHACL shapes. For a more comprehensive overview, please refer to the existing FDP documentation on exposing metadata. 1. Installing FDP 1. Follow the installation guide in the documentation linked above to set up FDP in your environment. 2. Ensure that the FDP instance is accessible and that you have administrative rights to configure metadata schemas. 2. Installing GDI-Specific SHACLs To add GDI-specific SHACL validation, perform the following steps: Step 1: Download SHACL Shapes - Access the GDI-specific SHACL shapes from this GDI metadata repository. - Download each SHACL shape file (e.g., and others). Step 2: Upload SHACL Shapes to FDP 1. Login to FDP using an admin account. 2. Navigate to Metadata Schemas (located in the dropdown under your username). 3. For each shape file: - Open the editor and paste the contents of (or other shapes). - Add a description to document the purpose or release information. - Ensure the abstract checkbox is selected when uploading , as most other classes derive from it. - For other shapes, uncheck the abstract checkbox. - Press Save and Release to finalize the shape. - Provide a meaningful description and version number for the release. - Check the public checkbox to make the shape accessible. - Press Release to complete the upload. Repeat these steps for each SHACL shape file. 3. Supported Metadata Fields for Datasets The following metadata fields are currently supported: Dataset | Property Name | Example Data | | ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | contact_point | VCard(hasEmail=[mailto:data-access-committee@xumc.nl], full_name=[Data Access Committee of the x UMC], hasUID=https://ror.org/05wg1m734) | | creator | Agent(name=[Academic Medical Center], identifier=https://ror.org/05wg1m734) | | description | This dataset is part of the GDI MS8 milestone, focused on the distributed analysis of COVID-19 cases (GWAS) and allele frequency lookup for infectious diseases. It contains synthetic data designed to replicate COVID-19-related genetic studies, including risk variants associated with severe disease outcomes. The data is used for federated analysis across multiple nodes to identify genomic associations and variant prevalence. | | number_of_patients | 100 | | issued | 2024-07-01T11:11:11 | | keywords | Covid, Smokers, (free to choose) | | identifier | GDID-[0-9a-f]{8}-[0-9a-f]{4} | | modified | 2024-06-04T13:36:10.246Z | | publisher | Agent(name=[Radboud University Medical Center], identifier=https://ror.org/05wg1m734, mbox=[mailto:test@health-ri.nl]) | | theme | http://publications.europa.eu/resource/authority/data-theme/HEAL | | title | COVID-19 GWAS and Allele Frequency Lookup Dataset for GDI MS 8 | | number_of_participant | 100 | | phenotypes | Age (min and max) | | accessRights | DUO:0000006, DUO:0000017, DUO:0000018 (General research use, Infectious Disease research use, Genomic research on complex diseases) | Distribution | Property Name | Example Data | | --------------- | ------------------------------------------------------------------------- | | title | GWAS and Allele Frequency Lookup Data Distribution for GDI MS8 | | description | VCF file containing COVID-19 case/control data for GDI MS8 demonstration. | | access_url | https://example.com/dataset/GDI-MS8-COVID19.vcf | | media_type | https://www.iana.org/assignments/media-types/application/vcf | | license | https://creativecommons.org/licenses/by-sa/4.0/ | 4. Onboarding Metadata To onboard large datasets more efficiently, you can use a Jupyter notebook to automate this process. Clone the Sempyro repository and run the notebook using: As a reference, an MS8 template/example is available in the notebook for streamlined metadata upload to FDP.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/installation/azure",
      "url": "/gdi-userportal-frontend/system-admin-guide/installation/azure",
      "title": "azure",
      "content": "Azure CLI Script Deployment Guide for a Catalogue with CKAN This guide will walk you through the process of deploying an environment using Azure CLI that includes a CKAN container, Frond end catalogue, SOLR for CKAN, Keycloak for authentication, a managed PostgreSQL server, and Redis Cache. This environment is suitable for development purposes, and further security and performance reviews are necessary for production deployment. Prerequisites - Azure CLI installed: Make sure you have Azure CLI installed on your machine. You can install it via Homebrew with the command . - GitHub Personal Access Token (classic): You'll need a personal access token from GitHub with pack read permissions. - Azure Account with Sufficient Permissions: Ensure you have an Azure account with permissions that, at a minimum, allow you to create a resource group. - PSQL installed: Ensure that PSQL is installed (e.g. ) Initial Setup Before running the script, you'll find several parameters at the beginning of the script that can be customized: - Passwords for the CKAN database, Keycloak database, and the PostgreSQL admin. Change these to secure passwords as desired. Deployment Steps 1. Execute the Script: - Navigate to the deployment project at GenomicDataInfrastructure/gdi-userportal-deployment. - Go to the Azure deployment folder - Run to start the deployment process. 2. Enter Required Information: - The script will prompt you to enter the necessary information. Fill in the details as requested. 3. Script Execution: - After entering the information, the script will automatically execute, setting up the environment and deploying the code. It typically takes about 10 minutes for the entire process to complete and for the services to be up and running. 4. Verification: - Once the script execution is complete, verify that all components are online by accessing the following URLs, replacing with your project name and with your environment name: - SOLR: - CKAN: - Catalog: - Keycloak: 5. Import CKAN Realm into Keycloak: - After verifying that all components are online, the next step is to import the CKAN realm into Keycloak. Log in to Keycloak using the admin account to perform this action. (creditials can be found in the script) Components Included - Azure Web App with CKAN Container: Runs a CKAN container from the main branch of the gdi-userportal-ckan-docker repository. - Azure Web App with Front Catalog: Originates from the main branch of the gdi-userportal-frontend repository. - Azure Web App with SOLR for CKAN: Dedicated SOLR instance for CKAN. - Azure Web App with Keycloak: For authentication and authorization. - Managed PostgreSQL Server: Includes a Keycloak database and a CKAN database. - Managed Redis Cache: For caching purposes to enhance performance. Note This setup is intended for development use. Before moving to a production environment, review and adjust the security and performance settings to meet the necessary requirements.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/installation/components",
      "url": "/gdi-userportal-frontend/system-admin-guide/installation/components",
      "title": "components",
      "content": "Installation guides The user portal consists of multiple components. To install or contribute to a specific component, refer to the respective installation guide linked below. All components run on Docker containers, and their individual setups are documented in their respective repositories. Components User Portal Frontend The User Portal Frontend, built with Next.js, provides a web interface for interacting with key services, including the Dataset Discovery Service (DDS) and the Access Management Service (AMS). It acts as the primary user interface for the GDI project. Installation guide: User Portal Frontend README Dataset Discovery Service (DDS) The Dataset Discovery Service acts as a backend layer mediating requests from the frontend to CKAN’s data catalog APIs. It retrieves, processes, and maps dataset information while abstracting CKAN-specific logic. To use DDS, ensure that the GDI CKAN extension is installed in your CKAN instance. Installation guide: Dataset Discovery Service README Access Management Service (AMS) The Access Management Service ensures secure interactions between the frontend and backend data authorities. It provides APIs for managing user access requests and integrates with external APIs like REMS to enforce policies and track user actions. Installation guide: Access Management Service README CKAN Extensions CKAN is an open-source data management system for publishing, sharing, and discovering datasets. It enables cataloging, searching, and accessing data through a web interface and API. Custom extensions can be developed to extend CKAN’s core functionalities. The User Portal uses several extensions, including one specifically developed for this project. Extensions used include (but are not limited to): - GDI Userportal Ckanext: Adds a DCAT-AP 3 compatible schema with fields such as , , , and . It also provides enhanced parsing for creators in the DCAT profile, adds support for OpenID Connect with PKCE, introduces new fields to , and links CKAN harvest views for admin users. Additionally, it offers endpoints for listing unique values and simplifies integration with CKAN-based datasets for the User Portal. - Fair Datapoint Ckanext: Provides features related to FAIR principles to enhance dataset accessibility and interoperability. - Harvest Ckanext: Supports automated data harvesting and integration with external data sources. In order to contribute on a ckan extension and run it on you local machine, it must be integrated into the docker build that will run as your backend service, connected to your DDS instance. For a detailed guide on how to integrate the extention, read 5. installing new extensions from the CKAN Docker repository",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/installation/elixir-lu",
      "url": "/gdi-userportal-frontend/system-admin-guide/installation/elixir-lu",
      "title": "elixir lu",
      "content": "Current deployment - - User Portal - - IAM - - API Gateway - - Catalogue Deployment Steps 1. Checkout . 2. Copy into the server and update all the secrets. 3. Run . 4. Run . 5. Run . 6. Enter in REMS docker container. 7. Configure the admin user. 8. Configure apikey, for any user and any REST method, but limited to . 9. Configure apikey and robot for any REST method, but limited to . 10. Configure apikey and robot, limited to . 11. Include in the environment variables the newly created apikeys and users. 12. Run . 13. Log into CKAN as sysadmin. 14. Add the harvest sources. 15. Wait for REMS Synchronizer or run it manually. 16. Access Keycloak. 17. Configure LS-AAI IdP. 18. Add mapper, that maps the clain clain into . 19. Create a new OIDC realm for GDI, that accepts redirections to User Portal, CKAN and REMS. 20. Create a new client scope for GDI realm. 21. Add new User Attribute Mapper, that maps the attribute into a claim called and a scope called . 22. Create a new client for User Portal, REMS and CKAN. 23. Add the scope into the newly created client.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/manage-data-services",
      "url": "/gdi-userportal-frontend/system-admin-guide/manage-data-services",
      "title": "manage data services",
      "content": "Manage data and services :::info content in progress We are working on this guide. ::: This section covers the administration of core data management services including CKAN administration, FAIR Data Point deployment, harvester configuration, and database management. Data service components Administer CKAN CKAN serves as the core data catalogue system. Learn about user management, organisation setup, dataset administration, and system maintenance. Set up FAIR Data Points FAIR Data Points provide standardised metadata endpoints that support FAIR principles. Configure FDP instances with GDI-specific SHACL shapes and metadata requirements. Configure harvesters Set up automated data harvesting from external sources including other CKAN instances, FAIR Data Points, and DCAT-AP endpoints. Manage databases Maintain database performance, backups, and integrity across PostgreSQL instances used by CKAN and other services. CKAN administration System configuration - Instance configuration and settings - Extension management and updates - Performance tuning and optimisation - Security configuration and updates User and organisation management - User account administration - Organisation setup and management - Permission and role assignment - API key management Data management - Dataset lifecycle management - Metadata quality assurance - Storage and backup procedures - Search index maintenance FAIR Data Point setup Installation and configuration Deploy FDP instances with GDI-specific requirements and configure metadata schemas using SHACL shapes. Metadata schema configuration Install and configure GDI-specific SHACL shapes for consistent metadata representation across the network. Supported metadata fields Comprehensive coverage of dataset and distribution metadata fields including contact points, creators, themes, and access rights. Harvesting configuration Harvester setup - Configure harvest sources and schedules - Set up authentication for protected endpoints - Monitor harvest job performance - Troubleshoot harvest failures Data source integration - FAIR Data Point harvesting - DCAT-AP endpoint harvesting - Custom API integration - Real-time vs. scheduled synchronisation Database management Performance monitoring - Query performance analysis - Index optimisation - Connection pool management - Resource utilisation tracking Backup and recovery - Automated backup procedures - Point-in-time recovery - Disaster recovery planning - Data integrity verification",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/manage-schemas",
      "url": "/gdi-userportal-frontend/system-admin-guide/manage-schemas",
      "title": "manage schemas",
      "content": "Manage schemas :::info content in progress We are working on this guide. ::: Learn how to configure and manage CKAN dataset schemas for the GDI User Portal. This guide covers schema format, field definitions, and deployment procedures. Schema format and field definitions A CKAN schema can be defined either as JSON or YAML file. The GDI User Portal uses JSON schemas for consistency. Field structure A field in CKAN schema JSON file has the following format: Where: - - CKAN field identifier - - UI field representation - - Text appearing under field in UI next to icon. Square brackets contain DCAT-AP mapping information Field configuration options Documentation on field keys and specifications can be found in the CKAN Scheming documentation. Available field keys include: - - For handling cardinality requirements - - Controls field appearance on multi-stage forms - - For dropdown lists (array of dictionaries with value and label) - - For dynamic dropdowns or API-driven choices - - Built-in field types (, , ) - - Custom field representation (Jinja2-based format) - - Custom data display formatting - - Override representation for DCAT mapping Example with display property: Validation configuration - - Data validation functions. Available functions listed in CKAN validators documentation - - Convert complex data structures from database storage back to objects Important: Default validation includes and . When specifying custom validators, include these explicitly if needed. Changing schemas in running instance Schema configuration Schema is defined in setup scripts by setting: Runtime schema changes In running Docker container, schema is configured in : Configuration changes trigger automatic CKAN updates. Schema path format Schema paths follow format: Example: resolves to extension directory structure under Multi-schema configuration Configuration file approach For better maintainability, create a JSON configuration file under extension schemas directory: Multiple dataset types Support for multiple schema types: Configure in : Schema merging behaviour - Core CKAN: Latest schema with same takes precedence - GDI implementation: Schemas with same type are merged, field order follows schema order in configuration - Field merging: Controlled by parameter - : Latest field definitions take precedence - Fields are never deleted, only added or modified - To remove fields, explicitly undeclare or set to empty API management List available schemas Get specific schema Search configuration Control dataset type visibility in search with:",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/manage-user-roles",
      "url": "/gdi-userportal-frontend/system-admin-guide/manage-user-roles",
      "title": "manage user roles",
      "content": "Manage user roles and permissions Configure and manage user access levels within the CKAN data catalogue system. This guide covers platform-wide and organisation-specific role management for system administrators. CKAN user role hierarchy Understanding CKAN user roles is essential for effective system administration. CKAN operates with two levels of roles: Platform-level roles 1. Visitor - Capabilities: Search and view public datasets - Access level: Anonymous/unauthenticated users 2. Registered User - Capabilities: - Become a member of an organisation (requires admin approval) - Publish, edit, or add datasets based on their role in the organisation - Manage their own profile - Configuration note: Creation of organisations is typically disabled for regular users 3. Sysadmin - Capabilities: - Access and edit any organisations - View and change user details - Permanently delete datasets - Customise the look and feel of the platform - Configure system-wide settings Organisation-level roles 1. Member - Capabilities: View the organisation's private datasets - Use case: Users who need access to restricted organisational data 2. Editor - Capabilities: - All capabilities of a Member - Add new datasets to the organisation - Edit or delete any of the organisation's datasets - Make datasets public or private - Use case: Content contributors and data curators 3. Organisation Admin - Capabilities: - All capabilities of an Editor - Add users to the organisation, and set their role (member, editor, or admin) - Change the role of any user in the organisation, including other admin users - Remove members, editors, or other admins from the organisation - Edit the organisation's details (e.g., title, description, image) - Delete the organisation - Use case: Organisational data stewards and managers User management procedures Configure platform roles Use CKAN's admin interface to manage platform-level user permissions and system access. Set up organisation permissions Configure organisation-specific roles and manage member access to datasets within organisational boundaries. Role assignment best practices - Follow principle of least privilege - Regular audit of user permissions - Document role assignments and changes - Implement approval workflows for sensitive roles For detailed role management procedures, see the CKAN authorisation documentation. Activity monitoring and auditing Monitor user activity and dataset changes to maintain data integrity and track catalogue usage. Enable activity streams CKAN displays a full history of dataset changes in the Activity Stream. For new installations, this is enabled by default, but upgrades may need manual activation. To make activity history public, add this to your file: Note: Since CKAN 2.10, Activity must be activated as a plugin. See the CKAN 2.10 changelog for details. Activity monitoring levels Configure activity tracking at different levels: - Organisation level - Track all changes within an organisation - Dataset level - Monitor specific dataset modifications - Difference view - See detailed changes between versions - User activity - Track individual user actions and access patterns Audit configuration For complete activity configuration options, see CKAN activity settings documentation. Next steps After configuring user roles: - Manage data and services - Set up data management workflows - Monitor and maintain the system - Ongoing system maintenance - Deploy and manage infrastructure - Infrastructure management",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/monitor-maintain",
      "url": "/gdi-userportal-frontend/system-admin-guide/monitor-maintain",
      "title": "monitor maintain",
      "content": "Monitor and maintain the system :::info content in progress We are working on this guide. ::: Ongoing monitoring and maintenance are crucial for ensuring the reliability, security, and performance of your GDI User Portal deployment. This section covers monitoring tools, maintenance procedures, and troubleshooting approaches. Monitoring components Monitor performance Track system performance metrics including response times, resource utilisation, and user activity to ensure optimal platform operation. Audit security Implement comprehensive security monitoring including access logging, intrusion detection, and compliance verification. Back up data Establish reliable backup procedures for all critical data including CKAN databases, configuration files, and user data. Publish new versions Manage platform updates and version deployments with minimal downtime and proper rollback procedures. Performance monitoring",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/platform-overview",
      "url": "/gdi-userportal-frontend/system-admin-guide/platform-overview",
      "title": "platform overview",
      "content": "Platform overview :::info content in progress This section will describe architecture, components, and interactions at a high level. ::: The GDI User Portal consists of multiple interconnected components: - User Portal Frontend - Next.js web interface providing the user experience - Dataset Discovery Service (DDS) - Backend API layer mediating frontend-CKAN communication - Access Management Service (AMS) - Access control and data request management - CKAN - Open-source data catalogue management system with custom extensions - Keycloak - Authentication and authorisation service - Supporting services - PostgreSQL, Elasticsearch/Solr, Redis, Docker containers",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/publishing-new-version/release-process",
      "url": "/gdi-userportal-frontend/system-admin-guide/publishing-new-version/release-process",
      "title": "release process",
      "content": "Publishing new versions > All repositories must follow the same process. > Once all necessary changes are merged to , please follow this process: - Ensure is up to date. - Push a new tag following the versioning and releases described in this page. The tag name follows . Example: - Create a new release branch, to simplify bugfixing and security patches. The branch name follows . Example: - Stage the Commit the : Push the branch to the remote repository - Go to GitHub and create a new release, example: - Click on \"Draft a new release\" CHANGELOG - Select the just created release branch and tag. - Enter a title for the release that includes the version and possibly a short description. - Auto-generate release notes. - Remove unnecessary release notes: ensure that only relevant information for the users is included and matches CHANGELOG.md. - Double-check all entered information. - Click on \"Publish release\" to officially make the release. - Ensure docker images were built and published correctly.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/welcome",
      "url": "/gdi-userportal-frontend/system-admin-guide/welcome",
      "title": "welcome",
      "content": "Welcome, system administrators :::info content in progress We are working on this deployment guide. ::: Welcome to the GDI User Portal System Administration Guide! This comprehensive documentation is designed for system administrators responsible for deploying, configuring, and maintaining the GDI User Portal platform and its associated services. Get started Choose your focus area based on your immediate needs: - New deployment? Start with Deploy and manage infrastructure - Setting up users? Begin with Set up authentication and authorisation - Managing access? Go to Manage user roles and permissions - Configuring data? Check out Manage data and services - System health? Explore Monitor and maintain the system This guide provides the technical knowledge you need to successfully deploy and maintain the GDI User Portal platform for the European genomic data research community.",
      "guide": "system-admin-guide"
    }
  ],
  "developer-guide": [
    {
      "id": "/gdi-userportal-frontend/developer-guide/about-gdi",
      "url": "/gdi-userportal-frontend/developer-guide/about-gdi",
      "title": "About GDI",
      "content": "",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/add-modify-features",
      "url": "/gdi-userportal-frontend/developer-guide/add-modify-features",
      "title": "add modify features",
      "content": "Add and modify features :::info content in progress We are working on this guide. ::: This section covers advanced development topics including metadata field management, extension development, and comprehensive testing strategies for adding new features to the GDI User Portal. Feature development overview Adding new features to the GDI User Portal typically involves: 1. Frontend development - User interface and experience 2. Backend integration - API endpoints and data processing 3. Metadata management - Schema updates and field additions 4. Testing - Comprehensive testing across all layers 5. Documentation - User and developer documentation Metadata field management Manage metadata fields Adding, modifying, or deleting metadata fields requires updates across multiple components of the CKAN ecosystem. Process overview When adding new metadata fields, you must update: 1. CKAN DCAT model - Core schema definition 2. Solr search integration - Search indexing 3. FAIR Data Point - SHACL shapes 4. SeMPyRO - Metadata automation 5. Discovery Service - API mapping CKAN DCAT model updates For DCAT-AP 3 compliant fields: Example schema addition: Solr Search Configuration To make fields searchable: After changes, rebuild the search index: FAIR Data Point integration Add SHACL shapes in FDP: SeMPyRO integration Add property to relevant class: Discovery Service mapping Update OpenAPI definitions and mapping: For complete metadata field procedures, see Metadata field management. Extension development Develop extensions CKAN extensions provide powerful capabilities to enhance catalogue functionality. Extension structure Plugin development Custom Validators Template Customization Testing Strategies Write and Run Tests Comprehensive testing ensures feature reliability and maintainability. Frontend Testing API Integration Testing E2E Testing Extension Testing Performance Considerations Optimization Strategies - Database Indexing - Ensure proper indexes for new fields - Caching - Implement appropriate caching for expensive operations - Lazy Loading - Load heavy components only when needed - Bundle Optimization - Minimize JavaScript bundle size Monitoring",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/add-update-metadata-fields/metadata-fields",
      "url": "/gdi-userportal-frontend/developer-guide/add-update-metadata-fields/metadata-fields",
      "title": "metadata fields",
      "content": "Add and update metadata fields :::info content in progress We are working on this guide. ::: This document outlines the steps required to add, modify, or delete fields across various components of the CKAN ecosystem, including DCAT-AP schema updates, Solr search configuration, SeMPyRO, Discovery Service, and FAIR Data Point (FDP). Table of Contents 1. CKAN DCAT Model 2. Solr Search Integration 3. FAIR Data Point 4. SeMPyRO 5. Discovery Service 6. General Improvements --- CKAN DCAT Model When a schema change falls under DCAT-AP 3 or an earlier version of DCAT-AP but is not yet present, follow these steps: 1. Fork and clone the repository: 2. Add the new field to the schema: - Modify the schema file: - Use appropriate field types (e.g., text, repeating subfield, URI). - Follow examples from other fields for consistency. For more information about scheming can be found in the CKAN Scheming documentation 3. Extend the existing mapping depending on the DCAT-AP version: Modify the mapping files located in the directory: 4. Fix the corresponding unit tests: 5. Create a pull request to the CKAN DCAT extension repository. Ensure that you follow the contributing guidelines for CKAN: - Include unit tests for the new fields. - Ensure compatibility across different DCAT-AP versions. 6. Update the following repositories after a new release: Update development and production Dockerfiles in these repositories( order is important): - https://github.com/GenomicDataInfrastructure/gdi-userportal-ckanext-fairdatapoint - https://github.com/GenomicDataInfrastructure/gdi-userportal-ckan-docker Check if ckan locally works with the new added fields by harvesting an example FDP Example of new field An example of a missing mapping in CKAN DCAT can be found here: Multi-valued field creator in CKAN DCAT. > Note: Always take into account the mapping from CKAN → DCAT in addition to DCAT → CKAN. --- Solr Search Integration If you're adding a new field in CKAN and you want it to be searchable via Solr, follow these steps to modify the file. Steps to Add and Configure a Searchable Field 1. Defining the Field Type and Name In the top part of the file, define the type and name of the new field. The type specifies how Solr will handle the data in the field (e.g., as , , , etc.). - Navigate to the section in where other fields are defined. - Add your new field with its corresponding type. Example: Here, custom_field is the name of the field, and it's set as a string type. It is also indexed (which makes it searchable) and stored (so it can be returned in search results). 2. Adding the Field to Search In the lower part of the schema.xml file, you'll need to add this field to the list of fields that are searchable by Solr. This is typically done in a section that defines which fields are indexed for searches. Example: This example maps the custom_field to the text field, which Solr uses for full-text searches. By adding the copyField directive, you're instructing Solr to include the contents of custom_field in the search index 3. When finished. Release a new version and update When finished. Release a new version and update GitHub - GenomicDataInfrastructure/gdi-userportal-ckan-docker: Scripts and images to run CKAN using Docker Compose in the development and production dockerfile Notes Indexing vs Storing: - indexed=\"true\": The field can be used in searches. - stored=\"true\": The field can be retrieved in search results. Testing the Configuration: After making these changes, you should restart your Solr instance and reindex your CKAN data to ensure that the new field is indexed and searchable with the command: SeMPyRO Prerequisites Fields are easy to add to SeMPyRO. You’ll need to know a few things: - The predicate of the field - Cardinality (single or multiple-valued) - Range or datatype Adding a Field Once that’s identified, go to the relevant class and add a property as follows. Here’s an example of the property of : At Line 1, we see , which is the name of the property. Its range is an , which is a helper for any URL. Other examples of this are or sometimes even classes like or . It is multi-valued because it's in a . If the maximum cardinality is one, it should not be in a . At Line 2, indicates the field is optional and by default undefined. Leave this line out for mandatory fields. At Line 3, we have a human-readable description of the field. At Line 4, we define the predicate. In this case, it's . Some common namespaces, like and , are imported by default. A full URI can also be defined, for example with . At Line 5, we define the RDF type. There are many possible values here, such as , , or . It's recommended to take a look at other properties to understand what is necessary here. Once this is done, the JSON and YAML schemas need to be re-generated. For the class, this can be done by running the following command: FAIR Data Point For the technical point of view, updating the appropriate SHACL shapes allows for adding of fields. Steps to Add a Field in FDP: 1. In the FDP, log in as an admin user and go to the Metadata schemas option. 2. Select the resource to update (e.g. Catalog). 3. In the Form Definition textarea, add a new entry in the list of values. For example: 4. Click Save if this is a draft and needs further work, or Save and release if the work is done. 5. Add a description and select a version number. 6. Click Release. Discovery Service The Dataset Discovery service requires two parts to be updated: the OpenAPI definitions and the mapping. OpenAPI Definition Two definitions need to be updated, both located in the folder: - ckan.yaml: This file contains the API returned by CKAN. Based on this YAML, Java classes are automatically generated corresponding to the API definition. For adding a field to a Dataset, the primary change will likely be in the CkanPackage definition. See the examples there on how to add a property. - discovery.yaml: This file defines what the Discovery service should return. You can make this definition whatever you want it to be—it does not have to correspond one-to-one with CKAN. To add a property here, modify the RetrievedDataset definition. Again, see the examples in the file. Mapping Once you have changed the definitions, follow these steps: 1. Run the following command:",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/develop-ckan-extensions",
      "url": "/gdi-userportal-frontend/developer-guide/develop-ckan-extensions",
      "title": "develop ckan extensions",
      "content": "Develop CKAN extensions Learn how to develop and test custom CKAN extensions for the GDI User Portal. This guide covers local development setup, extension structure, and testing procedures. Local development setup To develop and test CKAN extensions locally, you need to set up a proper development environment: 1. Set up virtual environment Note: Keep the virtual environment activated during the entire installation process. 2. Install CKAN as a package 3. Troubleshoot common dependency issues psycopg2 building issues If installation of fails: 1. Edit the requirements file at 2. Change to 3. Reinstall dependencies and CKAN separately: PyYAML compatibility issues For CKAN v2.9.10, if you encounter this error: Downgrade PyYAML in requirements.txt from or to . 4. Install required extensions Extensions can be installed from local repositories or directly from GitHub. Install from local repository Example on macOS: Install from GitHub Install extension dependencies Example for ckanext-harvest: 5. Configure database Set up PostgreSQL database and specify database connection strings in both and . Testing CKAN extensions Testing strategy depends on extension functionality. CKAN provides helper functions for generating dummy data and cleaning databases. Testing setup 1. Install pytest-ckan: Should be in extension's 2. Configure test.ini: Point to CKAN's test configuration 3. Configure test-core.ini: Set correct database connection Recommendation: Use separate test database instance for extensions requiring database writes. Running tests Basic test execution Test with coverage PyCharm configuration Set environment variable: Testing best practices - Review CKAN testing documentation for detailed guidance - Use CKAN helper functions for data generation and cleanup - Write tests for all extension interfaces and validators - Test schema changes with various data scenarios - Include integration tests for API endpoints Extension development workflow For detailed extension development procedures, see: - Add and modify features - Complete feature development guide - Work with backend services - Integration patterns - CKAN extensions documentation - Official guide Next steps After setting up your development environment: - Add and modify features - Build complete features - Work with backend services - Integrate with GDI services - Get started - Review overall development setup",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/develop-frontend",
      "url": "/gdi-userportal-frontend/developer-guide/develop-frontend",
      "title": "develop frontend",
      "content": "Develop frontend features :::info content in progress We are working on this guide. ::: The GDI User Portal frontend is built with Next.js 13+ using the App Router, TypeScript, and Tailwind CSS. This section covers frontend development including theming, component development, and API integration. Frontend architecture Technology stack - Next.js 13+ with App Router for server-side rendering and routing - TypeScript for type safety and better developer experience - Tailwind CSS for utility-first styling and responsive design - React Hook Form for form handling and validation - SWR for data fetching and caching - Radix UI for accessible component primitives Component organisation Theme customisation and styling Customise themes and styling The GDI User Portal offers extensive customisation options through configuration files and CSS variables. Configuration-based theming Modify for site-wide customisation: CSS customisation Use to define colour schemes: Custom fonts 1. Add font files to 2. Define font faces in 3. Update Tailwind configuration for font usage Visual assets Replace default assets in : - - Header logo - - Footer logo - - Browser icon - - Homepage background For detailed theming documentation, see Frontend Customisation. Component development Build components Follow established patterns for creating new React components: Component guidelines - Use TypeScript for all components - Implement proper accessibility (ARIA labels, keyboard navigation) - Follow established naming conventions - Include comprehensive prop types - Write unit tests for component logic State management - Use React's built-in state management for local state - Implement custom hooks for complex state logic - Use SWR for server state management - Context providers for global application state API integration Integrate with APIs The frontend integrates with multiple backend services using consistent patterns. Data Fetching with SWR API Route Handlers Service integration patterns Dataset Discovery Service integration - Search and filter datasets - Retrieve dataset metadata - Handle pagination and sorting Access Management Service integration - Submit access requests - Track application status - Manage user permissions Authentication integration - Handle login/logout flows - Manage user sessions - Secure API communication Testing Frontend testing strategy Testing best practices - Test user interactions, not implementation details - Use semantic queries for element selection - Mock external API calls - Test accessibility compliance - Implement visual regression testing Development tools Code quality - ESLint for code linting - Prettier for code formatting - TypeScript for type checking - Husky for Git hooks Development workflow Performance optimisation Next.js optimisation - Use Next.js Image component for optimised images - Implement proper code splitting - Utilise server-side rendering where appropriate - Optimise bundle size with dynamic imports Accessibility - Follow WCAG guidelines - Test with screen readers - Ensure keyboard navigation - Implement proper ARIA attributes",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/get-started",
      "url": "/gdi-userportal-frontend/developer-guide/get-started",
      "title": "get started",
      "content": "Get started :::info content in progress We are working on this guide. ::: This guide helps you set up a complete development environment for the GDI User Portal platform, including all necessary tools and dependencies. Prerequisites Before you begin, ensure you have the following installed: - Node.js (version 18 or higher) - npm or yarn package manager - Git for version control - Docker and Docker Compose for containerised services - Java 11+ (for backend services) - PostgreSQL (for local database development) Development environment setup 1. Clone the repository 2. Install dependencies 3. Environment configuration Copy the example environment file and configure for local development: Edit with your local configuration settings: 4. Start development services Use Docker Compose to start the required backend services: This starts: - CKAN instance with GDI extensions - PostgreSQL database - Keycloak authentication server - Dataset Discovery Service - Access Management Service 5. Start the development server The application will be available at . Project structure Understanding the codebase organisation: Local development workflow 1. Feature development - Create feature branches from - Use descriptive commit messages - Follow the established coding conventions - Write tests for new functionality 2. Testing Run the test suite before committing: 3. Code quality Maintain code quality with automated tools: Backend services integration Dataset Discovery Service The DDS provides abstraction over CKAN APIs. For local development: - Repository: gdi-userportal-dataset-discovery-service - Local URL: Access Management Service The AMS handles access requests and user permissions: - Repository: gdi-userportal-access-management-service - Local URL:",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/theming/customise-frontend",
      "url": "/gdi-userportal-frontend/developer-guide/theming/customise-frontend",
      "title": "customise frontend",
      "content": "Frontend customisation :::info content in progress We are working on this guide. ::: The GDI User Portal offers extensive customisation options through configuration files and public assets. This guide will help you understand how to customise various aspects of the portal. Configuration options The following configuration options can be set in the file: | Variable Name | Explanation | Example Value | | ---------------------------------- | ----------------------------------------------- | --------------------------------------------------------- | | NEXT_PUBLIC_SITE_TITLE | Main title of the website | \"GDI - User Portal\" | | NEXT_PUBLIC_SITE_DESCRIPTION | Brief description of the site | \"Genomic Data Infrastructure User Portal\" | | NEXT_PUBLIC_HOMEPAGE_TITLE | Main heading on the homepage | \"WELCOME TO GDI\" | | NEXT_PUBLIC_HOMEPAGE_SUBTITLE | Subheading text on the homepage | \"The Genomic Data Infrastructure (GDI) project...\" | | NEXT_PUBLIC_HOMEPAGE_ABOUT_CONTENT | Detailed content for the about section | \"The Genomic Data Infrastructure (GDI) homepage...\" | | NEXT_PUBLIC_BANNER_LINK | Navigation link for the banner | \"/howto\" | | NEXT_PUBLIC_FOOTER_TEXT | Text displayed in the footer | \"GDI project receives funding from the European Union...\" | | NEXT_PUBLIC_LINKEDIN_URL | LinkedIn social media link | \"https://www.linkedin.com/company/gdi-euproject/\" | | NEXT_PUBLIC_TWITTER_URL | Twitter/X social media link | \"https://twitter.com/GDI_EUproject\" | | NEXT_PUBLIC_GITHUB_URL | GitHub repository link | \"https://github.com/GenomicDataInfrastructure\" | | NEXT_PUBLIC_WEBSITE_URL | Main project website link | \"https://gdi.onemilliongenomes.eu/\" | | NEXT_PUBLIC_EMAIL | Contact email address | \"gdi-coordination@elixir-europe.org\" | | NEXT_PUBLIC_SHOW_BASKET_AND_LOGIN | Feature flag for basket and login functionality | \"true\" | Public assets customisation The portal's appearance can be customised through various files in the directory: Core configuration files 1. : Contains main site configuration including: - Site title and description - Homepage content and titles - Social media links - Contact information - Footer text - Feature flags 2. : Defines the colour scheme including: - Primary and secondary colours - Info and warning colours - Hover states - Surface colours - Dark mode support Visual assets 1. Logos: - : Main logo displayed in the header - : Logo displayed in the footer - : Browser tab icon 2. Images: - : Background image for the about section Typography 1. : Custom font definitions and typography settings 2. directory: Contains custom font files Content files 1. : About page content 2. : How-to guide content 3. : Legal information and terms Customisation best practices 1. Colours: - Use the file to maintain consistent branding - Consider both light and dark mode colour schemes - Ensure sufficient contrast for accessibility 2. Typography: - Add custom fonts to the directory - Define font faces in - Maintain consistent font usage throughout the application 3. Content: - Keep content in markdown files for easy maintenance - Update for site-wide text changes - Maintain proper licensing information in files 4. Images: - Use SVG format for logos when possible - Optimise image sizes for web performance - Include appropriate alt text in implementation 5. Environment variables: - Use different values for development, staging, and production - Keep sensitive values secure - Document any new variables added to the system",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/welcome",
      "url": "/gdi-userportal-frontend/developer-guide/welcome",
      "title": "welcome",
      "content": "Welcome, developers :::info content in progress We are working on this developer guide. ::: Welcome to the GDI User Portal Developer Guide! This comprehensive documentation will help you contribute to the Genomic Data Infrastructure (GDI) User Portal platform, whether you're developing new features, fixing bugs, or extending functionality. Development overview The GDI User Portal is built with modern web technologies and follows best practices for scalability, security, and maintainability: - Frontend: Next.js with TypeScript - Backend Services: Java/Spring Boot microservices - Data Catalogue: CKAN with custom extensions - Authentication: Keycloak with LS-AAI integration - Containerisation: Docker and Docker Compose Getting started Choose your development focus: - New to the project? Start with Get started - Frontend development? Go to Develop frontend features - Backend integration? Check out Work with backend services - CKAN extensions? Explore Develop CKAN extensions - Feature development? See Add and modify features Contributing Before contributing, review our coding standards and follow the established Git workflow. Ensure comprehensive testing coverage and update documentation for new features. GitHub Repository: GenomicDataInfrastructure/gdi-userportal-frontend",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/work-with-backend",
      "url": "/gdi-userportal-frontend/developer-guide/work-with-backend",
      "title": "work with backend",
      "content": "Work with backend services The GDI User Portal integrates with multiple backend services to provide comprehensive genomic data infrastructure functionality. This section covers integration patterns, API communication, and service orchestration. Backend architecture Service overview The platform consists of several interconnected services: - Dataset Discovery Service (DDS) - Data catalogue API abstraction - Access Management Service (AMS) - Access control and requests - CKAN - Core data catalogue system - Keycloak - Authentication and authorisation - PostgreSQL - Data persistence - Solr - Search and indexing Service communication Services communicate using: - REST APIs with JSON payloads - OAuth2/OpenID Connect for authentication - Service-to-service authentication tokens - Event-driven patterns for asynchronous operations Dataset Discovery Service integration Integrate Dataset Discovery Service The DDS provides a clean API layer over CKAN, abstracting complex CKAN operations and providing enhanced functionality. API Endpoints Dataset Search and Retrieval React Integration Access Management Service integration Connect Access Management Service The AMS handles all aspects of data access requests, user permissions, and compliance tracking. Access Request Flow AMS Client Implementation Authentication flow implementation Implement authentication flows Integration with Keycloak and LS-AAI requires careful handling of OAuth2 flows and token management. NextAuth Configuration Token management Error handling and resilience Service error handling Implement robust error handling for service communication: Retry logic Service monitoring and logging Health checks Implement service health monitoring: Testing backend integration Integration testing Mocking services Next steps After mastering backend integration: - Add and modify features - Build complete features - Develop frontend features - Enhance user interfaces - Get started - Review development setup",
      "guide": "developer-guide"
    }
  ],
  "all": [
    {
      "id": "/gdi-userportal-frontend/user-guide/_get-started/sign-in",
      "url": "/gdi-userportal-frontend/user-guide/_get-started/sign-in",
      "title": "sign in",
      "content": "Sign in Sign in to GDI User Portal with your organisation credentials—no need to create a separate account. GDI User Portal uses your organisation’s Identity and Access Management (IAM) system to facilitate your access and permissions within the platform. For questions regarding your organisation account, please contact your Inventory Coordinator or IT support team. To sign in to GDI User Portal: 1. Obtain the link to GDI User Portal from your Inventory Coordinator. 2. Open GDI User Portal in your web browser. 3. Select your sign-in method and sign in with your organisation credentials. 4. After you sign in, the GDI User Portal home page loads and you can _explore the dashboard_ :::info Unauthorised Access? If you're signing in for the first time or if there are no roles assigned to your account, you may get an \"Unauthorized Access\" error. Contact your Inventory Coordinator and request that they assign the necessary roles to your account, and then try again. ::: Sign in Sign in to GDI User Portal with your organisation credentials—no need to create a separate account. GDI User Portal uses your organisation's Identity and Access Management (IAM) system to facilitate your access and permissions within the platform. For questions regarding your organisation account, please contact your IT support team. To sign in to GDI User Portal: 1. Obtain the link to GDI User Portal from your IT support team. 2. Open GDI User Portal in your web browser. 3. Select your sign-in method and sign in with your organisation credentials. 4. After you sign in, the GDI User Portal home page loads and you can explore the dashboard",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/about-gdi",
      "url": "/gdi-userportal-frontend/user-guide/about-gdi",
      "title": "About GDI",
      "content": "",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/explore-datasets/browse-by-category",
      "url": "/gdi-userportal-frontend/user-guide/explore-datasets/browse-by-category",
      "title": "browse by category",
      "content": "Browse datasets by category Browse datasets by Themes and Publishers directly from the main menu. While these categories are available as filters in the search page, you can access their dedicated sections from the main navigation menu for quick browsing. :::tip Sign in for better discovery Sign in to view comprehensive information. While you can use this tool without an account, signing in allows you to search and view more details, such as and other metadata, to help you find what you need. ::: Here's a quick demo of browsing datasets by publishers: To browse datasets by theme or publisher categories: 1. Select either Themes or Publishers from the main navigation menu. 2. Select a category to view all datasets within that theme or publisher. After you select a theme or publisher, the Datasets page opens with pre-applied filters based on your selection. In this example, we selected the theme: Health, and is pre-applied as a filter with its resulting datasets. 3. Explore more using the search, or apply more filters to narrow down results. 4. Found a dataset of interest? Select it to view more details or Request access to the dataset.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/explore-datasets/search-and-filter",
      "url": "/gdi-userportal-frontend/user-guide/explore-datasets/search-and-filter",
      "title": "search and filter",
      "content": "Search and filter datasets Use the search bar and filters to find datasets relevant to your research. Both search and filters are available on all pages where browsing datasets is possible. This includes the Home page and the Datasets page. :::tip Sign in for enhanced search Sign in to get comprehensive search results. While you can search datasets without an account, signing in allows you to filter and view more details in the search results, such as and other metadata. ::: Search datasets On the Home or Datasets page, enter any term or phrase to search across all dataset information, including: - Disease names, research topics, or data types - Specific terms like gene names or scientific keywords - Any other information described in the dataset metadata Filter your results Use the filters on the left side of the search results page to narrow down your results. These filters are based on dataset metadata, and signing in gives you access to additional metadata-based filters. Common filters include: Access Rights, Data Types, Themes, and Publishers. Here's an example of a search result for the word \"cancer\", with filters applied for Access Rights: and Themes: and .",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/explore-datasets/search-by-allele-frequency",
      "url": "/gdi-userportal-frontend/user-guide/explore-datasets/search-by-allele-frequency",
      "title": "search by allele frequency",
      "content": "Search by allele frequency Search for datasets containing specific genomic variants using the allele frequency search tool. Allele frequency refers to how common a specific genetic variant is within a population. This search tool allows you to: - Identify relevant datasets with your specific genomic variant of interest - Compare variant frequencies across different populations and research cohorts - Assess dataset suitability by viewing detailed prevalence data to select the most appropriate datasets for your research :::tip Sign in for enhanced search Sign in to get comprehensive search results. While you can use this tool without an account, signing in allows you to search and view more details, such as and other metadata, to help you find what you need. ::: Search by allele frequency 1. Select Allele Frequency from the main menu. 2. Enter your search criteria: - Variant: The full form of the genomic variant, usually represented in the format . Example: - Ref Genome: Select the reference genome assembly to use for the search. - Cohort: Select the cohort of interest. Cohorts are groups of individuals sharing common characteristics, for example, those with a specific condition such as COVID. - Sex (optional): Filter results by biological sex (Male or Female). - Country of Birth (optional): Filter results by country of birth using 2-letter ISO country codes. 3. Select Search or press Enter. The search results display dataset information in table format. Understanding your results The search results display datasets containing your specified variant in table format. Here's an example of the search result using the allele frequency search tool: - Dataset: Name and source of the dataset. These are Beacon identifiers—the portal uses Beacon technology to retrieve information about whether genomic databases contain specific variants. - Population: Population identifier from the dataset (e.g., \"FR_M\" for French males in GoE format). - Allele Count: Number of times the variant appears in the dataset. - Allele Number: Total number of alleles analysed in the dataset for this position. - Homozygous: Number of individuals with two copies of the variant. - Heterozygous: Number of individuals with one copy of the variant. - Hemizygous: Number of individuals with one copy of the variant on a sex chromosome (relevant for an X or Y chromosome). - Frequency: How common the variant is in that population (as a decimal). - Actions: Add the dataset to your basket to request access later.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/export-metadata",
      "url": "/gdi-userportal-frontend/user-guide/export-metadata",
      "title": "export metadata",
      "content": "Export metadata Download dataset metadata for integration with various tools and systems. The metadata includes detailed information about the dataset such as data types, collection methods, access rights, and other descriptive information that can help you integrate the dataset information into your research workflow. You can export metadata in the following formats: - RDF: Resource Description Framework format for semantic web applications - TTL: Turtle format for human-readable RDF data - JSON-LD: JSON for Linked Data format for web-based applications To export metadata: 1. Browse or search for datasets you want to export metadata from. 2. Select a dataset to view its details. 3. Locate the Export Metadata In section and select your preferred format (RDF, TTL, or JSON-LD). In this example, we select JSON-LD: 4. Select Download to save the metadata file to your device.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/faq",
      "url": "/gdi-userportal-frontend/user-guide/faq",
      "title": "faq",
      "content": "Frequently Asked Questions For additional questions or support, please contact our support team. Do I need an account to access GDI Portal? You do not need an account to access the GDI Portal and browse dataset information. However, you need to sign in to your account to request access to the dataset records. Signing in also enables additional features such as saving searches and receiving notifications. I found a dataset I want to use. What do I do? First, you need to submit an application to access the said data. You might be asked to provide additional information such as your research purpose, institutional affiliation, and ethics approval documentation. The portal will guide you through these requirements when you apply. Once your application is approved, you will receive instructions on how to download the data. How long does it take to get approval to access data? Approval times vary depending on the dataset, the requirements you provide, and the complexity of your request. The portal will connect you with the Data Access Committee who manage the approval process. Can I access data from multiple countries? Yes, the GDI Portal enables cross-border access to genomic data across European countries through its federated network approach.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/add-participants",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/add-participants",
      "title": "add participants",
      "content": "Add participants to your application Add participants to collaborate with team members or colleagues on your dataset access request. You can invite multiple participants to help complete the application, upload required documents, and stay informed about the request status. You can add participants to draft and submitted applications. Participants can: - View the application details and requirements - Submit requirements such as forms and documents - Submit draft applications for review - Receive status updates via email To add participants to your application: 1. Select the folder icon () on your dashboard. 2. Select the Applications tab on your dashboard, and select your draft or submitted application. 3. Select Add Participant on the application details page. 4. Enter the name and email address you want to invite and select Send. Do this for each participant you want to add. :::tip Well done After participants accept your invitation, they can access the application from their dashboard and continue the application process.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/apply-for-access",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/apply-for-access",
      "title": "apply for access",
      "content": "Apply for access to datasets Found datasets you want to use? Submit an application to access and use the datasets. The Data Access Committee will review your application to ensure compliance with data use policies and ethical standards. To apply for access to datasets: 1. Browse or search for datasets you want to access. 2. Select Add to basket on each dataset you want to include in your application. You can do this from the search results or when you view the dataset details. This example shows adding a dataset to the basket from the search results: 3. After you add datasets to your basket, select the Basket icon (). The Basket page opens with the list of datasets you selected. 4. Review your list of datasets. To remove a dataset, select Remove from basket. 5. Select Request now to create an application. The application form opens. 6. Submit the requirements to access the dataset. This can include filling out forms and uploading documents, depending on the dataset. Here's an example of requirements including document uploads: 7. (Optional) Need help with your application? Select Add Participant for collaborators to access your application, submit requirements, and continue your application. 8. Review the Terms & Conditions and select Accept All to agree to the terms. 9. Select Submit to complete your application. You will receive email notifications for status updates and if additional documentation is required. :::tip Continue later If you need more time, you can close or navigate away from the application page. The system automatically saves your progress as draft, and you or your collaborators can continue later. :::",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/continue-an-application",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/continue-an-application",
      "title": "continue an application",
      "content": "Continue an application Continue working on applications that you or other collaborators have started earlier. All incomplete applications are saved as draft. To continue a draft application: 1. Select the folder icon () on your dashboard. 2. Select the APPLICATIONS tab. The page lists applications, indicating their status. In this example, you have one application and one application: 3. Select the draft application you want to complete. 4. Complete the application form by providing all required information or uploading necessary documentation. 5. Review the Terms & Conditions and select Accept All to agree to the terms. 6. Select Submit to submit your completed application. You will receive a confirmation email and be notified of status updates. Or to save and continue later, simply navigate away from the page. The system saves your last completed input.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/download-datasets",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/download-datasets",
      "title": "download datasets",
      "content": "Download datasets Once your application is approved, you'll receive an email with instructions to access the Secure Processing Environment (SPE) where you can securely download and work with your approved datasets. To access and work with your approved datasets: 1. Check your email for instructions and access links to the Secure Processing Environment (SPE). 2. Follow the instructions provided in the email to securely access the SPE. 3. Download and work with your approved datasets within the SPE. :::info Stay compliant All data are protected by governance frameworks and data access policies to ensure ethical and legal use. Remember to use data responsibly and according to the terms and agreements you signed during the application process. ::: View approved datasets in the portal You can also view your approved datasets directly in the GDI Portal to see their metadata and details. To view your approved datasets: 1. Select the folder icon () on your dashboard. 2. Select the Entitlements tab to see the list of your approved datasets. 3. Select the dataset to view its details. This view only displays the metadata of your approved datasets. To download and work with the datasets, use the Secure Processing Environment (SPE) as instructed in your approval email.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/request-datasets/track-application",
      "url": "/gdi-userportal-frontend/user-guide/request-datasets/track-application",
      "title": "track application",
      "content": "Track your application After submitting your application, track its progress and check for any status updates or additional requirements from the Data Access Committee. To track your application: 1. Select the folder icon () on your dashboard. 2. Select the APPLICATIONS tab. The page displays all your applications with their current status, sorted by last modified date: In this example, there is one application and one application: 3. Review your application status. Applications can have the following statuses: - DRAFT: Application is incomplete and has not been submitted yet. Continue the application. - SUBMITTED: Application is under review by the Data Access Committee. - RETURNED: Application requires additional information or documents. View the feedback and continue the application. - APPROVED: Application has been approved and you can access the datasets. Download the datasets. - REJECTED: Application has been declined. Select the application to view feedback. To resubmit, create a new application. - CLOSED: Application is closed and no further action is required. Open the application to view details.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/sign-in",
      "url": "/gdi-userportal-frontend/user-guide/sign-in",
      "title": "sign in",
      "content": "Sign in Sign in to get full access to available datasets and request access. Why sign in? Signing in allows you to access enhanced features and request access to datasets. While you can browse datasets without an account, signing in allows you to: - Submit applications to request access to datasets. - Enhance your search with additional filters and more comprehensive search results. - See more dataset information including and other metadata to help assess if datasets meet your research needs. Sign in The GDI Portal uses your existing accounts with other platforms like Google, LinkedIn, and organisations like universities or research institutions, so you don't need to create a separate account. To sign in to the GDI Portal: 1. Open the GDI Portal in your browser: https://portal.dev.gdi.lu/. 2. Select Login at the top right corner of the page. The login page opens. 3. Select LSAAI as your sign-in method. :::info Why LSAAI? GDI Portal requires you to sign in with LSAAI (Login Service for Academic and Administrative Institutions). LSAAI is a secure login system that lets you use your existing accounts like Google, LinkedIn, university, or other institutional accounts. This means you don't need to create a new account specifically for the GDI Portal. ::: 4. Select your account provider: Search for your institution in the search bar, or select from the list of options (LinkedIn, Apple, Google, ORCID, GitHub). 5. Follow the instructions to sign in with your selected account. If it's your first time signing in, you may need to verify your email address. 6. After you sign in, the GDI Portal home page loads and you can start exploring datasets.",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/user-guide/welcome-data-users",
      "url": "/gdi-userportal-frontend/user-guide/welcome-data-users",
      "title": "welcome data users",
      "content": "Welcome to the GDI Data Portal Welcome to the GDI Data Portal user guide! The GDI Data Portal gives you access to Europe's largest network of genomic datasets for your research and analysis needs. As part of the 1+ Million Genomes Initiative, this portal enables federated and secure cross-border access to high-quality genomic data and related phenotypic information across European countries. This guide is for data users—healthcare researchers, policy-makers, and professionals—who want to discover and request access to genomic datasets for research and clinical purposes. Learn more about Genomic Data Infrastructure (GDI) and its founding initiatives. How it works Access genomic datasets in three steps: 1. Explore datasets: Browse and search through detailed dataset information—search by any criteria such as keywords, research topics, disease areas, or allele frequency. Explore datasets. 2. Request access: Found a dataset you want to use? Submit an application to access it. You may need to provide documentation or requirements for your request, and you can invite collaborators to assist you with your application. Request access. 3. Access approved datasets: Once your request is approved, you will receive an email with a link to the Secure Processing Environment (SPE) where you can securely download and work with the datasets. :::info Stay compliant All data are protected by governance frameworks and data access policies to ensure ethical and legal use. Remember to use data responsibly and according to the terms and agreements you signed during the application process. :::",
      "guide": "user-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/ensure-quality",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/ensure-quality",
      "title": "ensure quality",
      "content": "Ensure data quality Maintaining high-quality data in your catalogue is essential for user trust and effective data discovery. This section covers validation, monitoring, and auditing processes to ensure your catalogue maintains quality standards. :::info content in progress We are working on this data quality guide. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/harvest-data",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/harvest-data",
      "title": "harvest data",
      "content": "Set up harvest sources :::info content in progress We are working on this guide. ::: Data harvesting is a crucial process for automatically collecting and integrating datasets from various sources into your CKAN catalogue. This section covers setting up harvesters, managing different data source types, and troubleshooting common issues. Overview The GDI User Portal supports harvesting from multiple data source types: - FAIR Data Points - DCAT-AP endpoints - Other CKAN instances - Custom API endpoints Harvesting tasks Set up harvesters Learn how to configure and deploy harvesters for different data sources, including authentication and scheduling options. Harvest from FAIR Data Points Specific guidance for harvesting metadata from FAIR Data Point implementations, including configuration requirements and best practices. Harvest DCAT-AP data Instructions for setting up DCAT-AP harvesters to collect standardised metadata from European data portals and catalogues. Troubleshoot harvest issues Common problems and solutions for harvesting operations, including network issues, authentication failures, and data mapping problems.",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-datasets",
      "title": "manage datasets",
      "content": "Manage datasets :::info content in progress We are working on this dataset management guide. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/manage-organisations",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/manage-organisations",
      "title": "manage organisations",
      "content": "Manage organisations :::info content in progress We are working on this dataset management guide. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/welcome",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/welcome",
      "title": "welcome",
      "content": "Welcome, catalogue managers :::info content in progress We are working on this catalogue manager guide. ::: Welcome to the GDI Dataset Catalogue Portal Guide! This comprehensive documentation is designed for business users responsible for managing and curating data catalogues within the GDI ecosystem. Your role in the GDI ecosystem As a catalogue manager, you're a business user who plays a crucial role in ensuring high-quality, discoverable genomic datasets are available to the European research community. Your day-to-day responsibilities include: - Publishing datasets - Adding new research data to the catalogue - Managing organisations - Overseeing your institution's data presence - Ensuring quality - Maintaining high standards for data descriptions - Team collaboration - Working with colleagues on data publishing - Supporting users - Helping researchers find relevant datasets Available guides This documentation covers everything you need to manage datasets effectively: - Manage datasets - Learn to publish and update datasets - Manage organisations - Oversee your institution's data presence - Ensure data quality - Maintain high-quality data descriptions - Work with advanced features - Explore enhanced portal capabilities Getting started Choose your starting point based on your immediate needs: - New to the portal? Start with Manage datasets - Setting up your team? Begin with Manage organisations - Focus on quality? Go to Ensure data quality - Exploring features? Check out Work with advanced features Your work in managing datasets helps ensure that Europe's genomic data infrastructure serves the research community effectively.",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/catalogue-managers-guide/work-with-extensions",
      "url": "/gdi-userportal-frontend/catalogue-managers-guide/work-with-extensions",
      "title": "work with extensions",
      "content": "Work with advanced features Learn how to optimise your dataset publishing to take advantage of the portal's advanced capabilities. This guide helps you understand how your data publishing choices enhance user experience and dataset discoverability. :::info content in progress We are working on this advanced features guide. :::",
      "guide": "catalogue-managers-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/about-gdi",
      "url": "/gdi-userportal-frontend/system-admin-guide/about-gdi",
      "title": "About GDI",
      "content": "",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/configure-auth",
      "url": "/gdi-userportal-frontend/system-admin-guide/configure-auth",
      "title": "configure auth",
      "content": "Set up authentication and authorisation The GDI User Portal uses Keycloak for authentication and authorisation, with integration to LS-AAI (Life Science Authentication and Authorisation Infrastructure) for federated access across European research infrastructures. Authentication architecture Keycloak configuration Keycloak serves as the central authentication provider, managing user sessions, roles, and permissions across all platform components. LS-AAI integration Integration with LS-AAI enables users to authenticate using their existing institutional credentials through the European research federation. User role management Configure role-based access control to ensure appropriate permissions for different user types (data users, catalogue managers, system administrators). Configuration tasks Configure Keycloak Set up Keycloak instance with proper realm configuration, client settings, and security policies. Integrate with LS-AAI Configure LS-AAI as an identity provider in Keycloak, including OpenID Connect settings and attribute mapping. Manage user roles Define and manage user roles and permissions to control access to different platform features and data. Identity providers configuration When configuring identity providers (IdPs), you'll need: - ClientSecret - Provided by the IdP during registration - ClientId - Unique identifier for your application - Token URL - OAuth2 token endpoint - Authorisation URL - OAuth2 authorisation endpoint - Redirect URI - Keycloak callback URL Azure AD integration Configure Azure Active Directory as an identity provider for organisational authentication. LS-AAI integration details - Discovery endpoint: - Required scopes: , , , - Sync mode: Import (not force) - Token storage: Enabled for Beacon Network integration Security considerations Token management Proper configuration of token storage and refresh to enable secure API access across services. Access control Implementation of proper access control policies to protect sensitive data and administrative functions. Audit and monitoring Set up logging and monitoring for authentication events and security incidents. :::info content in progress We are working on this guide. :::",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/configure-ls-aai-in-keycloak/keycloak-setup",
      "url": "/gdi-userportal-frontend/system-admin-guide/configure-ls-aai-in-keycloak/keycloak-setup",
      "title": "keycloak setup",
      "content": "Configure LS-AAI in Keycloak Keycloak can be obtained by running the CKAN deployment script that you can find in the following guide: Azure CLI Script Deployment Guide Configuring Identity Providers (IdPs) When configuring identity providers (IdPs), the following information becomes crucial for OpenID setup: - ClientSecret - ClientId - Token URL - Authorization URL - Redirect URI Both the 'Token URL' and 'Authorization URL' are derived from the IdP. When registering a service, you acquire the clientId and secret. The 'Redirect URI', which remains constant, is provided by Keycloak: Additionally, the corresponding configuration entails: - Scopes: \"openid\", \"profile\", \"email\" , \"elixir_id\" - Method: POST the Clientsecret - Sync method: import For Elixer_id additional mapper is needed Azure AD For Azure integration, I followed the tutorial at https://www.youtube.com/watch?v=LYF-NLHD2uQ. This tutorial comprehensively explains both the service registration and the Azure AD setup within Keycloak. Management of the app registration is done within our Ad: portal.zure.com LSAAI To register Keycloak as service I used https://elixir-europe.org/platforms/compute/aai/service-providers. . Initially, obtaining an account is the first step. 1. Make sure your organisation is recognised as IdP and register if not. 2. Submit a registration for you application as a service. Please note that approval for this step may entail a waiting period. Management of the app registration is done within: https://services.aai.lifescience-ri.eu . Discovery endpoint: https://login.elixir-czech.org/oidc/.well-known/openid-configuration The LSAAI configuration looks like: !LSAAI Configuration Part 1 !LSAAI Configuration Part 2 Note 1: Sync mode must be \"import\" instead of \"force\"\\ Note 2: and must be on, to allow User Portal components to get LS-AAI . That enables Beacon Network integration via Oauth2.\\ The first time you log in you will get a question if you want to be a member of the test environment. Agree and proceed. Fetching LS-AAI Access Token from Keycloak Option 1 In order to fetch access token from LS-AAI - or any IdP - one needs to configure Keycloak accordingly, and later request to Keycloak LS-AAI tokens. 1. Go to ; 2. Enable and ; 3. Delete LS-AAI existing users, to ensure users are initialised correctly in Keycloak; 4. Login with a LS-AAI user; 5. Call Keycloak endpoint: Option 2: Configuring OAuth 2.0 in Postman This guide will help you set up OAuth 2.0 authorization for a request in Postman and obtaining the LSAAI token. Steps to Configure OAuth 2.0 1. Open Postman Application Begin by opening the Postman application on your desktop. 2. Select a Request - Choose any existing request from your collections, or create a new one by clicking on the 'New' button and selecting 'Request'. 3. Authorization Setup - Navigate to the 'Authorization' tab within the selected request. 4. Set Authorization Type - From the 'Type' dropdown menu, select 'OAuth 2.0'. 5. Add Authorization Data to Request Headers - In the 'Add authorization data to' dropdown, select 'Request Headers'. 6. Current Token Configuration - For the 'Current Token' section, choose 'Bearer' as the token type. 7. Configure New Token Follow the steps below to configure a new token: - Token Name: Enter a random name for your token. - Grant Type: Select 'Authorization Code' from the dropdown menu. - Authorize Using Browser: Ensure this box is checked to use your default web browser for the authorization. - Auth URL: Replace and with the appropriate values for your Keycloak server and realm. - Access Token URL: Similar to the Auth URL, fill in the Keycloak server and realm information. - Client ID: Enter 'ckan' or the specific client ID you have been provided. - Client Secret: Enter the client secret you obtained from Keycloak that corresponds to your client ID. - Scope: Input the scopes as . - Client Authentication: Select 'Send as Basic Auth header' from the dropdown menu. 8. Obtain Access Token - Click on the 'Get New Access Token' button to initiate the OAuth 2.0 authorization flow. After completing these steps, you should be able to receive an access token that can be used to authorize your requests within Postman, which is containing also an Elixer Id",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/configure-schemas",
      "url": "/gdi-userportal-frontend/system-admin-guide/configure-schemas",
      "title": "configure schemas",
      "content": "Configure metadata schemas Configure and manage CKAN metadata schemas to define dataset fields, validation rules, and data entry forms. This guide covers schema development, deployment, and maintenance for system administrators. Schema structure and format CKAN schemas can be defined as JSON or YAML files that specify dataset metadata fields and their properties. Example field definition Key field properties Configure field behaviour using these properties: - field_name: CKAN field identifier - label: UI field representation for end users - help_text: Explanatory text appearing under field in UI - choices: For dropdown menus - list of dictionaries with value and label - choices_helper: Form dropdowns dynamically from API - presets: Values like , , for automatic checks - form_snippet: Defines field representation for data input (jinja2 format) - display_snippet: Defines how data is shown in UI - validators: Data validation functions - output_validators: Convert complex data structures from database Schema configuration Single schema setup Configure your primary schema in CKAN configuration: Multiple schema support Configure multiple schemas using a declaration file for different dataset types: Reference the multi-schema file in : Schema deployment Update running CKAN instance To change schema in a running Docker container: Changes to trigger automatic CKAN updates. Schema path format Define schemas using the format: Example: Schema management APIs Use CKAN APIs to manage schemas programmatically: Best practices Schema design - Follow DCAT-AP standards for interoperability - Design for user experience, not just technical requirements - Include comprehensive help text for complex fields - Test schemas with real users before deployment Deployment - Test schema changes in development environment first - Document all schema modifications - Consider migration impact on existing datasets - Backup data before major schema updates For comprehensive schema development, see the CKAN scheming documentation. Next steps After configuring schemas: - Manage user roles and permissions - Control access to schema management - Manage data and services - Configure data workflows - Monitor and maintain the system - Track schema usage and performance",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/deploy-infrastructure",
      "url": "/gdi-userportal-frontend/system-admin-guide/deploy-infrastructure",
      "title": "deploy infrastructure",
      "content": "Deploy infrastructure :::info content in progress We are working on this guide. ::: The GDI User Portal consists of multiple interconnected components that require careful deployment and configuration. This section provides comprehensive guidance for system administrators on setting up production-ready infrastructure. Deployment options Deploy to Azure Complete guide for deploying the GDI User Portal on Microsoft Azure infrastructure, including resource provisioning, networking, and security configuration. Deploy to ELIXIR-LU Specific instructions for deploying to ELIXIR Luxembourg infrastructure, tailored for genomic data infrastructure requirements. Configure Docker containers All components run as Docker containers. Learn about container orchestration, networking, and persistent storage configuration. Manage environments Best practices for managing multiple environments (development, staging, production) and environment-specific configuration. Component installation User Portal Frontend The frontend provides the web interface and integrates with backend services. Built with Next.js for optimal performance and user experience. Installation guide: User Portal Frontend README Dataset Discovery Service (DDS) Backend service that mediates between the frontend and CKAN, providing abstraction and enhanced functionality. Installation guide: Dataset Discovery Service README Access Management Service (AMS) Handles access requests, user permissions, and integration with external systems like REMS. Installation guide: Access Management Service README CKAN Extensions The platform uses several custom CKAN extensions that must be properly integrated: - GDI Userportal Ckanext - Core GDI functionality - Fair Datapoint Ckanext - FAIR principles support - Harvest Ckanext - Data harvesting capabilities For extension integration, see the CKAN Docker repository installation guide.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/fdp/fair-data-point",
      "url": "/gdi-userportal-frontend/system-admin-guide/fdp/fair-data-point",
      "title": "fair data point",
      "content": "FAIR data point setup Fair Data Point (FDP) Installation Guide This guide provides steps to install FDP and configure it with GDI-specific SHACL shapes. For a more comprehensive overview, please refer to the existing FDP documentation on exposing metadata. 1. Installing FDP 1. Follow the installation guide in the documentation linked above to set up FDP in your environment. 2. Ensure that the FDP instance is accessible and that you have administrative rights to configure metadata schemas. 2. Installing GDI-Specific SHACLs To add GDI-specific SHACL validation, perform the following steps: Step 1: Download SHACL Shapes - Access the GDI-specific SHACL shapes from this GDI metadata repository. - Download each SHACL shape file (e.g., and others). Step 2: Upload SHACL Shapes to FDP 1. Login to FDP using an admin account. 2. Navigate to Metadata Schemas (located in the dropdown under your username). 3. For each shape file: - Open the editor and paste the contents of (or other shapes). - Add a description to document the purpose or release information. - Ensure the abstract checkbox is selected when uploading , as most other classes derive from it. - For other shapes, uncheck the abstract checkbox. - Press Save and Release to finalize the shape. - Provide a meaningful description and version number for the release. - Check the public checkbox to make the shape accessible. - Press Release to complete the upload. Repeat these steps for each SHACL shape file. 3. Supported Metadata Fields for Datasets The following metadata fields are currently supported: Dataset | Property Name | Example Data | | ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | contact_point | VCard(hasEmail=[mailto:data-access-committee@xumc.nl], full_name=[Data Access Committee of the x UMC], hasUID=https://ror.org/05wg1m734) | | creator | Agent(name=[Academic Medical Center], identifier=https://ror.org/05wg1m734) | | description | This dataset is part of the GDI MS8 milestone, focused on the distributed analysis of COVID-19 cases (GWAS) and allele frequency lookup for infectious diseases. It contains synthetic data designed to replicate COVID-19-related genetic studies, including risk variants associated with severe disease outcomes. The data is used for federated analysis across multiple nodes to identify genomic associations and variant prevalence. | | number_of_patients | 100 | | issued | 2024-07-01T11:11:11 | | keywords | Covid, Smokers, (free to choose) | | identifier | GDID-[0-9a-f]{8}-[0-9a-f]{4} | | modified | 2024-06-04T13:36:10.246Z | | publisher | Agent(name=[Radboud University Medical Center], identifier=https://ror.org/05wg1m734, mbox=[mailto:test@health-ri.nl]) | | theme | http://publications.europa.eu/resource/authority/data-theme/HEAL | | title | COVID-19 GWAS and Allele Frequency Lookup Dataset for GDI MS 8 | | number_of_participant | 100 | | phenotypes | Age (min and max) | | accessRights | DUO:0000006, DUO:0000017, DUO:0000018 (General research use, Infectious Disease research use, Genomic research on complex diseases) | Distribution | Property Name | Example Data | | --------------- | ------------------------------------------------------------------------- | | title | GWAS and Allele Frequency Lookup Data Distribution for GDI MS8 | | description | VCF file containing COVID-19 case/control data for GDI MS8 demonstration. | | access_url | https://example.com/dataset/GDI-MS8-COVID19.vcf | | media_type | https://www.iana.org/assignments/media-types/application/vcf | | license | https://creativecommons.org/licenses/by-sa/4.0/ | 4. Onboarding Metadata To onboard large datasets more efficiently, you can use a Jupyter notebook to automate this process. Clone the Sempyro repository and run the notebook using: As a reference, an MS8 template/example is available in the notebook for streamlined metadata upload to FDP.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/installation/azure",
      "url": "/gdi-userportal-frontend/system-admin-guide/installation/azure",
      "title": "azure",
      "content": "Azure CLI Script Deployment Guide for a Catalogue with CKAN This guide will walk you through the process of deploying an environment using Azure CLI that includes a CKAN container, Frond end catalogue, SOLR for CKAN, Keycloak for authentication, a managed PostgreSQL server, and Redis Cache. This environment is suitable for development purposes, and further security and performance reviews are necessary for production deployment. Prerequisites - Azure CLI installed: Make sure you have Azure CLI installed on your machine. You can install it via Homebrew with the command . - GitHub Personal Access Token (classic): You'll need a personal access token from GitHub with pack read permissions. - Azure Account with Sufficient Permissions: Ensure you have an Azure account with permissions that, at a minimum, allow you to create a resource group. - PSQL installed: Ensure that PSQL is installed (e.g. ) Initial Setup Before running the script, you'll find several parameters at the beginning of the script that can be customized: - Passwords for the CKAN database, Keycloak database, and the PostgreSQL admin. Change these to secure passwords as desired. Deployment Steps 1. Execute the Script: - Navigate to the deployment project at GenomicDataInfrastructure/gdi-userportal-deployment. - Go to the Azure deployment folder - Run to start the deployment process. 2. Enter Required Information: - The script will prompt you to enter the necessary information. Fill in the details as requested. 3. Script Execution: - After entering the information, the script will automatically execute, setting up the environment and deploying the code. It typically takes about 10 minutes for the entire process to complete and for the services to be up and running. 4. Verification: - Once the script execution is complete, verify that all components are online by accessing the following URLs, replacing with your project name and with your environment name: - SOLR: - CKAN: - Catalog: - Keycloak: 5. Import CKAN Realm into Keycloak: - After verifying that all components are online, the next step is to import the CKAN realm into Keycloak. Log in to Keycloak using the admin account to perform this action. (creditials can be found in the script) Components Included - Azure Web App with CKAN Container: Runs a CKAN container from the main branch of the gdi-userportal-ckan-docker repository. - Azure Web App with Front Catalog: Originates from the main branch of the gdi-userportal-frontend repository. - Azure Web App with SOLR for CKAN: Dedicated SOLR instance for CKAN. - Azure Web App with Keycloak: For authentication and authorization. - Managed PostgreSQL Server: Includes a Keycloak database and a CKAN database. - Managed Redis Cache: For caching purposes to enhance performance. Note This setup is intended for development use. Before moving to a production environment, review and adjust the security and performance settings to meet the necessary requirements.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/installation/components",
      "url": "/gdi-userportal-frontend/system-admin-guide/installation/components",
      "title": "components",
      "content": "Installation guides The user portal consists of multiple components. To install or contribute to a specific component, refer to the respective installation guide linked below. All components run on Docker containers, and their individual setups are documented in their respective repositories. Components User Portal Frontend The User Portal Frontend, built with Next.js, provides a web interface for interacting with key services, including the Dataset Discovery Service (DDS) and the Access Management Service (AMS). It acts as the primary user interface for the GDI project. Installation guide: User Portal Frontend README Dataset Discovery Service (DDS) The Dataset Discovery Service acts as a backend layer mediating requests from the frontend to CKAN’s data catalog APIs. It retrieves, processes, and maps dataset information while abstracting CKAN-specific logic. To use DDS, ensure that the GDI CKAN extension is installed in your CKAN instance. Installation guide: Dataset Discovery Service README Access Management Service (AMS) The Access Management Service ensures secure interactions between the frontend and backend data authorities. It provides APIs for managing user access requests and integrates with external APIs like REMS to enforce policies and track user actions. Installation guide: Access Management Service README CKAN Extensions CKAN is an open-source data management system for publishing, sharing, and discovering datasets. It enables cataloging, searching, and accessing data through a web interface and API. Custom extensions can be developed to extend CKAN’s core functionalities. The User Portal uses several extensions, including one specifically developed for this project. Extensions used include (but are not limited to): - GDI Userportal Ckanext: Adds a DCAT-AP 3 compatible schema with fields such as , , , and . It also provides enhanced parsing for creators in the DCAT profile, adds support for OpenID Connect with PKCE, introduces new fields to , and links CKAN harvest views for admin users. Additionally, it offers endpoints for listing unique values and simplifies integration with CKAN-based datasets for the User Portal. - Fair Datapoint Ckanext: Provides features related to FAIR principles to enhance dataset accessibility and interoperability. - Harvest Ckanext: Supports automated data harvesting and integration with external data sources. In order to contribute on a ckan extension and run it on you local machine, it must be integrated into the docker build that will run as your backend service, connected to your DDS instance. For a detailed guide on how to integrate the extention, read 5. installing new extensions from the CKAN Docker repository",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/installation/elixir-lu",
      "url": "/gdi-userportal-frontend/system-admin-guide/installation/elixir-lu",
      "title": "elixir lu",
      "content": "Current deployment - - User Portal - - IAM - - API Gateway - - Catalogue Deployment Steps 1. Checkout . 2. Copy into the server and update all the secrets. 3. Run . 4. Run . 5. Run . 6. Enter in REMS docker container. 7. Configure the admin user. 8. Configure apikey, for any user and any REST method, but limited to . 9. Configure apikey and robot for any REST method, but limited to . 10. Configure apikey and robot, limited to . 11. Include in the environment variables the newly created apikeys and users. 12. Run . 13. Log into CKAN as sysadmin. 14. Add the harvest sources. 15. Wait for REMS Synchronizer or run it manually. 16. Access Keycloak. 17. Configure LS-AAI IdP. 18. Add mapper, that maps the clain clain into . 19. Create a new OIDC realm for GDI, that accepts redirections to User Portal, CKAN and REMS. 20. Create a new client scope for GDI realm. 21. Add new User Attribute Mapper, that maps the attribute into a claim called and a scope called . 22. Create a new client for User Portal, REMS and CKAN. 23. Add the scope into the newly created client.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/manage-data-services",
      "url": "/gdi-userportal-frontend/system-admin-guide/manage-data-services",
      "title": "manage data services",
      "content": "Manage data and services :::info content in progress We are working on this guide. ::: This section covers the administration of core data management services including CKAN administration, FAIR Data Point deployment, harvester configuration, and database management. Data service components Administer CKAN CKAN serves as the core data catalogue system. Learn about user management, organisation setup, dataset administration, and system maintenance. Set up FAIR Data Points FAIR Data Points provide standardised metadata endpoints that support FAIR principles. Configure FDP instances with GDI-specific SHACL shapes and metadata requirements. Configure harvesters Set up automated data harvesting from external sources including other CKAN instances, FAIR Data Points, and DCAT-AP endpoints. Manage databases Maintain database performance, backups, and integrity across PostgreSQL instances used by CKAN and other services. CKAN administration System configuration - Instance configuration and settings - Extension management and updates - Performance tuning and optimisation - Security configuration and updates User and organisation management - User account administration - Organisation setup and management - Permission and role assignment - API key management Data management - Dataset lifecycle management - Metadata quality assurance - Storage and backup procedures - Search index maintenance FAIR Data Point setup Installation and configuration Deploy FDP instances with GDI-specific requirements and configure metadata schemas using SHACL shapes. Metadata schema configuration Install and configure GDI-specific SHACL shapes for consistent metadata representation across the network. Supported metadata fields Comprehensive coverage of dataset and distribution metadata fields including contact points, creators, themes, and access rights. Harvesting configuration Harvester setup - Configure harvest sources and schedules - Set up authentication for protected endpoints - Monitor harvest job performance - Troubleshoot harvest failures Data source integration - FAIR Data Point harvesting - DCAT-AP endpoint harvesting - Custom API integration - Real-time vs. scheduled synchronisation Database management Performance monitoring - Query performance analysis - Index optimisation - Connection pool management - Resource utilisation tracking Backup and recovery - Automated backup procedures - Point-in-time recovery - Disaster recovery planning - Data integrity verification",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/manage-schemas",
      "url": "/gdi-userportal-frontend/system-admin-guide/manage-schemas",
      "title": "manage schemas",
      "content": "Manage schemas :::info content in progress We are working on this guide. ::: Learn how to configure and manage CKAN dataset schemas for the GDI User Portal. This guide covers schema format, field definitions, and deployment procedures. Schema format and field definitions A CKAN schema can be defined either as JSON or YAML file. The GDI User Portal uses JSON schemas for consistency. Field structure A field in CKAN schema JSON file has the following format: Where: - - CKAN field identifier - - UI field representation - - Text appearing under field in UI next to icon. Square brackets contain DCAT-AP mapping information Field configuration options Documentation on field keys and specifications can be found in the CKAN Scheming documentation. Available field keys include: - - For handling cardinality requirements - - Controls field appearance on multi-stage forms - - For dropdown lists (array of dictionaries with value and label) - - For dynamic dropdowns or API-driven choices - - Built-in field types (, , ) - - Custom field representation (Jinja2-based format) - - Custom data display formatting - - Override representation for DCAT mapping Example with display property: Validation configuration - - Data validation functions. Available functions listed in CKAN validators documentation - - Convert complex data structures from database storage back to objects Important: Default validation includes and . When specifying custom validators, include these explicitly if needed. Changing schemas in running instance Schema configuration Schema is defined in setup scripts by setting: Runtime schema changes In running Docker container, schema is configured in : Configuration changes trigger automatic CKAN updates. Schema path format Schema paths follow format: Example: resolves to extension directory structure under Multi-schema configuration Configuration file approach For better maintainability, create a JSON configuration file under extension schemas directory: Multiple dataset types Support for multiple schema types: Configure in : Schema merging behaviour - Core CKAN: Latest schema with same takes precedence - GDI implementation: Schemas with same type are merged, field order follows schema order in configuration - Field merging: Controlled by parameter - : Latest field definitions take precedence - Fields are never deleted, only added or modified - To remove fields, explicitly undeclare or set to empty API management List available schemas Get specific schema Search configuration Control dataset type visibility in search with:",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/manage-user-roles",
      "url": "/gdi-userportal-frontend/system-admin-guide/manage-user-roles",
      "title": "manage user roles",
      "content": "Manage user roles and permissions Configure and manage user access levels within the CKAN data catalogue system. This guide covers platform-wide and organisation-specific role management for system administrators. CKAN user role hierarchy Understanding CKAN user roles is essential for effective system administration. CKAN operates with two levels of roles: Platform-level roles 1. Visitor - Capabilities: Search and view public datasets - Access level: Anonymous/unauthenticated users 2. Registered User - Capabilities: - Become a member of an organisation (requires admin approval) - Publish, edit, or add datasets based on their role in the organisation - Manage their own profile - Configuration note: Creation of organisations is typically disabled for regular users 3. Sysadmin - Capabilities: - Access and edit any organisations - View and change user details - Permanently delete datasets - Customise the look and feel of the platform - Configure system-wide settings Organisation-level roles 1. Member - Capabilities: View the organisation's private datasets - Use case: Users who need access to restricted organisational data 2. Editor - Capabilities: - All capabilities of a Member - Add new datasets to the organisation - Edit or delete any of the organisation's datasets - Make datasets public or private - Use case: Content contributors and data curators 3. Organisation Admin - Capabilities: - All capabilities of an Editor - Add users to the organisation, and set their role (member, editor, or admin) - Change the role of any user in the organisation, including other admin users - Remove members, editors, or other admins from the organisation - Edit the organisation's details (e.g., title, description, image) - Delete the organisation - Use case: Organisational data stewards and managers User management procedures Configure platform roles Use CKAN's admin interface to manage platform-level user permissions and system access. Set up organisation permissions Configure organisation-specific roles and manage member access to datasets within organisational boundaries. Role assignment best practices - Follow principle of least privilege - Regular audit of user permissions - Document role assignments and changes - Implement approval workflows for sensitive roles For detailed role management procedures, see the CKAN authorisation documentation. Activity monitoring and auditing Monitor user activity and dataset changes to maintain data integrity and track catalogue usage. Enable activity streams CKAN displays a full history of dataset changes in the Activity Stream. For new installations, this is enabled by default, but upgrades may need manual activation. To make activity history public, add this to your file: Note: Since CKAN 2.10, Activity must be activated as a plugin. See the CKAN 2.10 changelog for details. Activity monitoring levels Configure activity tracking at different levels: - Organisation level - Track all changes within an organisation - Dataset level - Monitor specific dataset modifications - Difference view - See detailed changes between versions - User activity - Track individual user actions and access patterns Audit configuration For complete activity configuration options, see CKAN activity settings documentation. Next steps After configuring user roles: - Manage data and services - Set up data management workflows - Monitor and maintain the system - Ongoing system maintenance - Deploy and manage infrastructure - Infrastructure management",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/monitor-maintain",
      "url": "/gdi-userportal-frontend/system-admin-guide/monitor-maintain",
      "title": "monitor maintain",
      "content": "Monitor and maintain the system :::info content in progress We are working on this guide. ::: Ongoing monitoring and maintenance are crucial for ensuring the reliability, security, and performance of your GDI User Portal deployment. This section covers monitoring tools, maintenance procedures, and troubleshooting approaches. Monitoring components Monitor performance Track system performance metrics including response times, resource utilisation, and user activity to ensure optimal platform operation. Audit security Implement comprehensive security monitoring including access logging, intrusion detection, and compliance verification. Back up data Establish reliable backup procedures for all critical data including CKAN databases, configuration files, and user data. Publish new versions Manage platform updates and version deployments with minimal downtime and proper rollback procedures. Performance monitoring",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/platform-overview",
      "url": "/gdi-userportal-frontend/system-admin-guide/platform-overview",
      "title": "platform overview",
      "content": "Platform overview :::info content in progress This section will describe architecture, components, and interactions at a high level. ::: The GDI User Portal consists of multiple interconnected components: - User Portal Frontend - Next.js web interface providing the user experience - Dataset Discovery Service (DDS) - Backend API layer mediating frontend-CKAN communication - Access Management Service (AMS) - Access control and data request management - CKAN - Open-source data catalogue management system with custom extensions - Keycloak - Authentication and authorisation service - Supporting services - PostgreSQL, Elasticsearch/Solr, Redis, Docker containers",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/publishing-new-version/release-process",
      "url": "/gdi-userportal-frontend/system-admin-guide/publishing-new-version/release-process",
      "title": "release process",
      "content": "Publishing new versions > All repositories must follow the same process. > Once all necessary changes are merged to , please follow this process: - Ensure is up to date. - Push a new tag following the versioning and releases described in this page. The tag name follows . Example: - Create a new release branch, to simplify bugfixing and security patches. The branch name follows . Example: - Stage the Commit the : Push the branch to the remote repository - Go to GitHub and create a new release, example: - Click on \"Draft a new release\" CHANGELOG - Select the just created release branch and tag. - Enter a title for the release that includes the version and possibly a short description. - Auto-generate release notes. - Remove unnecessary release notes: ensure that only relevant information for the users is included and matches CHANGELOG.md. - Double-check all entered information. - Click on \"Publish release\" to officially make the release. - Ensure docker images were built and published correctly.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/system-admin-guide/welcome",
      "url": "/gdi-userportal-frontend/system-admin-guide/welcome",
      "title": "welcome",
      "content": "Welcome, system administrators :::info content in progress We are working on this deployment guide. ::: Welcome to the GDI User Portal System Administration Guide! This comprehensive documentation is designed for system administrators responsible for deploying, configuring, and maintaining the GDI User Portal platform and its associated services. Get started Choose your focus area based on your immediate needs: - New deployment? Start with Deploy and manage infrastructure - Setting up users? Begin with Set up authentication and authorisation - Managing access? Go to Manage user roles and permissions - Configuring data? Check out Manage data and services - System health? Explore Monitor and maintain the system This guide provides the technical knowledge you need to successfully deploy and maintain the GDI User Portal platform for the European genomic data research community.",
      "guide": "system-admin-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/about-gdi",
      "url": "/gdi-userportal-frontend/developer-guide/about-gdi",
      "title": "About GDI",
      "content": "",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/add-modify-features",
      "url": "/gdi-userportal-frontend/developer-guide/add-modify-features",
      "title": "add modify features",
      "content": "Add and modify features :::info content in progress We are working on this guide. ::: This section covers advanced development topics including metadata field management, extension development, and comprehensive testing strategies for adding new features to the GDI User Portal. Feature development overview Adding new features to the GDI User Portal typically involves: 1. Frontend development - User interface and experience 2. Backend integration - API endpoints and data processing 3. Metadata management - Schema updates and field additions 4. Testing - Comprehensive testing across all layers 5. Documentation - User and developer documentation Metadata field management Manage metadata fields Adding, modifying, or deleting metadata fields requires updates across multiple components of the CKAN ecosystem. Process overview When adding new metadata fields, you must update: 1. CKAN DCAT model - Core schema definition 2. Solr search integration - Search indexing 3. FAIR Data Point - SHACL shapes 4. SeMPyRO - Metadata automation 5. Discovery Service - API mapping CKAN DCAT model updates For DCAT-AP 3 compliant fields: Example schema addition: Solr Search Configuration To make fields searchable: After changes, rebuild the search index: FAIR Data Point integration Add SHACL shapes in FDP: SeMPyRO integration Add property to relevant class: Discovery Service mapping Update OpenAPI definitions and mapping: For complete metadata field procedures, see Metadata field management. Extension development Develop extensions CKAN extensions provide powerful capabilities to enhance catalogue functionality. Extension structure Plugin development Custom Validators Template Customization Testing Strategies Write and Run Tests Comprehensive testing ensures feature reliability and maintainability. Frontend Testing API Integration Testing E2E Testing Extension Testing Performance Considerations Optimization Strategies - Database Indexing - Ensure proper indexes for new fields - Caching - Implement appropriate caching for expensive operations - Lazy Loading - Load heavy components only when needed - Bundle Optimization - Minimize JavaScript bundle size Monitoring",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/add-update-metadata-fields/metadata-fields",
      "url": "/gdi-userportal-frontend/developer-guide/add-update-metadata-fields/metadata-fields",
      "title": "metadata fields",
      "content": "Add and update metadata fields :::info content in progress We are working on this guide. ::: This document outlines the steps required to add, modify, or delete fields across various components of the CKAN ecosystem, including DCAT-AP schema updates, Solr search configuration, SeMPyRO, Discovery Service, and FAIR Data Point (FDP). Table of Contents 1. CKAN DCAT Model 2. Solr Search Integration 3. FAIR Data Point 4. SeMPyRO 5. Discovery Service 6. General Improvements --- CKAN DCAT Model When a schema change falls under DCAT-AP 3 or an earlier version of DCAT-AP but is not yet present, follow these steps: 1. Fork and clone the repository: 2. Add the new field to the schema: - Modify the schema file: - Use appropriate field types (e.g., text, repeating subfield, URI). - Follow examples from other fields for consistency. For more information about scheming can be found in the CKAN Scheming documentation 3. Extend the existing mapping depending on the DCAT-AP version: Modify the mapping files located in the directory: 4. Fix the corresponding unit tests: 5. Create a pull request to the CKAN DCAT extension repository. Ensure that you follow the contributing guidelines for CKAN: - Include unit tests for the new fields. - Ensure compatibility across different DCAT-AP versions. 6. Update the following repositories after a new release: Update development and production Dockerfiles in these repositories( order is important): - https://github.com/GenomicDataInfrastructure/gdi-userportal-ckanext-fairdatapoint - https://github.com/GenomicDataInfrastructure/gdi-userportal-ckan-docker Check if ckan locally works with the new added fields by harvesting an example FDP Example of new field An example of a missing mapping in CKAN DCAT can be found here: Multi-valued field creator in CKAN DCAT. > Note: Always take into account the mapping from CKAN → DCAT in addition to DCAT → CKAN. --- Solr Search Integration If you're adding a new field in CKAN and you want it to be searchable via Solr, follow these steps to modify the file. Steps to Add and Configure a Searchable Field 1. Defining the Field Type and Name In the top part of the file, define the type and name of the new field. The type specifies how Solr will handle the data in the field (e.g., as , , , etc.). - Navigate to the section in where other fields are defined. - Add your new field with its corresponding type. Example: Here, custom_field is the name of the field, and it's set as a string type. It is also indexed (which makes it searchable) and stored (so it can be returned in search results). 2. Adding the Field to Search In the lower part of the schema.xml file, you'll need to add this field to the list of fields that are searchable by Solr. This is typically done in a section that defines which fields are indexed for searches. Example: This example maps the custom_field to the text field, which Solr uses for full-text searches. By adding the copyField directive, you're instructing Solr to include the contents of custom_field in the search index 3. When finished. Release a new version and update When finished. Release a new version and update GitHub - GenomicDataInfrastructure/gdi-userportal-ckan-docker: Scripts and images to run CKAN using Docker Compose in the development and production dockerfile Notes Indexing vs Storing: - indexed=\"true\": The field can be used in searches. - stored=\"true\": The field can be retrieved in search results. Testing the Configuration: After making these changes, you should restart your Solr instance and reindex your CKAN data to ensure that the new field is indexed and searchable with the command: SeMPyRO Prerequisites Fields are easy to add to SeMPyRO. You’ll need to know a few things: - The predicate of the field - Cardinality (single or multiple-valued) - Range or datatype Adding a Field Once that’s identified, go to the relevant class and add a property as follows. Here’s an example of the property of : At Line 1, we see , which is the name of the property. Its range is an , which is a helper for any URL. Other examples of this are or sometimes even classes like or . It is multi-valued because it's in a . If the maximum cardinality is one, it should not be in a . At Line 2, indicates the field is optional and by default undefined. Leave this line out for mandatory fields. At Line 3, we have a human-readable description of the field. At Line 4, we define the predicate. In this case, it's . Some common namespaces, like and , are imported by default. A full URI can also be defined, for example with . At Line 5, we define the RDF type. There are many possible values here, such as , , or . It's recommended to take a look at other properties to understand what is necessary here. Once this is done, the JSON and YAML schemas need to be re-generated. For the class, this can be done by running the following command: FAIR Data Point For the technical point of view, updating the appropriate SHACL shapes allows for adding of fields. Steps to Add a Field in FDP: 1. In the FDP, log in as an admin user and go to the Metadata schemas option. 2. Select the resource to update (e.g. Catalog). 3. In the Form Definition textarea, add a new entry in the list of values. For example: 4. Click Save if this is a draft and needs further work, or Save and release if the work is done. 5. Add a description and select a version number. 6. Click Release. Discovery Service The Dataset Discovery service requires two parts to be updated: the OpenAPI definitions and the mapping. OpenAPI Definition Two definitions need to be updated, both located in the folder: - ckan.yaml: This file contains the API returned by CKAN. Based on this YAML, Java classes are automatically generated corresponding to the API definition. For adding a field to a Dataset, the primary change will likely be in the CkanPackage definition. See the examples there on how to add a property. - discovery.yaml: This file defines what the Discovery service should return. You can make this definition whatever you want it to be—it does not have to correspond one-to-one with CKAN. To add a property here, modify the RetrievedDataset definition. Again, see the examples in the file. Mapping Once you have changed the definitions, follow these steps: 1. Run the following command:",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/develop-ckan-extensions",
      "url": "/gdi-userportal-frontend/developer-guide/develop-ckan-extensions",
      "title": "develop ckan extensions",
      "content": "Develop CKAN extensions Learn how to develop and test custom CKAN extensions for the GDI User Portal. This guide covers local development setup, extension structure, and testing procedures. Local development setup To develop and test CKAN extensions locally, you need to set up a proper development environment: 1. Set up virtual environment Note: Keep the virtual environment activated during the entire installation process. 2. Install CKAN as a package 3. Troubleshoot common dependency issues psycopg2 building issues If installation of fails: 1. Edit the requirements file at 2. Change to 3. Reinstall dependencies and CKAN separately: PyYAML compatibility issues For CKAN v2.9.10, if you encounter this error: Downgrade PyYAML in requirements.txt from or to . 4. Install required extensions Extensions can be installed from local repositories or directly from GitHub. Install from local repository Example on macOS: Install from GitHub Install extension dependencies Example for ckanext-harvest: 5. Configure database Set up PostgreSQL database and specify database connection strings in both and . Testing CKAN extensions Testing strategy depends on extension functionality. CKAN provides helper functions for generating dummy data and cleaning databases. Testing setup 1. Install pytest-ckan: Should be in extension's 2. Configure test.ini: Point to CKAN's test configuration 3. Configure test-core.ini: Set correct database connection Recommendation: Use separate test database instance for extensions requiring database writes. Running tests Basic test execution Test with coverage PyCharm configuration Set environment variable: Testing best practices - Review CKAN testing documentation for detailed guidance - Use CKAN helper functions for data generation and cleanup - Write tests for all extension interfaces and validators - Test schema changes with various data scenarios - Include integration tests for API endpoints Extension development workflow For detailed extension development procedures, see: - Add and modify features - Complete feature development guide - Work with backend services - Integration patterns - CKAN extensions documentation - Official guide Next steps After setting up your development environment: - Add and modify features - Build complete features - Work with backend services - Integrate with GDI services - Get started - Review overall development setup",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/develop-frontend",
      "url": "/gdi-userportal-frontend/developer-guide/develop-frontend",
      "title": "develop frontend",
      "content": "Develop frontend features :::info content in progress We are working on this guide. ::: The GDI User Portal frontend is built with Next.js 13+ using the App Router, TypeScript, and Tailwind CSS. This section covers frontend development including theming, component development, and API integration. Frontend architecture Technology stack - Next.js 13+ with App Router for server-side rendering and routing - TypeScript for type safety and better developer experience - Tailwind CSS for utility-first styling and responsive design - React Hook Form for form handling and validation - SWR for data fetching and caching - Radix UI for accessible component primitives Component organisation Theme customisation and styling Customise themes and styling The GDI User Portal offers extensive customisation options through configuration files and CSS variables. Configuration-based theming Modify for site-wide customisation: CSS customisation Use to define colour schemes: Custom fonts 1. Add font files to 2. Define font faces in 3. Update Tailwind configuration for font usage Visual assets Replace default assets in : - - Header logo - - Footer logo - - Browser icon - - Homepage background For detailed theming documentation, see Frontend Customisation. Component development Build components Follow established patterns for creating new React components: Component guidelines - Use TypeScript for all components - Implement proper accessibility (ARIA labels, keyboard navigation) - Follow established naming conventions - Include comprehensive prop types - Write unit tests for component logic State management - Use React's built-in state management for local state - Implement custom hooks for complex state logic - Use SWR for server state management - Context providers for global application state API integration Integrate with APIs The frontend integrates with multiple backend services using consistent patterns. Data Fetching with SWR API Route Handlers Service integration patterns Dataset Discovery Service integration - Search and filter datasets - Retrieve dataset metadata - Handle pagination and sorting Access Management Service integration - Submit access requests - Track application status - Manage user permissions Authentication integration - Handle login/logout flows - Manage user sessions - Secure API communication Testing Frontend testing strategy Testing best practices - Test user interactions, not implementation details - Use semantic queries for element selection - Mock external API calls - Test accessibility compliance - Implement visual regression testing Development tools Code quality - ESLint for code linting - Prettier for code formatting - TypeScript for type checking - Husky for Git hooks Development workflow Performance optimisation Next.js optimisation - Use Next.js Image component for optimised images - Implement proper code splitting - Utilise server-side rendering where appropriate - Optimise bundle size with dynamic imports Accessibility - Follow WCAG guidelines - Test with screen readers - Ensure keyboard navigation - Implement proper ARIA attributes",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/get-started",
      "url": "/gdi-userportal-frontend/developer-guide/get-started",
      "title": "get started",
      "content": "Get started :::info content in progress We are working on this guide. ::: This guide helps you set up a complete development environment for the GDI User Portal platform, including all necessary tools and dependencies. Prerequisites Before you begin, ensure you have the following installed: - Node.js (version 18 or higher) - npm or yarn package manager - Git for version control - Docker and Docker Compose for containerised services - Java 11+ (for backend services) - PostgreSQL (for local database development) Development environment setup 1. Clone the repository 2. Install dependencies 3. Environment configuration Copy the example environment file and configure for local development: Edit with your local configuration settings: 4. Start development services Use Docker Compose to start the required backend services: This starts: - CKAN instance with GDI extensions - PostgreSQL database - Keycloak authentication server - Dataset Discovery Service - Access Management Service 5. Start the development server The application will be available at . Project structure Understanding the codebase organisation: Local development workflow 1. Feature development - Create feature branches from - Use descriptive commit messages - Follow the established coding conventions - Write tests for new functionality 2. Testing Run the test suite before committing: 3. Code quality Maintain code quality with automated tools: Backend services integration Dataset Discovery Service The DDS provides abstraction over CKAN APIs. For local development: - Repository: gdi-userportal-dataset-discovery-service - Local URL: Access Management Service The AMS handles access requests and user permissions: - Repository: gdi-userportal-access-management-service - Local URL:",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/theming/customise-frontend",
      "url": "/gdi-userportal-frontend/developer-guide/theming/customise-frontend",
      "title": "customise frontend",
      "content": "Frontend customisation :::info content in progress We are working on this guide. ::: The GDI User Portal offers extensive customisation options through configuration files and public assets. This guide will help you understand how to customise various aspects of the portal. Configuration options The following configuration options can be set in the file: | Variable Name | Explanation | Example Value | | ---------------------------------- | ----------------------------------------------- | --------------------------------------------------------- | | NEXT_PUBLIC_SITE_TITLE | Main title of the website | \"GDI - User Portal\" | | NEXT_PUBLIC_SITE_DESCRIPTION | Brief description of the site | \"Genomic Data Infrastructure User Portal\" | | NEXT_PUBLIC_HOMEPAGE_TITLE | Main heading on the homepage | \"WELCOME TO GDI\" | | NEXT_PUBLIC_HOMEPAGE_SUBTITLE | Subheading text on the homepage | \"The Genomic Data Infrastructure (GDI) project...\" | | NEXT_PUBLIC_HOMEPAGE_ABOUT_CONTENT | Detailed content for the about section | \"The Genomic Data Infrastructure (GDI) homepage...\" | | NEXT_PUBLIC_BANNER_LINK | Navigation link for the banner | \"/howto\" | | NEXT_PUBLIC_FOOTER_TEXT | Text displayed in the footer | \"GDI project receives funding from the European Union...\" | | NEXT_PUBLIC_LINKEDIN_URL | LinkedIn social media link | \"https://www.linkedin.com/company/gdi-euproject/\" | | NEXT_PUBLIC_TWITTER_URL | Twitter/X social media link | \"https://twitter.com/GDI_EUproject\" | | NEXT_PUBLIC_GITHUB_URL | GitHub repository link | \"https://github.com/GenomicDataInfrastructure\" | | NEXT_PUBLIC_WEBSITE_URL | Main project website link | \"https://gdi.onemilliongenomes.eu/\" | | NEXT_PUBLIC_EMAIL | Contact email address | \"gdi-coordination@elixir-europe.org\" | | NEXT_PUBLIC_SHOW_BASKET_AND_LOGIN | Feature flag for basket and login functionality | \"true\" | Public assets customisation The portal's appearance can be customised through various files in the directory: Core configuration files 1. : Contains main site configuration including: - Site title and description - Homepage content and titles - Social media links - Contact information - Footer text - Feature flags 2. : Defines the colour scheme including: - Primary and secondary colours - Info and warning colours - Hover states - Surface colours - Dark mode support Visual assets 1. Logos: - : Main logo displayed in the header - : Logo displayed in the footer - : Browser tab icon 2. Images: - : Background image for the about section Typography 1. : Custom font definitions and typography settings 2. directory: Contains custom font files Content files 1. : About page content 2. : How-to guide content 3. : Legal information and terms Customisation best practices 1. Colours: - Use the file to maintain consistent branding - Consider both light and dark mode colour schemes - Ensure sufficient contrast for accessibility 2. Typography: - Add custom fonts to the directory - Define font faces in - Maintain consistent font usage throughout the application 3. Content: - Keep content in markdown files for easy maintenance - Update for site-wide text changes - Maintain proper licensing information in files 4. Images: - Use SVG format for logos when possible - Optimise image sizes for web performance - Include appropriate alt text in implementation 5. Environment variables: - Use different values for development, staging, and production - Keep sensitive values secure - Document any new variables added to the system",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/welcome",
      "url": "/gdi-userportal-frontend/developer-guide/welcome",
      "title": "welcome",
      "content": "Welcome, developers :::info content in progress We are working on this developer guide. ::: Welcome to the GDI User Portal Developer Guide! This comprehensive documentation will help you contribute to the Genomic Data Infrastructure (GDI) User Portal platform, whether you're developing new features, fixing bugs, or extending functionality. Development overview The GDI User Portal is built with modern web technologies and follows best practices for scalability, security, and maintainability: - Frontend: Next.js with TypeScript - Backend Services: Java/Spring Boot microservices - Data Catalogue: CKAN with custom extensions - Authentication: Keycloak with LS-AAI integration - Containerisation: Docker and Docker Compose Getting started Choose your development focus: - New to the project? Start with Get started - Frontend development? Go to Develop frontend features - Backend integration? Check out Work with backend services - CKAN extensions? Explore Develop CKAN extensions - Feature development? See Add and modify features Contributing Before contributing, review our coding standards and follow the established Git workflow. Ensure comprehensive testing coverage and update documentation for new features. GitHub Repository: GenomicDataInfrastructure/gdi-userportal-frontend",
      "guide": "developer-guide"
    },
    {
      "id": "/gdi-userportal-frontend/developer-guide/work-with-backend",
      "url": "/gdi-userportal-frontend/developer-guide/work-with-backend",
      "title": "work with backend",
      "content": "Work with backend services The GDI User Portal integrates with multiple backend services to provide comprehensive genomic data infrastructure functionality. This section covers integration patterns, API communication, and service orchestration. Backend architecture Service overview The platform consists of several interconnected services: - Dataset Discovery Service (DDS) - Data catalogue API abstraction - Access Management Service (AMS) - Access control and requests - CKAN - Core data catalogue system - Keycloak - Authentication and authorisation - PostgreSQL - Data persistence - Solr - Search and indexing Service communication Services communicate using: - REST APIs with JSON payloads - OAuth2/OpenID Connect for authentication - Service-to-service authentication tokens - Event-driven patterns for asynchronous operations Dataset Discovery Service integration Integrate Dataset Discovery Service The DDS provides a clean API layer over CKAN, abstracting complex CKAN operations and providing enhanced functionality. API Endpoints Dataset Search and Retrieval React Integration Access Management Service integration Connect Access Management Service The AMS handles all aspects of data access requests, user permissions, and compliance tracking. Access Request Flow AMS Client Implementation Authentication flow implementation Implement authentication flows Integration with Keycloak and LS-AAI requires careful handling of OAuth2 flows and token management. NextAuth Configuration Token management Error handling and resilience Service error handling Implement robust error handling for service communication: Retry logic Service monitoring and logging Health checks Implement service health monitoring: Testing backend integration Integration testing Mocking services Next steps After mastering backend integration: - Add and modify features - Build complete features - Develop frontend features - Enhance user interfaces - Get started - Review development setup",
      "guide": "developer-guide"
    }
  ]
}